# Exported with the Erfurt API - http://aksw.org/Projects/Erfurt

@base <http://eis.iai.uni-bonn.de/> .
@prefix sysont: <http://ns.ontowiki.net/SysOnt/> .
@prefix foaf: <http://xmlns.com/foaf/0.1/> .
@prefix sioc: <http://rdfs.org/sioc/ns#> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix geo: <http://www.w3.org/2003/01/geo/wgs84_pos#> .
@prefix site: <http://ns.ontowiki.net/SysOnt/Site/> .
@prefix void: <http://rdfs.org/ns/void#> .
@prefix skos: <http://www.w3.org/2004/02/skos/core#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .
@prefix v: <http://www.w3.org/2006/vcard/ns#> .
@prefix content: <http://purl.org/rss/1.0/modules/content/> .
@prefix lod2: <http://lod2.eu/schema/> .
@prefix dcterms: <http://purl.org/dc/terms/> .
@prefix dbpedia: <http://dbpedia.org/resource/> .
@prefix doap: <http://usefulinc.com/ns/doap#> .
@prefix sioct: <http://rdfs.org/sioc/types#> .
@prefix aiiso: <http://purl.org/vocab/aiiso/schema#> .
@prefix ov: <http://open.vocab.org/terms/> .
@prefix vs: <http://www.w3.org/2003/06/sw-vocab-status/ns#> .
@prefix schema: <http://schema.org/> .
@prefix label: <http://purl.org/net/vocab/2004/03/label#> .
@prefix dc: <http://purl.org/dc/elements/1.1/> .
@prefix umbel: <http://umbel.org/umbel#> .
@prefix vann: <http://purl.org/vocab/vann/> .
@prefix ns14: <https://twitter.com/Daniel_hladky#> .
@prefix ns4: <http://vocab.ox.ac.uk/projectfunding#> .
@prefix ns0: <http://139.18.2.164:8080/> .
@prefix ns1: <http://cstadler.aksw.org/> .
@prefix ns2: <http://139.18.2.164:4444/demo/> .
@prefix ns3: <http://nlp2rdf.lod2.eu/> .
@prefix ns7: <https://twitter.com/alex_siebert#> .
@prefix ns8: <http://hans.uszkoreit.net/#> .
@prefix ns9: <http://www.nittka.de/index_e.html#> .
@prefix ns10: <http://de.linkedin.com/pub/andreas-both/22/672/942#> .
@prefix ns11: <http://www.mi.fu-berlin.de/inf/groups/ag-csw/Members/almashraee.html#> .
@prefix ns12: <http://www.hpi.uni-potsdam.de/meinel/lehrstuhl/team_fotos/current_phd_students/christian_hentschel.html#> .
@prefix ns13: <http://www.xing.com/profile/Mario_Lenz#> .
@prefix ns5: <http://eis.iai.uni-bonn.de/SchemaEvent/> .
@prefix ns15: <http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Presenter/> .
@prefix projects: <http://eis.iai.uni-bonn.de/Projects/> .
@prefix ns6: <http://eis.iai.uni-bonn.de/Events/2013/> .
@prefix lswt2013: <http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/> .
@prefix groups: <http://eis.iai.uni-bonn.de/Groups/> .
@prefix people: <http://eis.iai.uni-bonn.de/> .
@prefix ns16: <http://eis.iai.uni-bonn.de/Partner/> .
@prefix ns17: <http://cstadler.eis.iai.uni-bonn.de/> .
@prefix eis: <http://eis.iai.uni-bonn.de/schema/> .
@prefix qb: <http://purl.org/linked-data/cube#> .
@prefix address: <http://eis.iai.uni-bonn.de/Address/> .
@prefix ns18: <http://eis.iai.uni-bonn.de/schema_Event/> .
@prefix ns19: <http://eis.iai.uni-bonn.de/Project_Partner/> .
@prefix ns20: <http://aksw.org/schema/> .
@prefix ns21: <http://eis.uni-bonn.de/Person/> .
@prefix ns22: <http://eis.uni-bonn.de/> .
@prefix aair: <http://xmlns.notu.be/aair#> .
@prefix ns23: <http://www.iais.fraunhofer.de/#> .
@prefix ns24: <http://eis.iai.uni-bonn.de/Demo/> .
@prefix ns25: <http://> .
@prefix ns26: <http://butterbur04.iai.uni-bonn.de/ontowiki/diachron/> .
@prefix ns27: <https://github.com/AKSW/semann/> .
@prefix ns28: <http://eis.iai.uni-bonn.de/foaf_Person/> .

<http://107.170.70.175:8000/> a eis:Demo ;
                              rdfs:label "LinDA" ;
                              ov:screenshot <https://lh4.googleusercontent.com/-zbnGaYQl3Wo/VNDODc8YVxI/AAAAAAAAACA/pqEWkmQHi2U/w1412-h881-no/LinDA.png> ;
                              eis:demonstrates projects:Linda ;
                              eis:hookline "Enabling Linked Data and Analytics for SMEs" .

<http://academic.research.microsoft.com/Author/53619090> a schema:ProfilePage ;
                                                         foaf:primaryTopic people:MichaelMartin ;
                                                         eis:buttonLabel "@MSAcademicResearch" .

<http://academic.research.microsoft.com/Author/9493178> a schema:ProfilePage ;
                                                        foaf:primaryTopic people:SebastianTramp ;
                                                        eis:buttonLabel "@Microsoft Academic Search" .

<http://acrux.weposolutions.de/xodx/?c=activity&id=04cb30b3fc95f3bb5638cb4e234f8aaa> aair:activityObject people:NatanaelArndt .

<http://acrux.weposolutions.de/xodx/?c=activity&id=132077f2502515ed9f7e364b2ce4c460> aair:activityObject people:NatanaelArndt .

<http://acrux.weposolutions.de/xodx/?c=activity&id=24dcb3c22dcd7aa4beacaaf8a195595a> aair:activityObject people:NatanaelArndt .

<http://acrux.weposolutions.de/xodx/?c=activity&id=2c194121bef4934d66ecb94f1c75c458> aair:activityObject people:NatanaelArndt .

<http://acrux.weposolutions.de/xodx/?c=activity&id=39faa18f903b06032311e51d04ab957f> aair:activityObject people:NatanaelArndt .

<http://acrux.weposolutions.de/xodx/?c=activity&id=3e4c4b8062d145ca1ebac247d9820784> aair:activityObject people:NatanaelArndt .

<http://acrux.weposolutions.de/xodx/?c=activity&id=4dcde606089921ea837307edb0229937> aair:activityObject people:NatanaelArndt .

<http://acrux.weposolutions.de/xodx/?c=activity&id=8c5c330cf46537ff5b12e173b763c069> aair:activityObject people:NatanaelArndt .

<http://acrux.weposolutions.de/xodx/?c=activity&id=972cc818fd0dbccd7552780ba77c7784> aair:activityObject people:NatanaelArndt .

<http://acrux.weposolutions.de/xodx/?c=activity&id=d5614681f4d61eaf762bf5687543f129> aair:activityObject people:NatanaelArndt .

<http://acrux.weposolutions.de/xodx/?c=activity&id=e26d7a27bb581a10d4f04dd9ca97ed3a> aair:activityObject people:NatanaelArndt .

<http://acrux.weposolutions.de/xodx/?c=person&id=Lukasw> foaf:knows people:NatanaelArndt .

<http://acrux.weposolutions.de/xodx/?c=person&id=toni> foaf:knows people:NatanaelArndt .

<http://aksw.org/vCard/Bonn#adr> a v:Work ;
                                 rdfs:label "[Address Bonn]" ;
                                 v:country-name "Germany" ;
                                 v:locality "Bonn" ;
                                 v:postal-code "53117" ;
                                 v:street-address "Römerstraße 164" .

<http://butterbur04.iai.uni-bonn.de/ontowiki/> a eis:Demo ;
                                               rdfs:label "Luzzu" ;
                                               ov:screenshot <https://lh6.googleusercontent.com/-H9SmjNWNdmk/VNJN1jyhkYI/AAAAAAAAACo/YqGWoChtRgA/w1358-h796-no/Luzzu.png> ;
                                               eis:demonstrates projects:Luzzu ;
                                               eis:hookline "Quality Assessment Framework for LOD" .

ns10:id dcterms:description """Dr. Andreas Both ist Leiter Forschung und Entwicklung bei
Unister, einem der führenden E-Commerce-Unternehmen (B2C) in
Deutschland. In seiner Promotionsschrift erforschte er robuste
komponentenbasierte Systeme und Service-orientiere Architekturen (SOA).
Die durch ihn geleitete Forschung- und Entwicklungsgruppe konzentriert
sich auf die Integration von modernen Internet-Technologien bzw.
entsprechenden Forschungsergebnissen, besonderen Wert wird auf die
Erzeugung von Synergieeffekten aus der Verbindung verschiedener
Technologien gelegt."""^^sysont:Markdown .

<http://dl-learner.org/files/dl-learner-manual.pdf> a schema:Book ;
                                                    rdfs:label "DL-Learner Manual" ;
                                                    schema:isRelatedTo projects:SPARQR ;
                                                    eis:buttonLabel "Manual" .

<> a owl:Ontology, void:Dataset ;
   rdfs:label "EIS site model", "eis.iai.uni-bonn.de Research Group dataset" ;
   owl:imports <http://schema.org/> ;
   dcterms:title "eis.iai.uni-bonn.de" ;
   dcterms:contributor groups:EIS ;
   dcterms:creator people:JeremyDebattista ;
   dcterms:description "This dataset contains projects, sub groups, people and pages of the Enterprise Information Systems (EIS) Research Group @ University of Bonn and Organised Knowledge (OK) @ Fraunhofer IAIS.", "This dataset contains projects, sub groups, people and pages of the Enterprise Information Systems (EIS) Research Group @ University of Bonn and Organised Knowledge (OK) @ Fraunhofer IAIS Bonn."^^sysont:Markdown ;
   dcterms:license <http://creativecommons.org/licenses/by-sa/3.0/> ;
   dcterms:publisher groups:EIS ;
   dcterms:subject dbpedia:Machine_learning, dbpedia:Natural_language_processing, dbpedia:Semantic_Web ;
   void:classes "10" ;
   void:dataDump <http://eis.iai.uni-bonn.de/model/export/?m=http%3A%2F%2Feis.iai.uni-bonn.de%2F&f=rdfxml>, <http://eis.iai.uni-bonn.de/model/export/?m=http%3A%2F%2Feis.iai.uni-bonn.de%2F&f=turtle> ;
   void:entities "80" ;
   void:feature <http://www.w3.org/ns/formats/RDF_XML>, <http://www.w3.org/ns/formats/Turtle> ;
   void:properties "40" ;
   void:sparqlEndpoint people:sparql ;
   void:triples "700" ;
   void:vocabulary <http://purl.org/dc/terms/>, <http://purl.org/vocab/aiiso/schema#>, <http://rdfs.org/ns/void#>, <http://rdfs.org/sioc/ns#>, <http://usefulinc.com/ns/doap#>, <http://www.w3.org/2004/02/skos/core#>, <http://xmlns.com/foaf/0.1/> ;
   foaf:homepage <http://eis.iai.uni-bonn.de> ;
   foaf:page projects:EISorg ;
   sioc:feed <http://eis.iai.uni-bonn.de/blog/feed/> ;
   void:rootResource <http://eis.iai.uni-bonn.de/Navigation/Main> .

<http://eis.iai.uni-bonn.de//157> site:content """# Funded Projects

{{query where=\"?resourceUri a eis:FundedProject.\" template=\"liplain\"}}
EIS is currently funded with the following regional, national and European research projects: {{query where=\"?resourceUri a eis:FundedProject. OPTIONAL { ?resourceUri eis:status ?status } FILTER (?status != 'finished')\" template=\"abstract\"}}"""^^sysont:Markdown .

<http://eis.iai.uni-bonn.de//158> site:content """# Funded Projects

{{query where=\"?resourceUri a eis:FundedProject.\" template=\"liplain\"}}
EIS is currently funded with the following regional, national and European research projects: {{query where=\"?resourceUri a eis:FundedProject. OPTIONAL { ?resourceUri eis:status ?status } FILTER (?status != 'finished')\" template=\"abstract\"}}"""^^sysont:Markdown .

people:About site:content """<nav class=\"nav-sidelinks\">
  <ul>
     <li>
          <strong>current projects</strong>
          {{query where=\"?resourceUri a foaf:Project. OPTIONAL { ?resourceUri eis:status ?status }  FILTER (?status != 'finished')\" template=\"liplain\"}}
  </ul>
</nav>
The department **Enterprise Information Systems (EIS)** at the Institute for Applied Computer Science at University of Bonn and Fraunhofer Institute for Intelligent Analysis and Information Systems (IAIS) is led by [Sören Auer](/SoerenAuer \"Contact Information\").

The primary objective of the research group is to advance research and technology in the field of enterprise information systems & semantic technologies and to widely apply this research in large-scale use cases. A particular focus of research and technology is information, data and knowledge integration employing Linked Data strategies. The department is committed to the open source, open access and open knowledge movements.

We achieved many projects and are actively working  on several others. Please have a look at some of our **demos**:

{{query where=\"?resourceUri a eis:Demo.\" template=\"wheel\"}}

<hr>"""^^sysont:Markdown .

address:Romerstrasse164 a schema:PostalAddress ;
                        rdfs:label "Romerstraße 164, 53117 Bonn" ;
                        schema:addressCountry "DE" ;
                        schema:addressLocality "Bonn" ;
                        schema:postalCode "53117" ;
                        schema:streetAddress "Romerstraße 164" .

address:Schloss_Birlinghoven_1_53754_Sankt_Augustin a schema:PostalAddress ;
                                                    rdfs:label "Schloß Birlinghoven 1, 53754 Sankt Augustin" ;
                                                    schema:addressCountry "DE" ;
                                                    schema:addressLocality "Sankt Augustin" ;
                                                    schema:postalCode "53754 " ;
                                                    schema:streetAddress "Schloß Birlinghoven 1" .

<http://eis.iai.uni-bonn.de/Address/vCard/Augustusplatz10> a v:Work ;
                                                           rdfs:label "[Address Leipzig]" ;
                                                           v:country-name "Germany" ;
                                                           v:locality "Leipzig" ;
                                                           v:postal-code "04109" ;
                                                           v:street-address "Augustusplatz 10" .

people:AlanTygel a foaf:Person ;
                 rdfs:label "AlanTygel" ;
                 skos:prefLabel "Alan Tygel" ;
                 foaf:name "Alan Tygel" ;
                 foaf:homepage <http://cirandas.net/alantygel/site-academico> ;
                 foaf:depiction <http://cirandas.net/thumbnails/0029/5980/alan_ihu_menor_display.jpg> ;
                 foaf:mbox <mailto:alantygel@ppgi.ufrj.br> ;
                 foaf:familyName "Tygel" ;
                 eis:room "A110a" .

people:Blog rdfs:label "Blog" .

people:ChristophLange a foaf:Person ;
                      rdfs:label "Dr. Christoph Lange" ;
                      rdfs:seeAlso <http://langec.wordpress.com/about> ;
                      owl:sameAs <http://purl.org/net/clange> ;
                      skos:prefLabel "Dr. Christoph Lange" ;
                      foaf:name "Christoph Lange" ;
                      foaf:homepage <http://langec.wordpress.com/about> ;
                      skos:hiddenLabel "Christoph Lange-Bever" ;
                      foaf:currentProject projects:OpenCourseWare_observatory, projects:Diachron, projects:VoCol ;
                      foaf:depiction <http://www.iai.uni-bonn.de/~langec/photo.jpg> ;
                      foaf:mbox <mailto:math.semantic.web@gmail.com> ;
                      foaf:phone <tel:+492241142428> ;
                      foaf:familyName "Lange" ;
                      eis:room "A118" .

people:Comment5211f4e1c0394 a sioct:Comment ;
                            dcterms:created "2013-08-19T12:35:13+02:00"^^xsd:dateTime ;
                            sioc:has_creator people:NatanaelArndt ;
                            sioc:content "@thomas, passt das jetzt so mit der Adresse?" ;
                            sioc:about ns16:RolandBloch .

people:Comment5239af3bcbcc1 a sioct:Comment ;
                            sioc:about ns6:LeipzigerSemanticWebTag .

people:Comment5239ba30c1ad5 a sioct:Comment ;
                            sioc:about <http://eis.iai.uni-bonn.de/Events/2013/DigitaleForschungskollaboration/Programm> .

people:Contact site:content """<nav class=\"nav-sidelinks\">
<ul>
<li><strong class=\"headline\">people</strong>
{{query where=\"?group foaf:member ?resourceUri . OPTIONAL {  ?group aiiso:part_of groups:EIS . ?resourceUri <http://xmlns.com/foaf/0.1/familyName> ?familyName }\" template=\"liplain\" orderby=\"ASC(?familyName)\"}}
</li>
</nav>

Please send emails to <a href=\"eis-leaders@lists.iai.uni-bonn.de\">eis-leaders@lists.iai.uni-bonn.de</a>.

## How To Find Us
The Department of Enterprise Information Systems is located in the Institut für Informatik III  at <a href=\"https://www.google.de/maps/place/Römerstraße+164,+University+of+Bonn,+Fachschaft+Informatik+Universität+Bonn,+53117+Bonn/@50.7524378,7.0955941,17z/data=!3m1!4b1!4m2!3m1!1s0x47bee1ad766d40fd:0x564485adf7f46873?hl=en\"> Römerstraße 164 </a>.

### Directions

#### By car
##### Fraunhofer
<a href=\"https://maps.google.com/maps?q=Fraunhofer-Institut+für+Intelligente+Analyse-+und+Informationssysteme+IAIS,+Sankt+Augustin,+Germany&hl=en&ie=UTF8&sll=50.751011,7.201881&sspn=0.102201,0.098705&oq=Fraunhofer+IAIS&t=h&hq=Fraunhofer-Institut+für+Intelligente+Analyse-+und+Informationssysteme+IAIS,&hnear=Sankt+Augustin,+Cologne,+North+Rhine-Westphalia,+Germany&z=14\">Schloss Birlinghoven, Sankt Augustin, Germany</a>. Before your satnav sends you to <a href=\"https://maps.google.com/maps?q=Birlinghoven&ll=50.748703,7.216129&spn=0.025551,0.024676&hnear=Birlinghoven,+Germany&t=h&z=15\">Birlinghoven village</a>, rather enter “Konrad-Adenauer-Straße, Sankt Augustin”


#### By Public Transport
##### University
Enter the destination “Pädagogische Fakultät, Bonn” into this <a href=\"http://reiseauskunft.bahn.de/bin/query.exe/d\">form</a>

##### Fraunhofer
Enter the destination “Fraunhofer-Schloß Birlinghoven, Sankt Augustin” into this <a href=\"http://reiseauskunft.bahn.de/bin/query.exe/d\">form</a>

### Address

Institut für Informatik III
Römerstraße 164
53117 Bonn,
Germany

Phone: <a href=\"tel:+ 49228737816\">+49 228 73 7816</a>

Fax: <a href=\"tel:+ 49228734382\">+49 228 73 4382 </a>"""^^sysont:Markdown .

people:DaryaTarasowa a foaf:Person ;
                     skos:prefLabel "Darya Tarasowa" ;
                     foaf:name "Darya Tarasowa" ;
                     site:templateOption "extended" ;
                     foaf:currentProject projects:SlideWiki, projects:EDSA ;
                     foaf:depiction <https://fbcdn-profile-a.akamaihd.net/hprofile-ak-xfp1/v/t1.0-1/c1.0.521.521/s200x200/10414502_792600064129418_5113957601139984831_n.jpg?oh=3b120e931f287aa23380263d1fafd27d&oe=5582838D&__gda__=1434948509_ab7267b25078f6de5d8e242fd2d56d5a> ;
                     foaf:mbox <mailto:darya.tarasowa@gmail.com> ;
                     foaf:familyName "Tarasowa" ;
                     eis:publicationTag "tarasowa" ;
                     eis:room "A110a" .

people:Diego_Collarana a foaf:Person ;
                       rdfs:label "Diego Collarana" ;
                       skos:prefLabel "Diego Collarana" ;
                       foaf:name "Diego Collarana" ;
                       foaf:homepage <https://www.linkedin.com/pub/diego-collarana/27/b61/60a> ;
                       skos:hiddenLabel "Diego Collarana" ;
                       foaf:depiction <https://media.licdn.com/media/p/4/000/13e/336/35bb4dc.jpg> ;
                       foaf:mbox <mailto:collaran@iai.uni-bonn.de> .

people:DietlandZuehlke a foaf:Person ;
                       rdfs:label "Dr. Dietlind Zühlke" ;
                       foaf:depiction <https://media.licdn.com/mpr/mpr/shrink_200_200/p/1/005/08e/1bf/02d4dd7.jpg> ;
                       foaf:mbox <mailto:dietlind.zuehlke@iais.fraunhofer.de> ;
                       foaf:familyName "Zühlke" .

people:Environment site:content """<p>The university and Bonn region provide an exceptional environment for successful research and a high quality of life.</p>
<h3>University of Bonn</h3>
<p>The University of Bonn offers a large number of undergraduate and graduate programs in a range of subjects. Its library holds more than two million volumes. The University of Bonn has 525 professors and 31,000 students. Among its notable alumni and faculty are seven Nobel Laureates, two Fields Medalists, twelve Gottfried Wilhelm Leibniz Prize winners, Pope Benedict XVI, Frederick III, Karl Marx, Heinrich Heine, Friedrich Nietzsche, Konrad Adenauer, and Joseph Schumpeter.
University of Bonn is constantly <a href=\"http://en.wikipedia.org/wiki/University_of_Bonn#Ranking\">ranked among the best universities</a> in Germany, Europe and world-wide.</p>
<h3>Fraunhofer Institute for Intelligent Analysis and Information Systems (IAIS)</h3>
<p>With its workforce of nearly 280 employees, <a href=\"http://www.iais.fraunhofer.de/\">Fraunhofer IAIS</a> combines the competences and scientific qualities of all engineering disciplines - especially informatics, and mathematics, natural sciences, business economics, geo and social sciences - with profound industry expertise.
IAIS has a budget of approx. 20 million euros the institute implements application solutions in the fields of machine learning, multimedia pattern recognition, visual analytics, process intelligence, adaptive robotics and cooperating objects.</p>
<h3>City of Bonn</h3>
<p><a href=\"http://en.wikipedia.org/wiki/Bonn\">Bonn</a> is a city on the banks of the Rhine River in the German State of North Rhine-Westphalia.
It was capital of West Germany till 1990 and the official seat of government of united Germany till 1999.
Bonn is located right next to Cologne (Germany's fourth largest city) in the very south of the Rhine-Ruhr region, the largest metropolitan area of Germany.
While being a cultural, political, scientific and economic hub Bonn has preserved its historic charm.
Comparative worldwide studies have confirmed for many years that <a href=\"http://www.bonn.de/wirtschaft_wissenschaft_internationales/wirtschaftsstandort_bonn/standortimage/09339/index.html?lang=en\">Bonn offers an outstanding quality of life</a>.
Surrounded by some of the most delightful countryside in Europe, its residents have a wide range of recreational options.
Bonn has developed into a hub of international cooperation in particular in the area of environment and sustainable development and currently hosts 18 United Nations institutions.
Bonn is located at the most frequented German high-speed ICE rail line, shares with Cologne one of the busiest German airports and is just a 40 minutes train ride away from Frankfurt airport.
Many European metropoles such as Brussels, Luxembourg, Frankfurt, Paris, Amsterdam are in easy reach by train.</p>"""^^sysont:HTML .

people:Events site:content """# Upcoming Events
<nav class=\"nav-sidelinks\">
{{query where=\"?resourceUri a schema:Event . ?resourceUri schema:startDate ?startDate . filter(xsd:dateTime(?startDate) > NOW()).\" orderby=\"DESC(?startDate)\" template=\"liplain\"}}
</nav>
{{query where=\"?resourceUri a schema:Event . ?resourceUri schema:startDate ?startDate . filter(xsd:dateTime(?startDate) > NOW()). \" orderby=\"DESC(?startDate)\" template=\"abstract\"}}

# Past Events

<nav class=\"nav-sidelinks\">
{{query where=\"?resourceUri a schema:Event . ?resourceUri schema:startDate ?startDate . filter(xsd:dateTime(?startDate) < NOW()).\" orderby=\"DESC(?startDate)\" template=\"liplain\"}}
</nav>
{{query where=\"?resourceUri a schema:Event . ?resourceUri schema:startDate ?startDate . filter(xsd:dateTime(?startDate) < NOW()).\" orderby=\"DESC(?startDate)\" template=\"abstract\"}}

"""^^sysont:Markdown .

ns6:ColloquiumPokharelCherix dcterms:abstract """In our weekly AKSW Colloquium, we present research, technologies and tools of the Semantic Web. The colloquium is open to the public and we welcome interested students, colleagues and industry partners to experience bleeding edge work-in-progress presentations and discussion rounds as well as talks by invited experts of our AKSW lecture series.

On Monday, October 21at 1.30 – 2.30 pm in Room P-702 (Paulinum), we will have presentations by Suresh Pokharel about Ontologies for farming in Nepal and by Didier Cherix about his master’s thesis about semi automatic error detection in ontologies (in german).

Furthermore, we would like to announce, that there is complimentary coffee and cake after the session. Bachelor and Master students will be able to get points for attendance.""" ;
                             site:content """# Ontology Based Data Access and Integration for Improving the Effectiveness of Farming in Nepal” by Suresh Pokharel, new PhD student

I am Suresh Pokharel and I am studying at the University of Leipzig. My background is a Master of Engineering in Information and Communications Technologies (2008–2010) from Asian Institute of Technology, Thailand. I did my master’s thesis on the topic “Web Forum Mining based on User Satisfaction” under the supervision of Professor Sumanta Guha. I have an Bachelor of Engineering in Computer (2001–2005) from Pokhara University, Nepal. I taught (Part Time) Data Mining, Artificial Intelligence, Project works, Database etc. in Nepal College of Information Technology, Nepal since Sept 2010 to 29 Sept 2013.

In AKSW, I am working on the topic “Ontology Based Data Access and Integration for Improving the Effectiveness of Farming in Nepal”. The objective of this research is to integrate the agriculture related data (weather, crop, soil, geo-spatial data) with the help of semantic web technology for getting the richer agriculture related information.

# Ontologiemetriken zur Datenqualitätsverbesserung von Didier Cherix, Masterarbeit

Ich studiere an der Universität Leipzig, wo ich meine Bachelorarbeit über die Generierung von SPARQL queries geschrieben habe.

Nun stelle ich meine Masterarbeit vor. Diese behandelt die Entwicklung eines semi-automatisierten Verfahrens zur Entdeckung von potentiellen Fehlern in einer Ontologie.
Um potentiell fehlerhafte Instanzen zu finden, werden die Werte der verschiedenen Properties analysiert und in Metriken erfasst. Mittels dieser Metriken werden die einzelnen Instanzen einer Klasse geclustert und somit versucht, Fehler zu entdecken."""^^sysont:Markdown .

ns6:DigitaleForschungskollaboration site:content """# Übersicht / Overview

Im Fokus des Workshops stehen Vokabulare der verschiedener Domänen in den Geistes- und Sozialwissenschaften, deren Publikation und Entwicklung im Web, sowie Verfahren zur Angleichung. Der Workshop adressiert gleichermaßen Geistes- und Sozialwissenschaftler, IT-Experten in Bibliotheken und Informatiker.

Die Beiträge des Workshops werden in einem Tagungsband in der Reihe \"Leipziger Beiträge zur Informatik\" publiziert.

# Organisation / Chair

* Thomas Riechert
* Roland Bloch
* Ulf Morgenstern
* Alexander Mitterle

# Registrierung

* Normal:
  * Workshop OWL-Vokabulare im Kontext digitaler Forschungskollaboration (24.9.): 75,00 Euro
  * Workshop OWL-Vokabulare im Kontext digitaler Forschungskollaboration (24.9.) und Leipziger Semantic Web Tag (23.9.): 95,00 Euro


* Studierende:
  * Workshop OWL-Vokabulare im Kontext digitaler Forschungskollaboration (24.9.): 40,00 Euro
  * Workshop OWL-Vokabulare im Kontext digitaler Forschungskollaboration (24.9.) und Leipziger Semantic Web Tag (23.9.): 60,00 Euro


Aus den Gebühren werden die Durchführung des Workshops und die Produktion des Tagungsbandes finanziert.

##[ Ort: Campus der Universität Leipzig](http://eis.iai.uni-bonn.de/Events/2013/DigitaleForschungskollaboration/Anreise \"Anreise\")
"""^^sysont:Markdown .

<http://eis.iai.uni-bonn.de/Events/2013/DigitaleForschungskollaboration/CfP> site:content """Wissenschaftliches Arbeiten mit digitalen Medien wie Onlinepublikationen und wissenschaftlichen Datenbanken erweitert die bisherigen Forschungsgebiete und führt zu neuen Untersuchungsfeldern. Neuartige Zugangsverfahren und der Umfang an verfügbaren Informationen verändern das methodische Vorgehen und ermöglichen neuartige Zugänge. Einen Aspekt stellt dabei die Verknüpfung von Medien und Datenbanken im Web mittels des Linked Open Data Paradigmas dar. Eine semantische Interoperabilität kann über eine Angleichung von Vokabularen im Kontext der Forschungsdomänen erreicht werden.

In diesem Zusammenhang entstehen neue Forschungskollaborationen zwischen Geistes- und Sozialwissenschaftler/innen auf der einen Seite und Informatiker/innen auf der anderen Seite. Sollen beiden Seiten von digitalen Informationen profitieren, müssen informationstechnologische Entwicklungen mit geistes- und sozialwissenschaftlichen Fragestellungen verbunden werden. Das erfordert, ein gemeinsames Vokabular für die so entstehenden „Digital Humanities“ zu entwickeln.

Im Fokus des Workshops stehen Vokabulare verschiedener Domänen in den Geistes- und Sozialwissenschaften, deren Publikation und Entwicklung im Web sowie Verfahren zur Angleichung. Der Workshop wendet sich gleichermaßen an Geistes- und Sozialwissenschaftler/innen, IT-Expert/innen in Bibliotheken und Informatiker/innen. Geplant sind Kurzvorträge (15 min plus Diskussion), die sich aus unterschiedlichen Perspektiven der Schnittstelle zwischen geistes- und sozialwissenschaftlicher Forschungspraxis und dem Aufbau informationstechnologischer Infrastrukturen nähern.

Vorträgsvorschläge reichen Sie bitte in Form eines Extended Abstract (8.000 bis 12.000 Zeichen bzw. 4 Seiten im LNI-Format inkl. Grafiken etc.) bis zum 10. September 2013 online ein unter [http://www.easychair.org/conferences/?conf=vokdf2013](http://www.easychair.org/conferences/?conf=vokdf2013 \"http://www.easychair.org/conferences/?conf=vokdf2013\")"""^^sysont:Markdown .

<http://eis.iai.uni-bonn.de/Events/2013/DigitaleForschungskollaboration/Menu> a site:Navigation ;
                                                                              rdf:_1 ns6:DigitaleForschungskollaboration ;
                                                                              rdf:_2 <http://eis.iai.uni-bonn.de/Events/2013/DigitaleForschungskollaboration/CfP> ;
                                                                              rdf:_3 <http://eis.iai.uni-bonn.de/Events/2013/DigitaleForschungskollaboration/Programm> ;
                                                                              rdf:_4 <http://sabre2013.infai.org/registration> ;
                                                                              rdf:_5 <http://eis.iai.uni-bonn.de/Events/2013/DigitaleForschungskollaboration/Anreise> ;
                                                                              foaf:primaryTopic ns6:DigitaleForschungskollaboration .

<http://eis.iai.uni-bonn.de/Events/2013/DigitaleForschungskollaboration/Programm> site:content """**09:00 Anmeldung**

**09:30 Keynote: <a target=\"extern\"  href=\"http://de.wikipedia.org/wiki/Van_Bo_Le-Mentzel\">Van Bo Le Mentzel</a> (englisch)**

**10:15 Kaffeepause**

**10:30 Werkzeuge: Modellierung, Integration, Publikation**

- **Linked Data Vocabulary Publication utilizing OntoWiki Site Extension**<br/>_Natanael Arndt_, Andreas Nareike, Norman Radtke und Thomas Riechert<br/>
Das Fundament des Semantic Web stellen RDF/OWL-Vokabulare dar. Die Publikation des Vokabulars ermöglicht und fördert die breite Verwendung durch andere Anwender und damit die Verknüpfung mit anderen Ressourcen. SchemaSite stellt ein einfaches Werkzeug zur kollaborativen Erstellung und Publikation der Vokabulare in einer natürlichsprachichen Darstellung und als LinkedData auf Basis von OntoWiki dar.
- **Analyse von Metadaten wissenschaftlicher Onlinedatenbanken am Beispiel des Projekts Linked History**<br/>
_Paul Röwer_
-  **Vorstellung der
Arbeitsgemeinschaft Deutscher Professorenkatalog**<br/>
_Ulf Morgenstern_ und Thomas Riechert

**12:30 Mittagspause**

**13:30 Anwendungen des Semantic Web in Digitaler Forschungskollaboration**

- **Wenn die Sammlungen vernetzt werden, sollten die Metadatenvokabulare folgen**<br/>
_Gerard Kuys_<br/>
In den Niederlanden sind allmählich Kulturinstitutionen auf den Gedanken verfallen, daß sie ihres Publikum vergrößern können wenn sie wenigstens teilweise ihre Materialien als Open Data publizieren. Aber sogar diejenige Einrichtungen die der Vernetzung eigener Themen oder Gegenständen aufrichtig nachstreben, stoßen auf die Schwierigkeit daß die relevante Metadatenvokabulare nur für einen abgesteckten Bereich (jeweils Bibliotheken, Museen, Archive) geeignet sind. Sogar Europeana ist immer noch prinzipiell materialienbezogen. Gerard Kuys plädiert für ein verbindendendes Vokabular, das den Inhalten selber statt schlicht ihren Trägern zugewandt ist.
- **Digital Academics. Ein Konzept zur Entwicklung von Methoden zur Analyse digitaler Spuren von Wissenschaftler/innen**<br/>_Roland Bloch_, Alexander Mitterle, Carsten Würmann und Thomas Riechert
- **Entwicklung eines Electronic Resource Management Systems für Bibliotheken auf Basis von Linked Data Technologien**<br/>_Lydia Unterdörfel_ und Björn Muschal
- **Converting and Modelling Library Data For E-Journals**<br/>Natanael Arndt, _Andreas Nareike_, _Norman Radtke_ und Thomas Riechert<br/>
Vorgestellt und diskutiert werden Probleme, die im Umgang mit Bibliotheksdaten im Kontext von  elektronischen Zeitschriften auftreten. Dabei gehen wir auf existierende Datenbestände ein und inwieweit diese in einen Linked Data Ansatz integriert werden können. Es wird auch die Frage eine Rolle spielen, welche Ontologien bereits existieren, eventuell wiederverwendet und/oder angepasst werden können.
- **Ontology Alignment Pattern am Beispiel der Semantic Web Ontology for Requirements-Engeneering**<br/> _Thomas Riechert_

**16:00 Kaffee und Ende des Workshops**

Die **Abendveranstaltung** zum Workshop findet bereits am Montag den 23.September statt. Alle Teilnehmer sind herzlich eingeladen um  bei einem rustikalem Buffet mit musikalischer Untermalung den Leipziger Semantic Web Tag ausklingen zu lassen und sich auf den Workshop am Dienstag einzustimmen ;-). Die Abendveranstaltung bietet die Möglichkeit in entspannter Atmosphäre die Ereignisse und Erkenntnisse der Veranstaltungen zu reflektieren und neue Kontakte zu knüpfen . """^^sysont:Markdown .

ns6:LeipzigerSemanticWebTag schema:startDate "2013-09-23"^^xsd:date ;
                            schema:endDate "2013-09-24"^^xsd:date .

lswt2013:Anreise site:content """{{toc tag=\"ul\" depth=\"3\"}}
# Anreisebeschreibungen
<img src=\"http://www.wifa.uni-leipzig.de/fileadmin/user_upload/dekanat/Lageplan_Wirtschaftswissenschaftliche_Fakultaet.jpg\">

# Anreise mit dem Auto
Über die Autobahn A9: Abfahrt Großkugel auf die B6 oder Abfahrt Leipzig West auf die B181, jeweils Richtung Innenstadt.
Über die Autobahn A 38: Abfahrt Kreuz Rippachtal auf die B87, Richtung Innenstadt.
Über die Autobahn A 14: Abfahrt Leipzig Mitte auf die B2 oder Abfahrt Leipzig Nordost auf die B87, jeweils Richtung Innenstadt.
Folgen Sie dem Innenstadtring bis zum Augustusplatz am Georgiring. Parkmöglichkeiten gibt es direkt am Augustusplatz (Tiefgarage) gegen Gebühr.

# Anreise mit dem Zug
Intercity- und Intercity-Express-Züge verbinden Leipzig mit fast allen europäischen Städten. Der Campus Augustusplatz liegt in unmittelbarer Nähe des Leipziger Hauptbahnhofs:
  * 5 Minuten Fußweg entlang der Nikolaistraße oder der Goethestraße, Richtung City-Hochhaus.
  * Eine Haltestelle mit den Straßenbahnlinien 10, 11 oder 16 Richtung Süden oder mit den Straßenbahnlinien 4, 7, 12 oder 15 Richtung Osten bis Haltestelle Augustusplatz.

# Anreise mit dem Flugzeug
Der Flughafen Leipzig/Halle ist etwa 30 Autominuten vom Stadtzentrum entfernt. Zwischen dem Flughafen Leipzig/Halle und dem Hauptbahnhof gibt es eine Zugverbindung. Züge fahren alle halbe Stunde, die Fahrtzeit beträgt ca. 15 Minuten. Vom Hauptbahnhof aus benutzen Sie bitte den Weg wie oben beschrieben. Sollte es von Ihrer Stadt keinen Direktflug nach Leipzig geben, empfehlen wir Ihnen, nach Berlin (ca. eine Stunde Zugfahrt bis Leipzig), Frankfurt am Main oder Hannover (ca. drei/ dreieinhalb Stunden Zugfahrt bis Leipzig) zu fliegen. Von allen drei Städten verkehren regelmäßig Züge nach Leipzig.
"""^^sysont:Markdown .

lswt2013:Call site:content """Einladung zur Teilnahme - Call for participation

Der Leipziger Semantic Web Tag (LSWT) bietet seit 2009 Unternehmen und Organisationen die Möglichkeit, sich zu Themen im Bereich semantischer Technologien auszutauschen.
In den letzten Jahren wurden Semantic Web Technologien von vielen Firmen in größerem Umfang eingesetzt.
Insbesondere das Linked Data Paradigma hat sich von einem forschungszentrischen Thema zu einem Satz von industrierelevanten Technologien und Anwendungen entwickelt.
Im Fokus des LSWT 2013 mit dem Motto \"Von Big Data zu Smart Data\" steht das Demonstrieren dieser Technologien im Rahmen von Vorträgen von Experten aus Industrie und Wissenschaft.

## Ort und Zeit
* Montag, 23. September Konferenz
* Dienstag, 24. September Tutorials

Der LSWT findet  Rahmen der SABRE 2013 auf dem innerstädtischen Campus (Grimmaischen Straße 12) der Universität Leipzig am Augustusplatz statt.
Ein genaue Anfahrtsbeschreibung findet sich auf der [LSWT homepage](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Anreise)


## Keynote
Wir konnten Hans Uszkoreit als Keynote-Sprecher gewinnen.
[Hans Uszkoreit](http://hans.uszkoreit.net/) ist sowohl profilierter Forscher als auch Unternehmer.


## Themen
Im Rahmen unseres Mottos \"Von Big Data zu Smart Data\" interessieren uns insbesondere die Themen:

* Vernetzung von öffentliche (offenen?) Daten von Verwaltungen und Regierungen: Transparenz für Bürger und Verwertung für Unternehmen und Industrie
* Big Data and the Semantic Web: Skalierbarkeit von Datenbanken und Datenintegration im Unternehmen.
* Unlocking the Semantics of Text: Textanalyse im Semantic Web


## Teilnahme
Wir freuen uns auf Ihre Teilnahme am Leipziger Semantic Web Tag 2013.
Folgende Möglichkeiten stehen Ihnen offen:

### Teilnahme als Vortragende
Gerne können Sie am LSWT 2013 einen Vortrag halten.
Bitte nutzen Sie folgendes Formular zu Anmeldung.

### Teilnahme als Besuchende
Um die Teilnahme so einfach wie möglich zu gestalten, haben wir die Registrierungsgebühren so gering wie möglich gehalten, insbesondere für Studenten. Details und Registrierung entnehmen Sie bitte der LSWT website

### Teilnahme als Sponsor

Präsentieren Sie Ihr Unternehmen auf dem LSWT 2013.
Details zu den Paketen, deren Leistungen und Preisen finden Sie auf unserer [Website](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Sponsoring)

"""^^sysont:Markdown .

lswt2013:Einladung site:content """Im Fokus des LSWT 2013 mit dem Motto \"<b>Von Big Data zu Smart Data</b>\" steht das Demonstrieren dieser Technologien durch Vorträge von Experten aus Industrie und Wissenschaft. Im Rahmen unseres Mottos interessieren uns insbesondere die Themen:
<ul><li><b>Vernetzung von öffentliche (offenen?) Daten von Verwaltungen und Regierungen</b>: Transparenz für Bürger und Verwertung für Unternehmen und Industrie.</li>
<li><b>BigData and the Semantic Web</b>: Skalierbarkeit von Datenbanken und Datenintegration im Unternehmen.</li>
<li><b>Unlocking the Semantics of Text</b>: Textanalyse im Semantic Web</li>
</ul>

Der diesjährige LSWT ist Bestandteil der vom INFAI organisierten Leipziger Tage der Angewandten Informatik.

## [Aktive Teilnahme](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Einladung \"Aktive Teilnahme\")
Bitte füllen Sie [das Formular auf dieser Seite aus](https://docs.google.com/forms/d/1A0APKRpG287EUFUd6kN0oPUx9wj6burp4723VuKroLA/viewform \"Formular\") bis zum **20.08.2013** aus, wenn Sie sich aktiv am LSWT 2013 beteiligen wollen. Wir suchen noch Vortragende, Demos, Sponsoren und Tutorials, sind aber auch offen für Ihre Vorschläge. Falls Sie Fragen haben oder sich lieber per Email um die Teilnahme bewerben möchten, können Sie sich auch gern an das [Orga-Team](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Kontakt \"Orga Team\") wenden.

## [Sponsoring](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Sponsoring \"Sponsoring\")
Gern können Sie sich als Sponsor am LSWT beteiligen. Wir bieten insgesamt [drei Sponsoring-Pakete](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Sponsoring \"Sponsoring\") an, mit denen Sie Ihr Unternehmen auf dem LSWT präsentieren können. Bei Interesse wenden Sie sich bitte an das [Orga-Team](Kontakt).

## Save the date: 23.-24. September 2013
Kerntag des LSWT ist der 23.09. mit anschließender Abendveranstaltung. Zur Vertiefung finden am nächsten Tag (24.09.) Tutorien zum Knowledge Transfer statt.

## [Keynote: Hans Uszkoreit - Big Data and Text Analytics](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Keynote \"Keynote\")
<table border=\"0\">
<tr><td><img width = \"80\" src = \"http://wiki.eis.iai.uni-bonn.de/files/lswt/2013/HansUszkoreit.png \" /></td><td>
Es gehört zu den Herausforderungen unserer Zeit, adäquat mit unserer Hinterlassenschaft umzugehen: der unüberschaubaren Masse an Text im World Wide Web.  Durch die Kombination von skalierbaren statistischen Modellen mit intelligenten regelbasierten Systemen eröffnet sich die vielversprechende Perspektive, einen fein-granularen, vielseitig einsetzbaren, translingualen \"Wissensgraphen\" zu produzieren, der ein weites Spektrum an Anwendungen bedient. </td></tr></table>

## News
* [AKSW Blog](http://blog.eis.iai.uni-bonn.de \"AKSW Blog\")
* Twitter Tag: [#LSWT2013](https://twitter.com/search/realtime?q=%23LSWT2013 \"#LSWT 2013\")
* [Facebook](https://www.facebook.com/events/445578762204541/ \"Facebook\")
* [Program via Google ICal](https://www.google.com/calendar/ical/9j1htafari6eh9mvg1odcgnf28%40group.calendar.google.com/private-3929ab1664f2d184068135993c157f59/basic.ics \"Program\")



Bei Interesse wenden Sie sich bitte an das [Orga-Team](Kontakt).

Mit freundlichen Grüßen,

Sebastian Hellmann, Jörg Unbehauen und Michael Martin
"""^^sysont:Markdown .

lswt2013:Kerntag site:content """Vorträge können noch gerne zur

[Minute Madness](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/MinuteMadness.html \"Minute Madness\") eingereicht werden.

<iframe id=\"lswtcal\" src=\"http://docs.eis.iai.uni-bonn.de/lswt2013/day.php?getdate=20130923\" frameborder=\"0\" width=\"100%\" height=\"900\"><p>Diese Seite benötigt die Unterstützung von Frames durch Ihren Browser.</p></iframe>"""^^sysont:Markdown .

lswt2013:Keynote site:content """# 23.09. Hans Uszkoreit - Big Data and Text Analytics
{{toc tag=\"ul\" depth=\"3\"}}
##  Abstract - Deutsch
Das Gebiet der Textanalytik wird mit einer rapide anwachsenden Menge an Texten konfrontiert.
In seinem Vortrag argumentiert Hans Uszkoreit, dass Big Data im Bereich Sprachverarbeitung nicht nur als eine große Herausforderung aufzufassen ist, sondern als Chance, im großen Maße Wissen in Form von 'Smart Data' zu extrahieren. Unter den vielseitigen Verwendungszwecken von Smart Data finden sich neue Anwendungen der Wissensextraktion aber auch Verbesserungen von domänenspezifischen Sprachmodellen. Es gehört zu den Herausforderungen unserer Zeit, adäquat mit unserer Hinterlassenschaft umzugehen: der unüberschaubaren Masse an Text im World Wide Web.  Durch die Kombination von skalierbaren statistischen Modellen mit intelligenten regelbasierten Systemen eröffnet sich die vielversprechende Perspektive, einen fein-granularen, vielseitig einsetzbaren, translingualen \"Wissensgraphen\" zu produzieren, der ein weites Spektrum an Anwendungen bedient. Hans Uszkoreit wird bestehende neue Anwendungen vorstellen und mit einem Ausblick auf die Möglichkeiten schließen, die sich durch Big \"Smart\" Data ergeben.
Invited talk: Big Data and Text Analytics

##  Abstract - English
Text analytics is faced with rapidly increasing volumes of language data. In his talk, Hans Uszkoreit will show that big language data are not only a challenge for language technology but also an opportunity for obtaining application-specific language models that can cope with the long tail of linguistic creativity. It is the challenge of our time to deal with our legacy: the immense amount of text published on the ever-growing World Wide Web. Combining scalable statistical models with \"smart\" rule-based approaches opens up a promising perspective on the possibility of creating a fine-granular, versatile-useful, provenance-aware, translingual knowledge graph with a range of applications. Hans Uszkoreit will explain existing applications and give an outlook on what we can expect from big \"smart\" data.


## Biography

Hans Uszkoreit serves as scientific director at the German Research Center for Artificial Intelligence (DFKI) where he heads the DFKI Language Technology Lab. He has more than 30 years of experience in language technology which are documented in more than 180 international publications. Uszkoreit is Coordinator of the European Network of Excellence
META-NET with 60 research centers in 34 countries and he leads several national and international research projects.

He is a co-founder of XtraMind Technologies GmbH, Saarbruecken (now part of attensity inc.), acrolinx gmbh, Berlin and Yocoy Technologies GmbH, Berlin. From 2005-2011, he served as Chairman of the Board of Directors of the international initiative dropping knowledge.

His current research interests are information extraction, atomatic translation and other advanced applications of language and knowledge technologies as well as computer models of human language understanding and production."""^^sysont:Markdown .

lswt2013:Kontakt site:content """# Kontakt
Das Organisationsteam des LSWT 2013 ist [über diese Email erreichbar](mailto:lswt-orga@informatik.uni-leipzig.de \"lswt-orga-2013@informatik.uni-leipzig.de\").

# News
Weiterhin können Sie sich in die [öffentliche Mailingliste](http://lists.informatik.uni-leipzig.de/mailman/listinfo/lswt-public \"öffentliche Mailingliste\") eintragen, um Updates zu erhalten

# Programm
* {{link r=\"people:SebastianHellmann\"}}
* {{link r=\"people:JoergUnbehauen\"}}
* {{link r=\"people:MichaelMartin\"}}

# Co-chairs
* {{link r=\"people:RicardoUsbeck\"}}
* {{link r=\"people:MohamedSherif\"}}

# Organisation und Pressekontakt

* {{link r=\"people:NadineJaenicke\"}}



# Site'n'Semantics

* {{link r=\"people:SebastianTramp\"}}
"""^^sysont:Markdown .

lswt2013:MinuteMadness eis:sideNavigation lswt2013:Menu ;
                       site:content """In the Minute Madness session, we present industry-relevant, mature projects as well as high-impact, bleeding-edge work-in-progress and thus giving an overview of the current state as well as recent trends in the Web of Data.

The beginning of the Minute Madness will consist of featured projects of AKSW members itself followed by an open session with participants of LSWT (lightning talk style). We invite the audience to submit lightning talks (~3min.) to the  [Orga-Team](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Kontakt \"Orga Team\"). Language can be English or German.

The AKSW group has acquired an international reputation through projects such as DBpedia, LOD2, OntoWiki, Catalogus Professorum and the NLP Interchange Format (NIF). We consider it our duty to disseminate this know-how in local sessions to the public and facilitate interesting discussion and feedback. The general philosophy of AKSW is to combine scientific excellence with real world business applications and use cases via open-source communities and ambitious software engineering.

### German Translation
In unserer Minute Madness präsentieren wir neben industrie-relevanten & ausgereiften Projekten auch den aktuellen Stand der Forschung und Trends im Web of Data.

Zu Beginn werden Mitarbeiter der AKSW Forschungsgruppe Projekte und Ansätze präsentieren, es ist aber auch auf jeden Fall noch Platz für ihre Idee oder Projekt, die im Sinne eines Lightning Talk vorgetragen werden kann (~3min).
Bei Interesse wenden Sie sich einfach an unser [Orga-Team](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Kontakt \"Orga Team\").


<table dir='ltr' border=0 cellpadding=0 cellspacing=0 class='tblGenFixed' id='tblMain'><tr class='rShim'><td class='rShim' style='width:0;'><td class='rShim' style='width:134px;'><td class='rShim' style='width:120px;'><td class='rShim' style='width:437px;'><td class='rShim' style='width:312px;'><tr dir='ltr'><td class=hd><p style='height:16px;'>.</td><td  dir='ltr' class='s0'>Name<td  dir='ltr' class='s1'>Title<td  dir='ltr' class='s1'>Abstract (300 chars or 3 sentences)<td  dir='ltr' class='s1'>URL</tr><tr dir='ltr'><td class=hd><p style='height:16px;'>.</td><td  class='s2'>Darya Tarasowa<td  dir='ltr' class='s3'>SlideWiki<td  dir='ltr' class='s3'>SlideWiki is a collaboration platform which enables communities to build, share and play online presentations. In addition to importing PowerPoint presentations, it supports authoring of interactive online slides using HTML and LateX. Slides and their containers (called Deck), are versioned thereby enabling change tracking. Users can create their own themes on top of existing themes or re-use other's themes.<td  dir='ltr' class='s3'><a target=\"_blank\" href=\"http://www.google.com/url?q=http://slidewiki.org/&usd=2&usg=ALhdy2_VlLK3AtFvNS20hhVEaiW3rNThdg\">http://slidewiki.org/</a></tr><tr dir='ltr'><td class=hd><p style='height:16px;'>.</td><td  dir='ltr' class='s4'>Natanael Arndt<td  dir='ltr' class='s3'>Xodx<td  dir='ltr' class='s3'>Xodx is a distributed semantic social network (DSSN) node implementation. It uses Semantic Pingback and PubSubHubbub with Activity Streams for communicating with other nodes of the social network. The setup is designed and tested to run on low-cost and weak hardware such as the FreedomBox.<td  dir='ltr' class='s3'><a target=\"_blank\" href=\"http://www.google.com/url?q=http://xodx.dssn.org/&usd=2&usg=ALhdy28-0ijBDcwjkygNbVS_tz6PdKjU9Q\">http://xodx.dssn.org/</a></tr><tr dir='ltr'><td class=hd><p style='height:16px;'>.</td><td  dir='ltr' class='s4'>Muhammad Saleem<td  dir='ltr' class='s3'>Cancer Genome Atlas (TCGA) tailored federated query processing and linking to Linked Open Data (LOD) Cloud.<td  dir='ltr' class='s3'> TopFed is a tailored federated query processing engine for Linked Cancer Genome Atlas (TCGA) data set (the largest LOD dataset, to the best of our knowledge). TopFed relies on a source selection algorithm that takes into account the data distribution and triple joins, which allows smart source selection, thus improving both execution time and network traffic. We evaluate and compare our approach with the state of the art approach, using a total of 10 queries with varying requirements. Our evaluation shows that our approach selects significantly fewer sources for the same recall and smaller execution time. <td  dir='ltr' class='s3'><a target=\"_blank\" href=\"http://www.google.com/url?q=https://code.google.com/p/topfed/&usd=2&usg=ALhdy29Tyv3soWBV5_MAe8rckceK_k9I8w\">https://code.google.com/p/topfed/</a></tr><tr dir='ltr'><td class=hd><p style='height:16px;'>.</td><td  dir='ltr' class='s4'>Ivan Ermilov<td  dir='ltr' class='s3'>LODStats<td  dir='ltr' class='s3'>This demo presents LODStats, a web application for collection and exploration of the Linked Open Data statistics. LODStats consists of two parts: the core collects statistics about the LOD cloud and publishes it on the LODStats web portal, a front-end for exploration of dataset statistics. Statistics are published both in human-readable and machine-readable formats, thus allowing consumption of the data through web front-end by the users as well as through an API by services and applications. As an example for the latter we showcase how to visualize the statistical data with the CubeViz application.<td  dir='ltr' class='s3'><a target=\"_blank\" href=\"http://www.google.com/url?q=http://stats.lod2.eu&usd=2&usg=ALhdy2_b4ZcTU3ymPb7vHcNY5jDzq4yftw\">http://stats.lod2.eu</a></tr><tr dir='ltr'><td class=hd><p style='height:16px;'>.</td><td  dir='ltr' class='s4'>Saeedeh Shekarpour<td  dir='ltr' class='s3'>SINA<td  dir='ltr' class='s3'>There is a large and increasing quantity of structured data available on the Web. Traditional information retrieval approaches based on keyword search are user-friendly but cannot exploit the internal structure of data due to their bag of words semantic. For searching information on the Data Web we need similar user friendly approaches i.e. keyword-base interfaces, which leverage the internal structure of the data. Also, Question Answering is a specialized form of information retrieval. A Question Answering system attempts to extract correct answers to questions posed in natural language. Using the structure of data in retrieval process has two prominent advantages. Firstly, it approaches the information retrieval systems to question answering systems. Secondly, it enables us to easily integrate information from different datasets.<td  dir='ltr' class='s3'><a target=\"_blank\" href=\"http://www.google.com/url?q=http://sina.eis.iai.uni-bonn.de/&usd=2&usg=ALhdy28isVI11IHlPWVuJIQ7kHw0-gPOew\">http://sina.eis.iai.uni-bonn.de/</a></tr><tr dir='ltr'><td class=hd><p style='height:16px;'>.</td><td  dir='ltr' class='s4'>Amrapali Zaveri<td  dir='ltr' class='s3'>TripleCheckMate<td  dir='ltr' class='s3'>TripleCheckMate is a tool for crowdsourcing the quality assessment of Linked Data wherein a user assesses an individual resource and evaluates each fact for correctness. Using this tool first, a user chooses a resource. Second, she is displayed with all triples belonging to that resources and evaluates each triple individually to detect quality problems. Third, If she finds a problem, she marks it and associates it with a relevant problem category.<td  dir='ltr' class='s3'><a target=\"_blank\" href=\"http://www.google.com/url?q=http://nl.dbpedia.org:8080/TripleCheckMate-Demo/&usd=2&usg=ALhdy28JcdUX4qBp7VOBExJ-fluocPJIeA\">http://nl.dbpedia.org:8080/TripleCheckMate-Demo/</a></tr><tr dir='ltr'><td class=hd><p style='height:16px;'>.</td><td  dir='ltr' class='s4'>Claus Stadler<td  dir='ltr' class='s3'>Facete<td  dir='ltr' class='s3'>Facete is an Open Source web application for faceted browsing of data accessible via SPARQL endpoints. It supports filtering of nested facets and the creation of tables. Based on the filters set by a user, Facete automatically detects relations to geographical resources for showing them on a map.<td  dir='ltr' class='s3'><a target=\"_blank\" href=\"http://www.google.com/url?q=https://github.com/GeoKnow/Facete/&usd=2&usg=ALhdy29I6EqGUcjQSejZemDYQA2qxRPFNA\">https://github.com/GeoKnow/Facete/</a></tr><tr dir='ltr'><td class=hd><p style='height:16px;'>.</td><td  dir='ltr' class='s4'>Denis Lukovnikov<td  dir='ltr' class='s3'>DBpedia Viewer<td  dir='ltr' class='s3'>This lightning talk presents the result of a Google Summer of Code project on DBpedia concerned with the creation of a user-friendly interface for RDF triples.  The DBpedia Viewer introduces several features to improve user experience, such as language filtering of page content and string filtering. Also, a triple action framework was created to easily bind actions to values. The DBpedia Viewer also provides a noscript version (almost identical to the old viewer), intended for noscript users and crawlers.(GSoC).<td  dir='ltr' class='s3'><a target=\"_blank\" href=\"http://www.google.com/url?q=http://nl.dbpedia.org/page/Chuck_Norris&usd=2&usg=ALhdy2_GfMuHGC5scTTqsaEm9gIaxxOJxw\">http://nl.dbpedia.org/page/Chuck_Norris</a></tr><tr dir='ltr'><td class=hd><p style='height:16px;'>.</td><td  dir='ltr' class='s4'>Mohamed Sherif<td  dir='ltr' class='s3'>GeoLift<td  dir='ltr' class='s3'>GeoLift is a spatial mapping component. The goal of GeoLift is to enrich RDF datasets with geo-spatial information. To achieve this goal, GeoLift relies on three atomic modules based on dereferencing, linking and NLP.<br/><br/><td  dir='ltr' class='s3'><a target=\"_blank\" href=\"http://www.google.com/url?q=https://github.com/GeoKnow/GeoLift/&usd=2&usg=ALhdy29fNuR1vSYExdUHIF5fSidHh4Y4WQ\">https://github.com/GeoKnow/GeoLift/</a></tr><tr dir='ltr'><td class=hd><p style='height:16px;'>.</td><td  dir='ltr' class='s4'>Farshad Badie<td  dir='ltr' class='s3'>Fuzzy OWL EXpression (For Intelligent Learning Based on Semantic Web)<td  dir='ltr' class='s3'> Inductive logic programming approach to learning inclusion axioms in fuzzy description logics, reasoning with large A-boxes in fuzzy description logics using DL reasoners,fuzzy knowledge representation approach with DL and LP fuzzy DL approach to model management systems and Representing and finally Reasoning on Fuzzy UML models are the main approaches of our supposed system.<td  class='s5'></tr></table>"""^^sysont:Markdown .

lswt2013:Sponsoring site:content """Gern können Sie sich als Sponsor am LSWT beteiligen. Wir bieten insgesamt drei Sponsoring-Pakete an, mit denen Sie Ihr Unternehmen auf dem LSWT präsentieren können. Bei Interesse wenden Sie sich bitte an das [Orga-Team](Kontakt)

{{toc tag=\"ul\" depth=\"3\"}}

# Gold-Sponsor für €3.000

* Gold Sponsoren sind Hauptsponsoren des LSWT und werden überall an prominenter Stelle genannt (z.B. Pressemitteilungen, Blogposts, CfP)
* Verlinkung des Sponsors auf der Tagungswebseite (an prominenter Stelle)
* Kostenfreie Registrierung von _sechs_ Personen für die Tagung, das Tutorial und den Festabend. Das ergibt eine Ersparnis von 1200 Euro an Tickets.
* 10 m² kostenfreie Ausstellungsfläche mit Wahl der Lage (inkl. Tisch für Demonstrationen)
* Beilage von Informationsmaterial (Flyer oder Aufkleber) in den offiziellen Tagungsunterlagen der Teilnehmer
* Wir bieten die Möglichkeit kostenfrei großflächige, durch den Sponsor bereitgestellte Plakate oder Banner aufzuhängen (z.b. am Eingang der Konferenz und in den Veranstaltungsräumen)

# Silber-Sponsor für €1.500

* Verlinkung des Sponsors auf der Tagungswebseite
* Kostenfreie Registrierung von _drei_ Personen für die Tagung, das Tutorial und den Festabend. Das ergibt eine Ersparnis von 600 Euro an Tickets.
* 5 m² kostenfreie Ausstellungsfläche mit Wahl der Lage (inkl. Tisch für Demonstrationen)
* Beilage von Informationsmaterial (Flyer oder Aufkleber) in den offiziellen Tagungsunterlagen der Teilnehmer

# Bronze-Sponsor für €500

* Verlinkung des Sponsors auf der Tagungswebseite
* Kostenfreie Registrierung von _einer_ Personen für die Tagung, das Tutorial und den Festabend. Das ergibt eine Ersparnis von 200 Euro an Tickets.
* Der Sponsor hat weiterhin die Wahl zwischen:
   * a) Präsentation eines Posters (kostenfreier Platz an einer Posterstellwand)
   * b) Beilage von Informationsmaterial (kleiner Flyer oder Aufkleber) in den offiziellen Tagungsunterlagen der Teilnehmer

# Details
Hier finden Sie einige Details zu den Paketen. Gerne nehmen wir auch Ihre individuellen Wünsche und Fragen entgegen.
Bei Interesse wenden Sie sich bitte an das [Orga-Team](Kontakt)

Die Sponsoren werden auf der Kongresswebseite und im Programm je nach Leistungsumfang mit Logo aufgeführt. Bitte schicken Sie Ihr Firmenlogo, im Illustrationsformat, .jpg (300 dpi) und .eps, sowohl in schwarz-weiß als auch in Farbe zusammen mit der entsprechenden Link-Adresse an das Organisationsteam. Die Posterstellwand für das Bronze Paket kann ein DinA0 Poster aufnehmen.

In den Stand- bzw. Flächenpreisen sind enthalten:

* Stromanschluss 220V/16A, Energiekosten
* Internet- und W-Lan-Zugang
* Vor-Ort-Service des Veranstalters
* Posterwand"""^^sysont:Markdown .

lswt2013:Tutorien site:content """Erste Erfahrungen mit dem Semantic Web und Linked Data
==================
Das zweiteilige Tutorial (2*2 Sessions) richtet sich an Entwickler und Administratoren, die bereits gute Kenntnisse in anderen Bereichen der Informatik besitzen und einen Einstieg in die W3C Technologien rund um Linked Data finden wollen. Der erste Teil \"Grundlagen des Semantic Web und Linked Data\" vermittelt praktisches Wissen zu den Best Practices und Standards des Daten Webs. Der zweite Teil dient zur Vertiefung durch den übenden Einsatz der Eccenca Linked Data Suite, welche die im ersten Teil vorgestellten W3C Standards und Best Practices implementiert.

Content Analysis and the Semantic Web
=====================================
**Details in English are available below in the Calendar View**

In dem Tutorial (3 Sessions) für Fortgeschrittene stellen Feiyu Xu (DFKI), Sebastian Hellmann (AKSW) und andere Mitglieder der AKSW Gruppe die neuesten Technologien zur Überbrückung der Lücke zwischen natürlichsprachigen Text und Wissensdatenbanken vor. Im Anschluß findet eine interaktive Session statt in der Teilnehmer Lightning Talks mit Use Cases, Produkten und Problemen vorstellen können und dann gemeinsam in einer Diskussion Best Practices vermittelt werden, bzw. erarbeitet werden, falls es noch keine gibt.


Genauer Zeitplan
================

<iframe id=\"lswtcal\" src=\"http://docs.eis.iai.uni-bonn.de/lswt2013/day.php?getdate=20130924\" frameborder=\"0\" width=\"100%\" height=\"800\"><p>Diese Seite benötigt die Unterstützung von Frames durch Ihren Browser.</p></iframe>"""^^sysont:Markdown .

people:FabrizioOrlandi a foaf:Person ;
                       rdfs:label "Fabrizio" ;
                       rdfs:seeAlso <http://www.deri.ie/user/385/foaf.xml> ;
                       owl:sameAs <http://www.deri.ie/users/fabrizio-orlandi> ;
                       skos:prefLabel "Dr. Fabrizio Orlandi" ;
                       foaf:name "Fabrizio Orlandi" ;
                       foaf:currentProject projects:Linda, projects:WDAqua_ITN, projects:ODINE ;
                       foaf:depiction <https://dl.dropboxusercontent.com/u/1490985/profile2013.png> ;
                       foaf:mbox <mailto:orlandi@iai.uni-bonn.de> ;
                       foaf:phone <tel:+49228734504> ;
                       foaf:familyName "Orlandi" ;
                       eis:room "A119" .

people:Farah_Karim a foaf:Person ;
                   rdfs:label "Farah Karim" ;
                   foaf:name "Farah Karim" ;
                   skos:hiddenLabel "Farah Karim" ;
                   foaf:currentProject projects:OpenAIRE2020 ;
                   foaf:depiction <http://www.sessionlogs.com/media/icons/defaultIcon.png> ;
                   foaf:mbox <mailto:10msitfkarim@seecs.edu.pk> ;
                   foaf:phone <tel:+4915218815243> ;
                   foaf:familyName "Karim" ;
                   eis:room "A110a" .

people:FarshadBadie dcterms:description """With my respect to Rationalism in human's life, I believe humans may not necessarily be right and logical in the way they judge things and make decisions. I believe that an external reasoning system preferably with semantic nature, could be supposed to have the ability of guiding humans to a more knowledgeable judgment and Decision Making.

**My Research interests are**:

- Ontology Engineering, Fuzzy Ontology Engineering

-  Description Logic, Fuzzy Description Logic

-  OWL / Fuzzy OWL Class Expression

-  Machine Learning

-  Semantic Intelligence in Ontology Learning
"""^^sysont:Markdown .

people:Goekhan_Coskun a foaf:Person ;
                      rdfs:label "Dr. Gökhan Coskun" ;
                      skos:prefLabel "Dr. Gökhan Coskun" ;
                      foaf:name "Gökhan Coskun" ;
                      foaf:homepage <http://www.coskun.org/gokhan> ;
                      foaf:depiction <https://media.licdn.com/mpr/mpr/shrinknp_200_200/p/1/000/106/324/2a24fed.jpg> ;
                      foaf:mbox <mailto:coskun@iai.uni-bonn.de> .

groups:EIS a aiiso:ResearchGroup ;
           rdfs:label "Enterprise Information Systems" ;
           site:abbrevation "EIS" ;
           foaf:member people:ChristophLange, people:Saleh_Alkarabubi, people:JudieAttard, people:Kemele_M_Endris, people:Lavdim, people:Mohamed_Nadjib_Mami, people:AlanTygel, people:Farah_Karim, people:Diego_Collarana, people:DaryaTarasowa, people:SarvenCapadisli, people:SoerenAuer, people:SaeedehShekarpour, people:JyunYao_Huang, people:Goekhan_Coskun, people:Irlan, people:DietlandZuehlke, people:SidraFaisal, people:StefanLuettringhausKappel, people:NiklasPetersen, people:JeremyDebattista, people:Michael_Galkin, people:SimonScerri, people:FabrizioOrlandi, people:NataljaFriesen, people:KlaudiaThellmann, people:SaharVahdati .

people:HansUszkoreit site:content """Hans Uszkoreit serves as scientific director at the German Research Center for Artificial Intelligence (DFKI) where he heads the DFKI Language Technology Lab. He has more than 30 years of experience in language technology which are documented in more than 180 international publications. Uszkoreit is Coordinator of the European Network of Excellence META-NET with 60 research centers in 34 countries and he leads several national and international research projects.

He is a co-founder of XtraMind Technologies GmbH, Saarbruecken (now part of attensity inc.), acrolinx gmbh, Berlin and Yocoy Technologies GmbH, Berlin. From 2005-2011, he served as Chairman of the Board of Directors of the international initiative dropping knowledge.

His current research interests are information extraction, atomatic translation and other advanced applications of language and knowledge technologies as well as computer models of human language understanding and production."""^^sysont:Markdown .

people:Imprint site:content """<nav class=\"nav-sidelinks\">
<ul>
<li><strong class=\"headline\">current funded projects</strong>
{{query where=\"?resourceUri a eis:FundedProject. OPTIONAL { ?resourceUri eis:status ?status }  FILTER (?status != 'finished')\" template=\"liplain\"}}
</li>
<li><strong class=\"headline\">featured projects</strong>
{{query where=\"?resourceUri eis:promoted 'true'^^xsd:boolean.\" template=\"liplain\"}}
</li>
</nav>

**Prof. Dr. Sören Auer**

Telefon: [+49 228 73-7816](tel:+49228737816)<br />
Telefax: [+49 228 73-4382](tel:+49228734382)<br />
E-Mail: [auer@cs.uni-bonn.de](mailto:auer@cs.uni-bonn.de)

    Enterprise Information Systems department,
    Institut für Informatik III,
    Rheinische Friedrich-Wilhelms-Universität Bonn,
    Römerstraße 164,
    53117 Bonn,
    Germany

Die Universität Bonn ist eine Körperschaft des öffentlichen Rechts. Sie wird vertreten durch den Rektor. Weitere Informationen, insbesondere zur Aufsichtsbehörde, finden sich im [Impressum der Universität Bonn](http://www3.uni-bonn.de/impressum).


# Haftungshinweis

## Haftung für Inhalte
Wir bemühen uns die Inhalte unserer Seite aktuell zu halten. Trotz sorgfältiger Bearbeitung bleibt eine Haftung ausgeschlossen.

Als Diensteanbieter sind wir gemäß § 7 Abs.1 TMG für eigene Inhalte auf diesen Seiten nach den allgemeinen Gesetzen verantwortlich.

Nach §§ 8 bis 10 TMG sind wir als Diensteanbieter jedoch nicht verpflichtet, übermittelte oder gespeicherte fremde Informationen zu überwachen. Bei bekannt werden von Rechtsverletzungen, werden wir diese Inhalte umgehend entfernen. Eine diesbezügliche Haftung übernehmen wir erst ab dem Zeitpunkt der Kenntnis einer möglichen Rechtsverletzung.

## Haftung für Links
Unser Angebot enthält Links zu externen Webseiten Dritter, auf deren Inhalte wir keinen Einfluss haben. Für die Inhalte der verlinkten Seiten ist stets der jeweilige Anbieter oder Betreiber der Seiten verantwortlich. Für die Inhalte und die Richtigkeit der Informationen verlinkter Websites fremder Informationsanbieter wird keine Gewähr übernommen.

Die verlinkten Seiten wurden zum Zeitpunkt der Verlinkung auf mögliche Rechtsverstöße OHNE BEANSTANDUNG überprüft. Bei bekannt werden von Rechtsverletzungen werden wir derartige Links umgehend entfernen.

## Urheberrecht
Die durch die Seitenbetreiber erstellten Inhalte und Werke auf diesen Seiten unterliegen dem deutschen Urheberrecht. Die Vervielfältigung, Bearbeitung, Verbreitung und jede Art der Verwertung außerhalb der Grenzen des Urheberrechtes bedürfen der schriftlichen Zustimmung des jeweiligen Autors bzw. Erstellers.

## Datenschutz
Wir weisen darauf hin, dass die Datenübertragung im Internet (z.B. bei der Kommunikation per E-Mail) Sicherheitslücken aufweisen kann. Ein lückenloser Schutz der Daten vor dem Zugriff durch Dritte ist nicht möglich. Eine Vertraulichkeit im Hinblick auf die Datenschutzbestimmungen wird nur unter der vorstehenden Einschränkung gewährleistet. Insbesondere sollen alle Mitteilungen von personenbezogenen Daten über das Internet nur erfolgen, soweit nicht Rechte Dritter berührt werden. Es sei denn der Dritte hat in Kenntnis der vorstehenden Sicherheitslücken ebenfalls seine Zustimmung erklärt. Eine Haftung des Seitenbetreibers wird für die durch solche Sicherheitslücken entstehenden Schäden oder Unterlassungsansprüche ausgeschlossen.

Der Nutzung von allen veröffentlichten Kontaktdaten durch Dritte zur Übersendung von nicht ausdrücklich angeforderter Werbung wird widersprochen. Die Betreiber der Seiten behalten sich ausdrücklich rechtliche Schritte im Falle der unverlangten Zusendung von Werbeinformationen, etwa durch Spam-Mails, vor.

**Quelle: S&K Rechtsanwälte [www.streifler.de](http://www.streifler.de/)**

# Gestaltung

* [Maxi Bley . www.bleystift.de](http://bleystift.de) - Screendesign
* [Michael Haschke - 48augen Webentwicklung](http://48augen.de) - Umsetzung HTML/CSS"""^^sysont:Markdown .

people:Internal rdfs:label "Internal" ;
                dcterms:description "This is a description"^^sysont:Markdown .

people:Irlan a foaf:Person ;
             rdfs:label "Irlan Grangel-González" ;
             skos:prefLabel "Irlan Grangel-González" ;
             foaf:name "Irlan Grangel-González" ;
             foaf:currentProject projects:LUCID ;
             foaf:depiction <https://lh4.googleusercontent.com/-kUk1n0yC4z4/VO3W4PHPWVI/AAAAAAAAAOA/UkMTUXvgwj4/s520-no/mine.jpg> ;
             foaf:mbox <mailto:grangel@iai.uni-bonn.de> ;
             foaf:familyName "Grangel-González" .

people:JeremyDebattista a foaf:Person ;
                        skos:prefLabel "Jeremy Debattista" ;
                        foaf:name "Jeremy Debattista" ;
                        site:templateOption "extended" ;
                        foaf:currentProject projects:Diachron ;
                        foaf:depiction <https://media.licdn.com/media/p/2/000/0de/2b9/2d30505.jpg> ;
                        foaf:mbox <mailto:jeremy.debattista@iais-extern.fraunhofer.de>, <mailto:debattist@informatik.uni-bonn.de> ;
                        foaf:familyName "Debattista" ;
                        eis:publicationTag "debattista" ;
                        eis:room "A110a" .

people:Jobs site:content """**Fraunhofer IAIS hiring a PhD student in the field of data analysis, machine learning, Linked Data, crime analysis**

Please note that this job requires excellent German skills. If you do not know German on an excellent level, we will not consider your application. Note, however, that we may soon advertise similar jobs that do not require German skills.
For full details, see [this job posting](https://www.daad.de/deutschland/promotion/phd/en/13306-phdgermany-database/?promotiontype=&subject=5384&workinglang=&town=&paid=&page=2&sorting=created&detail=424).

[//]: # (**3+2 full time PhD students in the field of question answering on interlinked datasets**)
[//]: # ()
[//]: # (The EIS group is seeking 5 PhD students, to be employed in the Marie Skłodowska-Curie Innovative Training Network WDAqua (Answering Questions using Web Data).  Three of them will be employed at the University of Bonn, two at Fraunhofer IAIS.  They will work closely together.  Please see [the project's homepage](http://www.iai.uni-bonn.de/~langec/wdaqua/) for [further details](http://www.iai.uni-bonn.de/~langec/wdaqua/#partners) and for [how to apply](http://www.iai.uni-bonn.de/~langec/wdaqua/#apply).)
[//]: # ()
[//]: # (<h2>**One or more Post-doctoral Researcher / Research Group Leader**</h2><p><strong>What we are looking for:</strong>)
[//]: # ( The ideal candidate holds a doctoral degree in Computer Science or a )
[//]: # (related field and is able to combine theoretical and practical aspects )
[//]: # (in her work. The candidate is expected to build up her own research )
[//]: # (group and should have a track record in at least three (and be committed to expand it to more) of the following areas:</p><ul><li><em>publication of research results</em> in renowned, peer-reviewed journals and conferences of her field</li><li><em>proven software engineering skills</em> and the ability to develop mature software components beyond pure research prototypes</li><li><em>successful supervision</em> of bachelor, master and doctoral students</li><li><em>close collaboration</em>)
[//]: # ( with other research groups, industry, NGOs as well as open-source and )
[//]: # (community initiatives, for example, in the context of publicly funded )
[//]: # (collaborative research projects</li><li><em>successfully competing</em> for funding by national and international funding bodies</li><li><em>transfer and commercialization of research results</em>, for example, through open-source software, contractual research and development for industry, licensing, spin-off companies,</li></ul><p>Due)
[//]: # ( to the strong affiliation with Fraunhofer IAIS particular emphasis will)
[//]: # ( be on the successful transfer of research results into high-impact )
[//]: # (industrial and societal applications. Fluent English communication )
[//]: # (skills are a fundamental requirement. As of October 2014 we )
[//]: # (are primarily seeking one post-doctoral researcher <strong>fluent in)
[//]: # ( German</strong> but we also have limited opportunities to support very strong candidates in applying for a fellowship with us (see below). Still, German skills are always a plus.<br></p><p><strong>Fields:</strong> The candidate should have a background in field relevant for Enterprise Information Systems, such as:</p><ul><li>semantic web technologies and linked data</li><li>knowledge representations and ontology engineering</li><li>software engineering and modern application development</li><li>database technologies and data integration</li><li>HCI and user interface design for Web content</li><li>data analytics<br></li></ul><p><strong>What we offer:</strong> We provide an scientifically and intellectually inspiring environment with an entrepreneurial mindset embedded in a <a href=\"http://en.wikipedia.org/wiki/University_of_Bonn#Ranking\" data-mce-href=\"http://en.wikipedia.org/wiki/University_of_Bonn#Ranking\">world-leading university</a> and one of the <a href=\"http://en.wikipedia.org/wiki/Fraunhofer_Society\" data-mce-href=\"http://en.wikipedia.org/wiki/Fraunhofer_Society\">largest research organizations</a>. Our primary aim is to provide the environment and resources to make the research group leaders successful in their field.  <a href=\"/Environment.html\">(See more about the research environment and quality of life.)</a></p><ul><li>Research group leaders will have initially one or two PhD student positions assigned.</li><li>There)
[//]: # ( is initial funding available for equipment, conference and research )
[//]: # (visit travel and all costs required for a successful build-up of the )
[//]: # (research group.</li><li>A portfolio of technology components to build )
[//]: # (on, including the <a href=\"http://eis-bonn.github.io/Luzzu/\">Luzzu</a> data quality assessment framework and further )
[//]: # (components created by Sören's former research group AKSW including <a href=\"http://dbpedia.org\" data-mce-href=\"http://dbpedia.org\">DBpedia, </a><a href=\"http://linkedgeodata.org\" data-mce-href=\"http://linkedgeodata.org\">LinkedGeoData</a>, <a href=\"http://ontowiki.net\" data-mce-href=\"http://ontowiki.net\">OntoWiki</a>, <a href=\"http://persistence.uni-leipzig.org/nlp2rdf/\" data-mce-href=\"http://persistence.uni-leipzig.org/nlp2rdf/\">NLP Interchange Format</a>, <a href=\"http://rdface.aksw.org\" data-mce-href=\"http://rdface.aksw.org\">RDFaCE</a>, <a href=\"http://slidewiki.org\" data-mce-href=\"http://slidewiki.org\">SlideWiki</a> etc.</li><li>With <a href=\"http://diachron-fp7.eu\" data-mce-href=\"http://diachron-fp7.eu\">DIACHRON - Managing the Evolution and Preservation of the Data Web</a> and <a href=\"http://linda-project.eu\" data-mce-href=\"http://linda-project.eu\">LinDa - Enabling Linked Data and Analytics for SMEs by renovating public sector information</a> the group starts right away, with two important research projects with leading international partners funded by the EU FP7</li><li>Qualified candidates will start initially in level <a href=\"http://oeffentlicher-dienst.info/c/t/rechner/tv-l/west?id=tv-l&g=E_14&s=2&zv=keine&z=100&zulage=&stj=2013&stkl=1&r=0&zkf=&kk=15.5%25\" data-mce-href=\"http://oeffentlicher-dienst.info/c/t/rechner/tv-l/west?id=tv-l&g=E_14&s=2&zv=keine&z=100&zulage=&stj=2013&stkl=1&r=0&zkf=&kk=15.5%25\">TV-L 14 of the German public service pay-scale</a>)
[//]: # ( (approx. 2.200–2.900 € net monthly salary depending on experience including all German social benefits) with the option to be quickly )
[//]: # (promoted.</li></ul><p>The positions start as soon as possible, are open )
[//]: # (until filled (for full consideration please apply until November 7) and will)
[//]: # ( be granted initially for 2 years with envisioned extension.</p>)
[//]: # (<p><strong>How to apply:</strong>)
[//]: # ( Please indicate your willingness to apply as soon as possible with a )
[//]: # (short email and send your CV, two publications, 1–2 letters of reference)
[//]: # ( and a two pages motivational statement (incl. research, funding and transfer ambitions) to <a href=\"mailto:eis-leaders@lists.iai.uni-bonn.de\" data-mce-href=\"mailto:eis-leaders@lists.iai.uni-bonn.de\">eis-leaders@lists.iai.uni-bonn.de</a>. We also always happy to support strong candidates in applying for <a href=\"http://ec.europa.eu/research/participants/portal/desktop/en/opportunities/h2020/calls/h2020-msca-if-2015.html\">Marie Skłodowska Curie Individual Fellowships (MSCA-IF; next deadline 9 September 2015)</a> or <a href=\"https://fellowship.ercim.eu/\">ERCIM Alain Bensoussan Fellowships (deadlines 30 April and 30 September)</a>.)
[//]: # ( If you are interested and eligible for such a fellowship, please also send the)
[//]: # ( same information to the same address well before the deadline.<br></p>)
"""^^sysont:Markdown .

people:JudieAttard a foaf:Person ;
                   skos:prefLabel "Judie Attard" ;
                   foaf:name "Judie Attard" ;
                   site:templateOption "extended" ;
                   foaf:currentProject projects:Linda ;
                   foaf:depiction <https://dl.dropboxusercontent.com/u/5895290/ubonn_photos/judie.png> ;
                   foaf:mbox <mailto:attard@informatik.uni-bonn.de>, <mailto:judie.attard@iais-extern.fraunhofer.de> ;
                   foaf:familyName "Attard" ;
                   eis:publicationTag "attard" ;
                   eis:room "A110a" .

people:JyunYao_Huang a foaf:Person ;
                     rdfs:label "Jyun-Yao Huang" ;
                     skos:prefLabel "Jyun-Yao Huang" ;
                     foaf:name "Jyun-Yao Huang" ;
                     foaf:homepage <http://blog.allenworkspace.net> ;
                     foaf:currentProject projects:OpenAIRE2020 ;
                     foaf:depiction <http://www.allenworkspace.net/Profile.jpg> ;
                     foaf:mbox <mailto:allen501pc@gmail.com> ;
                     foaf:familyName "Huang" ;
                     eis:room "A110a" .

people:Kemele_M_Endris a foaf:Person ;
                       rdfs:label "Kemele M. Endris" ;
                       owl:sameAs <https://www.linkedin.com/in/keme686>, <https://twitter.com/KemeleM> ;
                       skos:prefLabel "Kemele M. Endris" ;
                       foaf:name "Kemele" ;
                       skos:hiddenLabel "Kemele Muhammed Endris" ;
                       foaf:currentProject projects:Linda ;
                       foaf:depiction <https://lh3.googleusercontent.com/-uTRBYDJh5A0/T7EAgQDbK_I/AAAAAAAAAG8/Lyv0h7ItozM/s577-no/j.jpg> ;
                       foaf:mbox <mailto:endris@cs.uni-bonn.de> ;
                       foaf:familyName "Endris" ;
                       eis:room "A119" .

people:KlaudiaThellmann a foaf:Person ;
                        skos:prefLabel "Klaudia Thellmann" ;
                        foaf:name "Klaudia Thellmann" ;
                        site:templateOption "extended" ;
                        foaf:currentProject projects:Linda ;
                        foaf:depiction <https://dl.dropboxusercontent.com/u/5895290/ubonn_photos/klaudia.png> ;
                        foaf:mbox <mailto:klaudia.thellmann@iais.fraunhofer.de> ;
                        foaf:phone <tel:+49-(0)-2241-14-2451> ;
                        foaf:familyName "Thellmann" ;
                        eis:room """B3-212 Fraunhofer IAIS/UBONN
Schloss Birlinghoven
53754 Sankt Augustin, Germany
""" .

people:Lavdim a foaf:Person ;
              rdfs:label "Lavdim Halilaj" ;
              foaf:currentProject projects:LUCID, projects:VoCol ;
              foaf:depiction <https://lh4.googleusercontent.com/-CpFaKPUN2IA/VO2RcI4RB8I/AAAAAAAAAH4/rI4CFDmB5Oc/w1011-h1015-no/IMG_20141111_130535.jpg> ;
              foaf:mbox <mailto:halilaj@iai.uni-bonn.de> ;
              foaf:familyName "Halilaj" .

people:Michael_Galkin a foaf:Person ;
                      rdfs:label "Michael Galkin" ;
                      skos:prefLabel "Michael Galkin" ;
                      foaf:name "Michael" ;
                      foaf:currentProject projects:Linda ;
                      foaf:depiction <https://lh5.googleusercontent.com/-xIRPKH7PQCo/UyYRNMKa58I/AAAAAAAAAJM/mhu6Q9HpHUo/w278-h280-p/1.jpg> ;
                      foaf:mbox <mailto:galkin@eis.iai.uni-bonn.de> ;
                      foaf:familyName "Galkin" .

people:MohamedMorsey site:content """Awards and Honours
==================
1. **Best research paper award at The 10th  International Semantic Web Conference (ISWC2011)**, for paper “DBpedia SPARQL Benchmark – Performance Assessment with Real Queries on Real Data”.
2. **Spotlight paper at The 11th  International Semantic Web Conference (ISWC2012)**, for paper “DeFacto - Deep Fact Validation”.
3. **Outstanding paper award at The Electronic Library and Information Systems Journal**, for paper “DBpedia and the Live Extraction of Structured Data from Wikipedia”.

Research Interests
==================
- Semantic Web.
- Ontology engineering.
- Object oriented analysis and design.
- Computer viruses."""^^sysont:Markdown .

people:Mohamed_Nadjib_Mami a foaf:Person ;
                           rdfs:label "Mohamed Nadjib Mami" ;
                           foaf:name "Mohamed Nadjib Mami" ;
                           skos:hiddenLabel "MohamedNadjibMami" ;
                           foaf:currentProject projects:BigDataEurope ;
                           foaf:depiction <https://fascww.bn1301.livefilestore.com/y2pH-PcQZXW5XDUFfVyvh5izNG7xejz9PkfnLLKaW4ztbUox0x7IQAdxKVi3c3XwitM5GdihgEd0j-uTMN3uaAVTxs707ep_C4ZnGJtcQa2_xyiLZ4-YfpEP4WybkPA7-CZ0kIZKAX0kALzTs7sxw6kuw/Profile3.jpg?psid=1> ;
                           foaf:mbox <mailto:mami@iai.uni-bonn.de> ;
                           foaf:familyName "Mami" ;
                           eis:room "A119" .

people:NataljaFriesen a foaf:Person ;
                      rdfs:label "Natalja Friesen" ;
                      skos:prefLabel "Natalja Friesen" ;
                      foaf:currentProject people:Diachron ;
                      foaf:depiction <https://dl.dropboxusercontent.com/u/5895290/ubonn_photos/natalja.png> ;
                      foaf:mbox <mailto:natalja.friesen@iais-extern.fraunhofer.de>, <mailto:friesenn@informatik.uni-bonn.de> ;
                      foaf:phone <tel:02241-14-2788> ;
                      foaf:familyName "Friesen" ;
                      eis:room "A118" .

<http://eis.iai.uni-bonn.de/Navigation/Main> a site:Navigation ;
                                             rdf:_1 people:About ;
                                             rdf:_2 people:Team ;
                                             rdf:_3 people:Projects ;
                                             rdf:_4 people:Publications ;
                                             rdf:_5 people:Jobs ;
                                             rdfs:label "Main Navigation" ;
                                             rdf:_6 people:Events ;
                                             rdf:_7 people:Presentations ;
                                             rdf:_8 people:Teaching ;
                                             rdf:_9 people:Partners ;
                                             rdf:_10 people:Environment .

<http://eis.iai.uni-bonn.de/Navigation/Top> a site:Navigation ;
                                            rdf:_1 people:Contact ;
                                            rdf:_2 people:blog ;
                                            rdf:_3 people:Internal ;
                                            rdf:_4 people:Imprint ;
                                            rdfs:label "Top Navigation" .

people:NiklasPetersen a foaf:Person ;
                      skos:prefLabel "Niklas Petersen" ;
                      foaf:name "Niklas Petersen" ;
                      skos:hiddenLabel "NiklasPetersen" ;
                      foaf:currentProject projects:VoCol ;
                      foaf:depiction <https://media.licdn.com/mpr/mpr/shrinknp_200_200/AAEAAQAAAAAAAADyAAAAJDNiYmM2M2NjLTFhZTItNDAxMi05N2NiLWU5ZjRjZTExZTJhZA.jpg> ;
                      foaf:mbox <mailto:petersen@cs.uni-bonn.de> ;
                      foaf:familyName "Petersen" .

people:NotFound site:content """
Either the resource you are trying to reach is not available anymore on this server, or you have tried to access a 'dead' link.
"""^^sysont:Markdown .

ns16:AgetoAG dcterms:abstract """AGETO is an IT consultancy for web-based business processes. Since 10 years prestigious clients in the retail, logistics, high-tech and automotive industry rely on our expertise in e-commerce, SAP and JAVA consulting and implementation services. Under the slogan \"Better E-Business\" we take responsibility for an integrated consulting approach to implement IT systemsand processes along the entire supply chain. We streamline process cycle times and costs and put the user in the center of our efforts.

With our solution suite to use the German ID cardas online authorization tool, we are an innovative leader in e-security and electronic signature space.""" .

ns16:CESSDA_AS a foaf:Organization, eis:Partner ;
               rdfs:label "CESSDA AS" ;
               foaf:homepage <http://www.cessda.net/index.html> ;
               foaf:logo <http://jobs.euractiv.com/files/cessda_logo.png> .

ns16:Centre_for_Renewable_Energy_Sources_and_Saving a foaf:Organization, eis:Partner ;
                                                    rdfs:label "Centre for Renewable Energy Sources and Saving" ;
                                                    foaf:homepage <http://www.cres.gr/kape/index_eng.htm> ;
                                                    foaf:logo <http://www.cres.gr/kape/images/top1_1.gif> .

ns16:European_Union_Satellite_Centre a foaf:Organization, eis:Partner ;
                                     rdfs:label "European Union Satellite Centre" ;
                                     foaf:homepage <http://www.satcen.europa.eu/> ;
                                     foaf:logo <http://www.satcen.europa.eu/templates/eusc_800/images/logo.gif> .

ns16:Food_and_Agriculture_Organization_of_the_United_Nations a foaf:Organization, eis:Partner ;
                                                             rdfs:label "Food and Agriculture Organization of the United Nations" ;
                                                             foaf:homepage <http://www.fao.org/home/en/> ;
                                                             foaf:logo <http://www.fao.org/fileadmin/templates/faoweb/images/FAO-logo.png> .

ns16:Implisense_GmbH a foaf:Organization, eis:Partner ;
                     rdfs:label "Implisense GmbH" ;
                     foaf:logo <http://lucid-project.org/media/images/pages/logo-implisense.png.jpg> .

ns16:Infineon_Technologies_AG a foaf:Organization ;
                              rdfs:label "Infineon Technologies AG" ;
                              foaf:logo <http://lucid-project.org/media/images/pages/logo-infineon.png.jpg> .

ns16:InstitutFuerHochschulforschungWittenberg dcterms:abstract """HoF Halle-Wittenberg is the only Institute in East Germany which carries out research on higher education. Although this implies a particular thrust for its projects and services, the Institute’s approach is not restricted to analyses of regional developments.

Established in 1996, HoF Halle-Wittenberg has gone on from a predecessor: from 1991 until 1996, the \"Projektgruppe Hochschulforschung Berlin-Karlshorst\" documented and analysed the restruc-turing of the East German higher education system.

The Institute for Research on Higher Education Halle-Wittenberg is funded jointly by the Federal Government and the State of Saxony-Anhaltine. Legally it is an associated research institute of Martin Luther University Halle-Wittenberg.""" .

ns16:Institut_fuer_Angewandte_Informatik_e_V a foaf:Organization, eis:Partner ;
                                             rdfs:label "Institut für Angewandte Informatik e. V." ;
                                             foaf:homepage <http://infai.org/de/Aktuelles> ;
                                             foaf:logo <http://infai.org/themes/infai2007/layout/logo-infai.png> .

ns16:National_Centre_for_Scientific_Research_Demokritos a foaf:Organization, eis:Partner ;
                                                        rdfs:label "National Centre for Scientific Research ‘Demokritos’" ;
                                                        foaf:homepage <http://www.demokritos.gr/?lang=en> ;
                                                        foaf:logo <http://www.conops.gr/wp-content/uploads/logodemokritosen.jpg> .

ns16:National_and_Kapodistrian_University_of_Athens a foaf:Organization, eis:Partner ;
                                                    rdfs:label "National and Kapodistrian University of Athens" ;
                                                    foaf:homepage <http://en.uoa.gr/> ;
                                                    foaf:logo <http://excellence.minedu.gov.gr/thales/sites/default/files/ekpalogo%20en.png> .

ns16:Open_Data_Institute a foaf:Organization, eis:Partner ;
                         rdfs:label "Open Data Institute" ;
                         foaf:homepage <http://opendatainstitute.org/> ;
                         dcterms:abstract "The Open Data Institute (ODI) is a non-profit private company limited by guarantee, based in the United Kingdom. It is catalysing the evolution of open data culture to create economic, environmental, and social value. It helps unlock supply, generates demand, creates and disseminates knowledge to address local and global issues." .

ns16:Open_PHACTS_Foundation_LBG a foaf:Organization, eis:Partner ;
                                rdfs:label "Open PHACTS Foundation LBG" ;
                                foaf:homepage <http://www.openphactsfoundation.org/> ;
                                foaf:logo <http://www.openphactsfoundation.org/wp/wp-content/uploads/2014/07/OPF_logo_med1.png> .

ns16:Semantic_Web_Company_GmbH a foaf:Organization, eis:Partner ;
                               rdfs:label "Semantic Web Company GmbH" ;
                               foaf:homepage <http://www.semantic-web.at/> ;
                               foaf:logo <http://www.semantic-web.at/sites/default/files/swc_logo.png> .

ns16:TenForce_BVBA a foaf:Organization, eis:Partner ;
                   rdfs:label "TenForce BVBA" ;
                   foaf:homepage <https://www.tenforce.com/tenforce.com/index.html> ;
                   foaf:logo <https://www.tenforce.com/www.tenforce.com/sites/default/files/tenforce-logo.gif> .

ns16:Transinsight dcterms:abstract """Beyond keywords, Transinsight uses novel algorithms, state-of-the art natural language processing, and ontologies to provide better and faster search capabilities for complex queries not only in the life sciences.
The goal of this development is the establishment of a semantic web for the life sciences. GoPubMed, the ontology-based literature search engine, is a first example of a knowledge-based semantic search engine to improve searching in sciences. GoPubMed paves the way for a migration from web to semantic web.""" .

ns16:UBL dcterms:abstract """Leipzig University Library was founded in the year 1543 and is one of the oldest university libraries that serves both members of the university and the population of its surrounding city.

Leipzig University Library is used nationally and internationally because of its precious holdings and extensive special collections. These include medieval and modern manuscripts, incunabulae, the collection of papyri and autographs and the collections of Ostraka and coins.

Since January 1, 1998, Leipzig University Library has joined the national system for special collections in modern disciplines and is responsible for collecting literature and information in the field of Communication, Media Studies and Journalism.

Leipzig University Library provides printed and electronic media for all students, teachers, and researchers at Leipzig University. It continuously improves its catalogues and its reading areas, assures modern reproduction technology, and offers services in information retrieval for every discipline. Leipzig University Library cooperates closely with libraries in Saxony and other German States as well as internationally.""" .

ns16:University_of_Southampton a foaf:Organization, eis:Partner ;
                               rdfs:label "University of Southampton" ;
                               foaf:homepage <http://www.ecs.soton.ac.uk/> ;
                               dcterms:abstract """The University of Southampton (abbreviated as Soton) is a public university located in Southampton. The University of Southampton is already one of the top 15 research universities in the UK.
Electronics and Computer Science school in the UK top 3 for Electronics & Electrical Engineering and the UK top 10 for Computer Science and IT (Guardian University Guide and Times/Sunday Times Good University Guide, 2015.""" .

ns16:World_Wide_Web_Consortium_W3C_GEIE_ERCIM a foaf:Organization, eis:Partner ;
                                              rdfs:label "World Wide Web Consortium (W3C), GEIE ERCIM" ;
                                              foaf:homepage <https://www.privacyos.eu/archives/15-GEIE-ERCIM-W3C.html> ;
                                              foaf:logo <https://www.privacyos.eu/uploads/Consortium/w3c_main.vorschau.png> .

ns16:brox a foaf:Organization, eis:Partner ;
          rdfs:label "brox IT-Solutions GmbH" ;
          foaf:homepage <http://www.brox.de/> ;
          dcterms:abstract "Brox IT-Solutions was founded in 1998 and is headquartered in Hannover, Germany. Brox core competencies are supporting large enterprises in managing and evolving their IT infrastructure." ;
          foaf:logo <http://www.geoknow.eu/site/images/logo-brox.png> .

people:Partners site:content """{{query where=\"?project eis:partner ?resourceUri.\" template=\"partner\"}}
"""^^sysont:Markdown .

people:Presentations site:content """<nav class=\"nav-sidelinks\">
<ul>
<li><strong class=\"headline\">current funded projects</strong>
{{query where=\"?resourceUri a eis:FundedProject. OPTIONAL { ?resourceUri eis:status ?status }  FILTER (?status != 'finished')\" template=\"liplain\"}}
</li>
<li><strong class=\"headline\">featured projects</strong>
{{query where=\"?resourceUri eis:promoted 'true'^^xsd:boolean.\" template=\"liplain\"}}
</li>
</nav>

# Videolectures

* Sören Auer: [Triplify - Light-weight Linked Data Publication from Relational Databases](http://videolectures.net/www09_auer_tlwldp/), at World Wide Web 2009 Conference
* Sören Auer: [DBpedia: A Nucleus for a Web of Open Data](http://videolectures.net/iswc07_soeren_nwo/), at International Semantic Web Conference 2007
* Sören Auer: [OntoWiki - A Tool for Social, Semantic Collaboration](http://videolectures.net/iswc06_auer_otssc/) at International Semantic Web Conference 2006"""^^sysont:Markdown .

ns19:ATHENA_Research_and_Innovation_Center_in_Information_Communication_and_Knowledge_Technologies a foaf:Organization, eis:Partner ;
                                                                                                   rdfs:label "“ATHENA” Research and Innovation Center in Information, Communication and Knowledge Technologies" ;
                                                                                                   foaf:homepage <https://www.athena-innovation.gr/> ;
                                                                                                   dcterms:abstract "The “Athena” Research and Innovation Centre in Information, Communication and Knowledge Technologies is a research and technology body, which was founded under the auspices of the Greek Ministry of Development in 2001. “Athena” comprises the Institute for the Management of Information Systems (IMIS). IMIS was founded in 2007, and conducts research in the area of data management and large-scale information systems. The research at IMIS has a strong collaborative aspect and ranges from basic to applied research. The collaborative aspect is expressed in that research is conducted with national and international partners from industry as well as academia, often also in the context of novel and innovative projects. IMIS has already attracted funding from the European Union as well as from national funding agencies. IMIS has expertise in the following areas: geospatial data (GIS, location-based services, spatiotemporal data management), web data management (knowledge representation and ontologies, search methods, user personalization), eGovernment (interoperability, metadata management, privacy-preservation), scholar data (semantic annotation methods, non-linear thinking and searching tools, curation methodologies), scientific databases (large scale biological databanks, preservation technologies)." ;
                                                                                                   foaf:logo <https://www.athena-innovation.gr/images/stories/EK_ATHENA_logofinal_greek.png> .

ns19:Automotive_Partner_Assotiation a eis:Partner ;
                                    rdfs:label "ITA " ;
                                    skos:prefLabel "Automotive Partner Assotiation" ;
                                    foaf:homepage <http://www.ita-int.org/en/> ;
                                    dcterms:abstract """On 14 March 2000 ITA was founded with the goal of improving the flow of information between car manufacturers and suppliers on the one and the ICT companies on the other hand. The current focus is on the support along the entire automotive value chain.

Today, more than 50 well-known service providers are organized with different core competencies in the ITA. They know the business processes in the automotive industry in detail and successfully support national and international operations. The Automotive Industry will benefit in addition to the industry-specific expertise and experience in the local markets of excellent IT skills and innovations that enable advanced and effcient processes.
""" ;
                                    foaf:logo <http://www.ita-int.org/wp-content/uploads/2013/01/ita_logo_left_small.png> .

ns19:Bremer_Institut_fuer_Produktion_und_Logistik_GmbH a eis:Partner ;
                                                       rdfs:label "BIBA" ;
                                                       skos:prefLabel "Bremer Institut für Produktion und Logistik GmbH" ;
                                                       skos:altLabel "BIBA" ;
                                                       foaf:homepage <http://www.biba.uni-bremen.de/?&L=0> ;
                                                       dcterms:abstract "The BIBA is a scientific engineering research institute dealing with the issues of production and logistics systems. It conducts research, develops technical and organisational solutions and applies them realistically in commercial and industrial companies of all branches, sizes and nationalities." ;
                                                       foaf:logo <http://www.biba.uni-bremen.de/fileadmin/template/bibaLogo.gif> .

ns19:Critical_Publics_Ltd a foaf:Organization, eis:Partner ;
                          rdfs:label "CRITICAL PUBLICS" ;
                          skos:prefLabel "Critical Publics Ltd" ;
                          foaf:homepage <http://www.criticalpublics.com/> ;
                          dcterms:abstract "Headquartered in London, CRITICAL PUBLICS  is a network of business intelligence-based management consultants comprehensively drafting and implementing international solutions. For 10 years, CRITICAL PUBLICS  has helped corporate and institutional clients to navigate complexity, developing and implementing strategies to manage relationships with those important stakeholders we define as \"CRITICAL PUBLICS\"." ;
                          foaf:logo <http://linda-project.eu/wp-content/uploads/2014/02/criticalpublics120x120.png> .

ns19:DataMarket_EHF a eis:Partner ;
                    rdfs:label "DataMarket EHF" ;
                    foaf:homepage <https://datamarket.com/> ;
                    dcterms:abstract "DataMarket helps business users find and understand data, and data providers efficiently publish their data and reach new audiences. DataMarket's unique data portal - DataMarket.com - provides access to thousands of data sets holding hundreds of millions of facts and figures from a wide range of public and private data providers including the United Nations, the World Bank, Eurostat and the Economist Intelligence Unit. The portal allows all this data to be searched, visualized, compared and downloaded in a single place in a standard, unified manner. DataMarket’s data publishing solutions allow data providers to easily publish their data on DataMarket.com and on their existing websites through embedded content and branded versions of DataMarket’s systems, enabling all the functionality of DataMarket.com on top of their own data collections. DataMarket ehf. is a privately held company, incorporated in Iceland in June 2008. DataMarket, Inc. is a wholly owned subsidiary of DataMarket ehf. incorporated in Delaware, USA in January 2012." ;
                    foaf:logo <https://datamarket.com/site_media/cb-269/skin/datamarket/img/logo.png> .

ns19:Data_Publica a foaf:Organization, eis:Partner ;
                  rdfs:label "Data Publica" ;
                  foaf:homepage <http://www.data-publica.com/> ;
                  dcterms:abstract "Data Publica has developed and managing the most complete, richest and best equipped directory of electronic data in France." ;
                  foaf:logo <http://www.data-publica.com/content/wp-content/uploads/2013/09/logo_datapublica.png> .

ns19:European_Bioinformatics_Institute a eis:Partner ;
                                       rdfs:label "European Bioinformatics Institute" ;
                                       foaf:homepage <http://www.ebi.ac.uk/> ;
                                       dcterms:abstract "The European Bioinformatics Institute (an outstation of the EMBL) is an academic research institute located on the Wellcome Trust Genome Campus in Hinxton near Cambridge (UK), part of the European Molecular Biology Laboratory (EMBL). Its mission is to provide freely available data and bioinformatics services to all facets of the scientific community in ways that promote scientific progress; to contribute to the advancement of biology through basic investigator-driven research in bioinformatics; to provide advanced bioinformatics training to scientists at all levels, from PhD students to independent investigators and to help disseminate cutting-edge technologies to industry. Several RDF representations of existing databases and SPARQL end points are available for EBI databases, and EBI has considerable expertise in curation, management of the data lifecycle, data integration and consumption of Biomedical data" ;
                                       foaf:logo <http://www.ebi.ac.uk/web_guidelines/images/logos/EMBL-EBI/EMBL_EBI_Logo_black.png> .

ns19:Foundation_for_Research_and_TechnologyHellas_Institute_of_Computer_Science a eis:Partner ;
                                                                                rdfs:label "Foundation for Research and Technology-Hellas, Institute of Computer Science" ;
                                                                                foaf:homepage <http://www.ics.forth.gr/> ;
                                                                                dcterms:abstract "The Institute of Computer Science of FORTH has a relatively long history and recognized tradition, since its establishment in 1983, of conducting basic and applied research, developing applications and products, providing services, and playing a leading role in Greece and internationally, in the fields of Information and Communication Technologies. It is the toprated research institute in Greece in the area of ICT, and represents Greece within the ERCIM network of European ICT institutes. The FORTH-ICS Information Systems Laboratory (ISL) combines expertise in knowledge representation and reasoning, database systems, net-centric information systems, and conceptual modelling. Given its strong background on Semantic Web Data Management, FORTH will be responsible for the design of Linked Open Governance infrastructure required by the project use cases." ;
                                                                                foaf:logo <http://www.ics.forth.gr/_gfx/bg_index_logo_en.jpg> .

ns19:Fraunhofer_FOKUS a foaf:Organization, eis:Partner ;
                      rdfs:label "Fraunhofer FOKUS" ;
                      skos:prefLabel "Fraunhofer FOKUS" ;
                      foaf:homepage <http://www.fokus.fraunhofer.de/en/fokus/index.html> ;
                      dcterms:abstract "The FRAUNHOFER Society is one of the leading organisations of applied research and development in Europe. One of the main goals of the FRAUNHOFER Society is to link scientific work with industrial demands. The FRAUNHOFER  Institute for Open Communication Systems based in Berlin with its more than 280 employees offers a high level of expertise ranging from mobile communication systems in wireless and wired networks to architectures and standards in different application areas." ;
                      foaf:logo <http://linda-project.eu/wp-content/uploads/2014/02/fokus_logo_120x120.png> .

ns19:HYPERBOREA_SRL a foaf:Organization, eis:Partner ;
                    rdfs:label "HYPERBOREA SRL" ;
                    skos:prefLabel "HYPERBOREA SRL" ;
                    foaf:homepage <http://www.hyperborea.com/web/guest/home> ;
                    dcterms:abstract """HYPERBOREA s.r.l, placed in Pisa within Navacchio Scientific and Technological Pole, was founded on the 1st of January 2009 after the incorporation and fusion process of HYPERBOREA s.c and H2 s.r.l. HYPERBOREA s.c. was established in 1995. It is well situated in the public administration market sector with many public administrations as
customers (Local and Regional Authorities), supplying products and services including environmental information system, CMS, automated procedures on Workflow management systems. H2 s.r.l. was aiming at commercial and advance sale activities of environmental system software HYPERBOREA s.r.l. is continuing in acting as a reference for the design and development of environmental data bases, decision support systems, BI solutions and for the solution of any kind of system integration problem may arise within companies and
administrations. Current customers include Regional Agencies for Environment Protection, regional governments (Tuscany, Sardinia, Veneto, etc.), municipalities and companies in Italy.""" ;
                    foaf:logo <http://linda-project.eu/wp-content/uploads/2014/02/hyper120x120.png> .

ns19:Hanzo_Archives_Ltd a eis:Partner ;
                        rdfs:label "Hanzo Archives Ltd" ;
                        foaf:homepage <http://www.hanzoarchives.com/> ;
                        dcterms:abstract "Hanzo Archives Ltd is the world leader in Web archiving tools and services for business applications. Hanzo’s clients base, includes a dozen of Fortune 500 companies such as Coca Cola world, have compliance and e-discovery requirements encompassing their Web content, including structured data like pension plans and medical data presented on the Web. This type of material is becoming a key in litigation support, where part or a company’s entire Website may be required by the courts; for regulatory compliance where regulations concerning corporate records and proceedings now encompass Web content; and in commercial services, business intelligence and contractual archives. Hanzo Archives has gained a leading position in the US market establishing strategic partnerships with key actors with companies like Symantec or Merrill Corporation. Hanzo has developed state-of-the-art technology and best practices in Web archiving, incorporating capture, access and search. Hanzo unique crawler is based on a new approach to capturing content on the Web based on execution rather than parsing of Web pages. Moreover the above enables capture of a much larger range of technology like JavaScript and flash. Hanzo thanks to the ability of its technology has experience in extracting structured information published on the web to interact with forms and CMS using POST method to expose structure data. Hanzo has recently completed successfully a project to archive a large EU government intranet system with various information including: data sets and semi structured data raising important issues regarding versioning, provenance and classification issues." .

ns19:Intrasoft_International_SA a foaf:Organization, eis:Partner ;
                                rdfs:label "Intrasoft International SA" ;
                                foaf:homepage <http://www.intrasoft-intl.com/> ;
                                dcterms:abstract "INTRASOFT International is a leading European company, member of INTRACOM HOLDINGS Group that employees some 6,200 people in 21 countries around the world. Established in October 1996, through its continuous investment over the years it has earned a place among the primary services suppliers for EU institutions and bodies. Our offering is grouped along four service lines offered through our regional units: Application development & systems integration, professional and managed services, research and consulting services, communication and creative services. In a nutshell, we provide the full gamut of services required for the conception, design, and implementation of large, trans-governmental, and geographically dispersed ICT-based systems and applications, as well as their management, operation, and support including a range of services to policy makers." ;
                                foaf:logo <http://www.intrasoft-intl.com/images/intrasoft/logo-header.png> .

ns19:National_Technical_University_of_Athens a foaf:Organization, eis:Partner ;
                                             rdfs:label "National Technical University of Athens - NTUA" ;
                                             skos:prefLabel "National Technical University of Athens" ;
                                             foaf:homepage <http://www.ntua.gr/index_en.html> ;
                                             dcterms:abstract """The National Technical University of Athens (NTUA) is the foremost academic institution for technical education in Greece. The Decision Support Systems Laboratory of NTUA (EPU-NTUA) is a multidisciplinary scientific unit within the School of Electrical and Computer Engineering, operating for more than 25 years, with international experience in the following sectors: Information Technology and Decision Support Systems with a specialisation in e-Business and e-Government, Program & Project Management.
EPU-NTUA is certified with the international quality standard EN ISO 9001, since May 2005.""" ;
                                             foaf:logo <http://linda-project.eu/wp-content/uploads/2014/02/ntua_logo120x120.png> .

ns19:Piksel_SpA a foaf:Organization, eis:Partner ;
                rdfs:label "Piksel SpA" ;
                skos:prefLabel "Piksel SpA" ;
                foaf:homepage <http://piksel.com/> ;
                dcterms:abstract """PIKSEL SPA is an Italian company leader in the European market as software vendor and integrator, specialized in Media & Channel Integration, with more than 10 years track record of successful business with Broadcasters and Media & Telco leaders.
PIKSEL is part of the NY based PIKSEL Group, one the world’s leading providers of end-to-end IP video solutions with hundreds Customers in more than 40 countries. The PIKSEL offering includes comprehensive Multi-channel Content and Digital Asset Management products, solutions and services enabling innovative new media business.""" ;
                foaf:logo <http://linda-project.eu/wp-content/uploads/2014/02/Piksel_120x120.png> .

ns19:TTNews24 a foaf:Organization, eis:Partner ;
              rdfs:label "TTNews24 SRL" ;
              skos:prefLabel "TTNews24 Srl" ;
              foaf:homepage <http://www.ttnews24.it/> ;
              dcterms:abstract """TTNEWS24  is a regional TV broadcaster located in North-Western Tuscany, owning Channel 672 of Italy’s new digital broadcasting system. Being part of a broader network of broadcasting SMEs, its coverage extends itself to four regions of Central Italy, namely Liguria, Tuscany, Umbria and Lazio (counting about one fifth of the Italian population – or 12
million people overall). The company mission is to report about the daily events of the targeted territory (a subset of the above coverage, corresponding to North-Western Tuscany and Eastern Liguria). It is therefore a News Channel, with several editions of the News starting at 7.15am and closing as 1.30am every day.""" ;
              foaf:logo <http://linda-project.eu/wp-content/uploads/2014/02/ttnews120x120.png> .

ns19:UBITECH a foaf:Organization, eis:Partner ;
             rdfs:label "UBITECH" ;
             skos:prefLabel "UBITECH" ;
             foaf:homepage <http://www.ubitech.eu/> ;
             dcterms:abstract """UBITECH is a leading, highly innovative company, established to provide leading edge intelligent technical solutions and consulting services to businesses, organisations and government in order to allow the efficient and effective access and communication with various heterogeneous information and services, anytime and anywhere. UBITECH enables
real-time valid information processing and decision-making, the realisation  of intelligent business environments and B2B and B2C transactions by providing high added-value busines oriented solutions.""" ;
             foaf:logo <http://linda-project.eu/wp-content/uploads/2014/02/ubitech120x120.png> .

ns19:University_of_Edinburgh a eis:Partner ;
                             rdfs:label "University of Edinburgh" ;
                             foaf:homepage <http://www.ed.ac.uk> ;
                             dcterms:abstract "The School of Informatics at the University of Edinburgh is the highest ranked department in the UK according to the recent Research Assessment Exercise (RAE) of Computer Science schools across the UK. The database group of the School of Informatics, is arguably the best database group in the UK and among the top three database groups in Europe. The database group holds various research grants on disparate disciplines including: data integration, data publishing, high-performance XML query processing, data cleaning, secure data access, and support for next generation storage systems." ;
                             foaf:logo <http://upload.wikimedia.org/wikipedia/en/0/0f/University_of_Edinburgh_logo.svg> .

people:Projects site:content """# Funded Projects

<nav class=\"nav-sidelinks\">
{{query where=\"?resourceUri a eis:FundedProject.\" template=\"liplain\"}}
</nav>

EIS is currently funded with the following regional, national and European research projects

{{query where=\"?resourceUri a eis:FundedProject. OPTIONAL { ?resourceUri eis:status ?status } FILTER (?status != 'finished')\" template=\"abstract\"}}

# Community Projects
<nav class=\"nav-sidelinks\">
{{query where=\"?resourceUri a eis:CommunityProject.\" template=\"liplain\"}}
</nav>

EIS is currently launched the following Community Projects

{{query where=\"?resourceUri a eis:CommunityProject. OPTIONAL { ?resourceUri eis:status ?status } FILTER (?status != 'finished')\" template=\"abstract\"}}

# Incubator Projects
<nav class=\"nav-sidelinks\">
{{query where=\"?resourceUri a eis:IncubatorProject.\" template=\"liplain\"}}
</nav>

 EIS Incubator projects

{{query where=\"?resourceUri a eis:IncubatorProject. OPTIONAL { ?resourceUri eis:status ?status } \" template=\"abstract\"}}


# Open Source Projects
<nav class=\"nav-sidelinks\">
{{query where=\"?resourceUri a eis:OpenSourceProject.\" template=\"liplain\"}}
</nav>
Open Source Projects

{{query where=\"?resourceUri a eis:OpenSourceProject. OPTIONAL { ?resourceUri eis:status ?status } \" template=\"abstract\"}}


# Alumni Projects
<nav class=\"nav-sidelinks\">
{{query where=\"?resourceUri a eis:AlumniProject.\" template=\"liplain\"}}
</nav>
In the EIS group, we currently have a number of Master and Lab students. Some of these projects have reached a stable state, but are currently not actively maintained and further developed.

{{query where=\"?resourceUri a eis:AlumniProject.\"}}"""^^sysont:Markdown .

projects:AGDISTIS site:content """Over the last decades, several billion Web pages have been made available on the Web.
The ongoing transition from the current Web of unstructured data to the Data Web yet requires scalable and accurate approaches for the extraction of structured data in RDF (Resource Description Framework). One of the key steps towards extracting RDF from natural-language corpora is the disambiguation of named entities. While several approaches aim to address this problem, they still achieve poor accuracy on Web/news data (WND). We address this drawback by presenting AGDISTIS, a novel knowledge-base-agnostic approach for named entity disambiguation that performs well on WND. Our approach combines the HITS algorithm with label expansion strategies and string similarity measures. Based on this combination, it can efficiently detect the correct URIs for a given set of named entities within an input text. We evaluate our approach on four different datasets against state-of-the-art named entity disambiguation frameworks. Our results indicate that we outperform the state-of-the-art approach by up to 16% F-measure. Moreover, [FOX](http://eis.iai.uni-bonn.de/projects/FOX \"FOX\") is a modern Named Entity Recognition Framework based on AGDISTIS. [Short Description of AGDISTIS - Framework can be found here.](http://139.18.2.164/rusbeck/main.pdf \"Short Description of AGDISTIS - Framework\") [Supplementary material can be found here.]( http://139.18.2.164/rusbeck/appendix.pdf \"here.\")

AGDISTIS is temporarily deployed as Web service. For example, you can use curl to test AGDISTIS:

	curl --data-urlencode
	\"text='The <entity>University of Leipzig</entity> 	in <entity>Barack Obama</entity>.'\"
	-d type='agdistis' http://139.18.2.164:8080/AGDISTIS
"""^^sysont:Markdown .

<http://eis.iai.uni-bonn.de/Projects/AKSWorg/Documentation> site:content """
{{toc tag=\"ul\" depth=\"3\"}}

# Big-Picture
This web page consists of linked data enabled resources.
Each resource has a specific HTML5 representation (besides its RDF representation).
This HTML representation is rendered by using a template and fill its variable parts with the content from these sources:

* values (Literals) of specific attributes from the resource
* output of helper markup (see below)
* content rendered from sub-templates

# Resources and Properties
The following attributes and classes are used by the templates.

## Classes
Currently, there are templates for the following classes of resources:

* [[foaf:Document]]: a basic web page without specific lists and queries
* [[aiiso:ResearchGroup]]: a (sub) research group with lists of member, research areas and projects
* [[foaf:Person]]: a person with lists of projects and research areas
* [[foaf:Project]]: an AKSW project.
Can be a funded, a community or an open-source project.

## Properties
These properties can be applied to all resources:

* [[rdfs:label]]: This is the overall headline, name or title of a resource.
* [[site:menuLabel]]: If the resource title is too long for the menu, use this property in addition to [[rdfs:label]].
* [[site:content]]: The main content property.
The literal value should be of datatype [[sysont:Markdown]].
* [[dcterms:abstract]]: This is a plain text attribute (no markup).
The content of this attribute is used in extended lists and build the header of the resource as a first summary paragraph.
* [[aksw:hookline]]: This a less than 100 character description of the resource.
Hooklines are especially important for projects to advertise them in lists and on top of the project page.
* [[sioc:feed]]: Use this object property to relate a RSS or Atom feed to this resource.
The content of this feed is shown in the right side content column.

In addition to the general properties, these class specific properties can be used:

* for Projects: [[foaf:homepage]]
* for Groups: [[aksw:researchAreas]], [[foaf:member]]
* for Person: [[foaf:name]], [[foaf:currentProject]], [[foaf:pastProject]], [[foaf:mbox]], [[aksw:room]], [[aksw:publicationTag]] (for the publication list)

# Main Content
The suggested markup language to write pages is [Markdown](http://daringfireball.net/projects/markdown/).
Markdown is a text-to-HTML conversion language for web writers.
Markdown is intended to be as easy-to-read and easy-to-write as is feasible.

All details on Markdown syntax are available on the [syntax page](http://daringfireball.net/projects/markdown/syntax).
Besides its readability, one main advantage of Markdown is its integration with HTML.
Wherever you need HTML markup, you can use it without any quote or special syntax as [inline HTML](http://daringfireball.net/projects/markdown/syntax#html).
Have a look at the sources of this document to copy/paste specific style elements which you want to reuse, or add new stuff and share it.

The main content of each resource is saved as a Literal object with the attribute [[site:content]].
See the description of this property for details about its usage.
In general: All attributes and classes have a proper documentation, so you just need to click on them inside of OntoWiki for more details.

## Helper Markup
Helper markup is used in the same way as wiki actions.
The general syntax of a helper tag is: `{{tagname p1=\"value1\" ... \"pX\"=\"valueX\"}}`.

The following helper exists so far.

### Table of Content helper
The `toc` helper creates an javascript generated table of contents at the position where the helper tag was written.

The following options can be used

* `tag`: the toc type can be `ol`, `ul` or `div`, default is `ol`
* `startlevel`: which heading level to start? default is `1`
* `depth`: how many TOC levels you want? default is `2`

Examples (use a single `=` instead of `==`):

* `{{toc depth==\"2\"}}`

### link helper
The `link` helper creates an internal page link to a specific resource.
If you need to link to an eis.iai.uni-bonn.de resource, you should use this helper instead of using plain HTML-links or Markdown link syntax.

Possible parameters are:

* `literal`: search for this literal and link to its resource (the first found).
  * short form: `l`
* 'uri': instead of searching for a resource, use the given qname or uri string
  * short form: `r`
* `property`: search only for literals of the given property.
  * short form: `p`
* `text`: instead of using the resource title, use the given string as link text.
  * short form: `t`

Examples (use a single `=` instead of `==`):

* `{{link uri==\"http://eis.iai.uni-bonn.de/About\"}}`
  * result: {{link uri=\"http://eis.iai.uni-bonn.de/About\"}}
* `{{link r==\"foaf:Person\"}}`
  * result: {{link r=\"foaf:Person\"}}
  * comment: use qnames where possible, use short values
* `{{link literal==\"Projects\"}}`
  * result: {{link literal=\"Projects\"}}
* `{{link text==\"our projects\" literal=\"Projects\"}}`
  * result: {{link text=\"our projects\" literal=\"Projects\"}}
* `{{link property==\"site:menuLabel\" literal=\"About\"}}`
  * result: {{link property=\"site:menuLabel\" literal=\"About\"}}
* `{{link literal==\"MyPage\"}}`
  * result: {{link literal=\"MyPage\"}}
  * comment: no links to non existing resources
* `{{link uri==\"no/uri\"}}`
  * result: {{link uri=\"no/uri\"}}
  * comment: wrong usage is indicated in this way, a mouseover tooltip over the error gives you more information about the problem
* `{{link p==\"foaf:nick\" l=\"Seebi\" t=\"my page\"}}`
  * result: {{link p=\"foaf:nick\" l=\"Seebi\" t=\"my page\"}}
  * comment: Example with short parameters, qname and given link text

## Style Elements
There are specific style elements as two column sections or tables which you can add to your documents by using HTML markup.

### Multi Columns

<div class=\"multicolumns2\">
<strong>first columns</strong>
<p>...</p>
<p>...</p>
<strong>second column</strong>
<p>...</p>
<p>...</p>
</div>

### Tables
Use standard HTML tables with table head and cell tags to achieve a look like this

<table>
<thead>
<tr>
<th>Tabelle Head</th>
<th>Tabelle Head</th>
</tr>
</thead>
<tbody>
<tr>
<td>Development</td>
<td>methods, tools and applications</td>
</tr>
<tr>
<td>applications</td>
<td>adaptive Knowledge Engineering</td>
</tr>
</tbody>
</table>

# Navigation Structures

Menus are [[rdf:Seq]] resources of type [[aksw:Navigation]].
The rdf properties `rdf:_1` till `rdf:_x` are used to arrange an ordererd list of resources which a used to render a navigation menu.
Currently, we have these navigation resources:

* {{link literal=\"Main Navigation\"}}
* {{link literal=\"Top Navigation\"}}

"""^^sysont:Markdown .

projects:ALOE site:content """# Background

The Linked Open Data (LOD) Cloud contains more than 31 billion triples. This wealth of knowledge is expressed by using a large number of vocabularies (e.g., FOAF, VCard, SKOS), leading to a schema mismatch between the different knowledge bases that express knowledge about the same types of entities (e.g., persons). Mismatches at instance level are similarly common, including the use of different units of measure (e.g., cm vs. inch for heights) or data types (e.g., strings instead of doubles for geographical coordinates of locations). The integration of this data is yet central for tasks such as large-scale inference, cross-ontology question answering, graph traversal and especially business applications that require all data to be available from their local servers in a particular format.

# Aim

The aim of the ALOE (Assisted Linked data cOnsumption Engine) project is to provide an engine for the semi-automatic generation of consumption configurations. For this purpose, ALOE can automatically discover class and property mappings across endpoints even when no schema information is available. In addition, ALOE can generate initial specifications for the consumption of Linked Data. For this purpose, it provides several functions for transforming the data from the source knowledge base into a format that corresponds to that of the target knowledge base. Therewith, ALOE enables lay and experienced users to consume Linked Data with great ease. The ALOE process can be controlled via the interface shown below. Please note that the demo only consumes 1000 triples."""^^sysont:Markdown .

projects:AutoSPARQL site:content """The aim of AutoSPARQL is to provide robust question answering over RDF data by combining methods from several research areas, such as:

- natural language processing for creating sophisticated semantic representations of questions
- inductive active learning for incorporating user feedback
- results of the BOA project

The underlying idea is to convert a natural language expression to a SPARQL query, which can then retrieve the answer of a question from a given triple store.

Papers:

- http://jens-lehmann.org/files/2011/autosparql_eswc.pdf ESWC 2011 AutoSPARQL Paper
- http://dl.acm.org/citation.cfm?doid=2187836.2187923 WWW 2012 TBSL Paper

Links:

- http://autosparql.dl-learner.org AutoSPARQL demo
- http://autosparql-tbsl.dl-learner.org AutoSPARQL-TBSL demo

Sourcecode:

- main: https://github.com/AKSW/AutoSPARQL
- machine learning algorithms in (http://dl-learner.org \"DL-Learner\")
- natural language patterns in BOA
"""^^sysont:Markdown .

projects:BIG site:content """* Duration: 2012–2014
* Funding Programme: EU FP7"""^^sysont:Markdown .

projects:BOA site:content """# General Overview

Most knowledge sources on the Data Web were extracted from structured or semi-structured data. Thus, they encompass solely a small fraction of the information available on the document-oriented Web. In this paper, we present BOA, an iterative bootstrapping strategy for extracting RDF from unstructured data. The idea behind BOA is to use the Data Web as background knowledge for the extraction of natural language patterns that represent predicates found on the Data Web. These patterns are used to extract instance knowledge from natural language text. This knowledge is finally fed back into the Data Web, therewith closing the loop. We evaluate our approach on two data sets using DBpedia as background knowledge. Our results show that we can extract several thousand new facts in one iteration with very high accuracy. Moreover, we provide the first repository of natural language representations of predicates found on the Data Web.

# Presentation

The following presentation was held at EKAW 2012 in Galway:

<iframe src=\"http://www.slideshare.net/slideshow/embed_code/14666229\" width=\"550\" height=\"440\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px\" allowfullscreen> </iframe> <div style=\"margin-bottom:5px\"> <strong> <a href=\"http://www.slideshare.net/gerbsen/extracting-multilingual-naturallanguage-patterns-for-rdf-predicates\" title=\"Extracting Multilingual Natural-Language Patterns for RDF Predicates\" target=\"_blank\">Extracting Multilingual Natural-Language Patterns for RDF Predicates</a> </strong> from <strong><a href=\"http://www.slideshare.net/gerbsen\" target=\"_blank\">Daniel Gerber</a></strong> </div>

The following presentation was held at We~KEx at ISWC 2011 in Bonn:

<iframe src=\"http://www.slideshare.net/slideshow/embed_code/9868776\" width=\"550\" height=\"440\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\" style=\"border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px\" allowfullscreen> </iframe> <div style=\"margin-bottom:5px\"> <strong> <a href=\"http://www.slideshare.net/gerbsen/boa-bootstrapping-linked-data-9868776\" title=\"BOA - Bootstrapping Linked Data\" target=\"_blank\">BOA - Bootstrapping Linked Data</a> </strong> from <strong><a href=\"http://www.slideshare.net/gerbsen\" target=\"_blank\">Daniel Gerber</a></strong> </div>

# Generated Knowledge

The generated knowledge can be accessed at the [BOA dydra repository][boadydra].

# Library of Natural-Language Representations of Formal Relations

The results of the BOA approach can be downloaded in form of an Lucene Index. The pattern in this index were derived from applying DBpedia background knowledge on the English Wikipedia. The index was created as follows:

    Document doc = new Document();
    doc.add(new Field(\"uri\", mapping.getProperty().getUri(), Field.Store.YES, Field.Index.NOT_ANALYZED));
    doc.add(new Field(\"nlr\", pattern.getNaturalLanguageRepresentationWithoutVariables().trim(), Field.Store.YES, Field.Index.ANALYZED));
    doc.add(new NumericField(\"confidence\", Field.Store.YES, true).setDoubleValue(pattern.getConfidence()));
    writer.addDocument(doc);%%

You can query the index like this:

    Query query1 = new TermQuery(new Term(\"nlr\", searchPhrase));
    Query query2 = NumericRangeQuery.newDoubleRange(\"confidence\", confidenceThreshold, 1D, true, true);

    BooleanQuery booleanQuery = new BooleanQuery();
    booleanQuery.add(query1, BooleanClause.Occur.MUST);
    booleanQuery.add(query2, BooleanClause.Occur.MUST);

    ScoreDoc[] hits = indexSearcher.search(booleanQuery, 100).scoreDocs;

    for (int i = 0; i < hits.length && i < 5; i++) {

        System.out.println(indexSearcher.doc(hits[i].doc).get(\"uri\"));
        System.out.println(indexSearcher.doc(hits[i].doc).get(\"nlr\"));
        System.out.println(indexSearcher.doc(hits[i].doc).get(\"confidence\"));
    }

You can download this index [here][patlibrary]. Keep in mind that you need Lucene in at least Version 3.0. We applied very strict rules during pattern filtering, so very few patterns were actually generated. Also there are no score constrains applied to the patterns contained, leading to very weak patterns inside the index.

[boadydra]: http://dydra.com/daniel-gerber/boa \"BOA dydra repository\"
[patlibrary]: http://eis.iai.uni-bonn.de/Projects/BOA/files?get=pattern_library_en_dbpedia_wikipedia.tar"""^^sysont:Markdown .

projects:BigDataEurope a foaf:Project, eis:FundedProject ;
                       rdfs:label "BigDataEurope" ;
                       foaf:homepage "http://www.big-data-europe.eu/" ;
                       dcterms:abstract """BigDataEurope will provide support mechanisms for all the major aspects of a data value chain, in terms of the employed data and technology assets, the participating roles and the established or evolving processes. The effectiveness of the provided support mechanisms will be assessed in different domains pertaining to Europe’s major societal challenges with respect to the needs and requirements of the related communities. To this end, BigDataEurope focuses on providing an integrated stack of tools to manipulate, publish and use large-scale data resources; tools that can be installed and used freely in a customised data processing chain with minimal knowledge of the technologies involved and integrating and industrially hardening key open-source Big Data technologies and European research prototypes into a Big Data Integrator Platform, i.e. an ecosystem of specifications and reference implementations that are both attractive to current players from all parts of the data value chain while also lowering the entry barrier for new businesses.

""" ;
                       foaf:logo <http://www.big-data-europe.eu/wp-content/uploads/logo-BigDataEurope.png> ;
                       doap:maintainer people:SoerenAuer ;
                       ns4:endDate "2017-12-31" ;
                       ns4:startDate "2015-01-01" ;
                       eis:hookline "Integrating Big Data, Software & Communities for Addressing Europe’s Societal Challenges" ;
                       eis:partner ns16:Open_PHACTS_Foundation_LBG, ns16:Centre_for_Renewable_Energy_Sources_and_Saving, ns16:Institut_fuer_Angewandte_Informatik_e_V, ns23:id, ns16:TenForce_BVBA, ns16:Semantic_Web_Company_GmbH, ns16:CESSDA_AS, ns16:National_and_Kapodistrian_University_of_Athens, ns16:Food_and_Agriculture_Organization_of_the_United_Nations, ns16:European_Union_Satellite_Centre, ns16:World_Wide_Web_Consortium_W3C_GEIE_ERCIM, ns16:National_Centre_for_Scientific_Research_Demokritos, <http://eis.iai.uni-bonn.de/Partner/12_European_Union_Satellite_Centre> ;
                       eis:status "Ongoing" ;
                       site:content """In order to realise its objectives, Big Data Europe will focus on two clearly defined coordination and support measures:

1. Coordination: Engaging with a diverse range of stakeholder groups representing particularly the Hori-zon 2020 societal challenges Health, Food & Agriculture, Energy, Transport, Climate, Social Sciences and Security; Collecting requirements for the ICT infrastructure needed by data-intensive science practition-ers tackling a wide range of societal challenges; covering all aspects of publishing and consuming seman-tically interoperable, large-scale data and knowledge assets;

2. Support: Designing, realizing and evaluating a Big Data Aggregator platform infrastructure that meets requirements, minimises the disruption to current workflows, and maximises the opportunities to take advantage of the latest European RTD developments, including multilingual data harvesting, data analyt-ics, and data visualisation.

BigDataEurope will implement and apply two main instruments to successfully realize these coordination and support measures:

a) Build Societal Big Data Interest Groups in the W3C interest group scheme and involving a large number of stakeholders from the Horizon 2020 societal challenges as well as technical Big Data experts;

b) Design, integrate and deploy a cloud-deployment-ready Big Data aggregator platform comprising key open-source Big Data technologies for real-time and batch processing, such as Hadoop, Cassandra and Storm.

BigDataEurope aims to provide an adaptable, easy to deploy and use solution, which will allow the interest-ed user groups and stakeholders to extend their Big Data solutions or introduce Big Data technology to their business processes, based on a concrete methodology for producing a technically sound solution and maxim-izing its out-reach to the relevant communities."""^^sysont:Markdown .

projects:BioASQ site:content """* Duration: 2012–2014
* Funding Programme: FP7-ICT-2011–8 (Collaborative Project)"""^^sysont:Markdown .

projects:CSVImport doap:programming-language """php
JavaScript""" ;
                   site:content """Statistical data on the web is often published as Excel sheets. Although they have the advantage of being easily readable by humans, they cannot be queried efficiently. Also it is difficult to integrate with other datasets, which may be in different formats. Our approach is to convert the data into a single data model – RDF. But in these datasets, a single statistical value is described in several dimensions. Thus a simple row-based transformation is not possible. Therefore, we use [The RDF Data Cube vocabulary](http://publishing-statistical-data.googlecode.com/svn/trunk/specs/src/main/html/cube.html \"The RDF Data Cube vocabulary\") for the conversion as it is designed particularly to represent multidimensional statistical data using RDF.
Transforming CSV to RDF in a fully automated way is not feasible as there may be dimensions encoded in the heading or label of a sheet. Therefore, we introduce a semi-automated approach as a plugin in [OntoWiki](http://eis.iai.uni-bonn.de/Projects/OntoWiki \"OntoWiki\"). """^^sysont:Markdown .

projects:CognitiveEvolutionLD dcterms:abstract """Cognition is determined by the function and interplay of several hundreds, if not thousands, of genes with a considerable overlap in the disease phenotypes they can cause if mutated. We argue that, in order to understand the biological basis of cognition, these genes have to be investigated together with their evolutionary history and the diseases they are implicated in. This requires the integration of data from different research disciplines. To allow researchers to answer complicated questions related to cognition, a task that is usually very time-consuming, we propose to use Linked Data publication. Such data integration and querying methods have already been successfully used in other life science domains. In our initial effort presented here, we converted and integrated 11 different datasets and provide a first demonstration of the added value of Linked Data by showing how a set of relevant queries over the integrated data can be answered.
""" .

projects:CubeViz site:content """In order to hide the complexity of the RDF Data Cube vocabulary from users and to facilitate the browsing and exploration of DataCubes we developed the RDF DataCube browser CubeViz. CubeViz can be divided into two parts, both developed as an extension of OntoWiki:

1. Faceted data selection component, which queries the structural part of a selected RDF graph containing DataCube resources.
2. Chart visualization component, which queries observations (selected by the faceted selection component) and visualize them with suitable charts.

CubeViz renders facets according to the DataCube vocabulary to select data on the first component, using SPARQL as the query language. Currently, the following facets are available:

1. Selection of a DataCube DataSet
2. Selection of a DataCube Slice
3. Selection of a specific measure and attribute (unit) property encoded in the respective DataCube dataset.
4. Selection of a set of dimension elements that are part of the dimensions encoded in the respective DataCube data set"""^^sysont:Markdown .

projects:DBPSB site:content """Triple stores are the backbone of increasingly many Data Web applications. It is evident that the performance of those stores is mission critical for individual projects as well as for data integration on the Web in general. Assessing the performance of current triple stores is, therefore, important to observe weaknesses and strengths of current implementations. DBPSB is a general SPARQL benchmark procedure, which we apply to the DBpedia knowledge base. The benchmark is based on query-log mining, clustering and SPARQL feature analysis. In contrast to other benchmarks, we perform measurements on actually posed queries against existing RDF data. Previous approaches often compared relational and triple stores and, thus, settled on measuring performance against a relational database, which has been converted to RDF, using SQL like queries. We argue that a pure RDF benchmark is more useful to compare between existing triple stores and provide results for Virtuoso, Sesame, Jena-TDB, and BigOWLIM.

Here we provide an overview of steps required to create the benchmark. The methodology can in principle be applied to all RDF knowledge bases. It allows the benchmark to be updated as the knowledge bases and queries to it evolve


Dataset Generation
==================
Base Data: DBpedia 3.5.1 with all data sets mentioned are available [here](http://wiki.dbpedia.org/DatasetsLoaded \"here\").

In order to generate a dataset of specific size, do the following steps:

1. In benchmark.xml file set the tag <percentageOfDataRequired> to the dataset size required e.g. 10, 20, ....
2. In benchmark.xml file set the tag <extractionMethod> to either 'RandomInstance' or 'RandomTriple'.
3. In benchmark.xml file set the tag <outputFile type=\"N-TRIPLE\"> to the name of the required output file.
4. In benchmark.xml file set the tag <sparqlEndpoint> to the address of your endpoint.
5. Call function generateData() from function main, and it will generate the data.

Generating data using Random Triple method is much faster than generation by Random Instance.

Datasets are available for download [here](http://dbpedia.eis.iai.uni-bonn.de/benchmark.dbpedia.org/ \"here\").

Query Generation
================
Query Log: [here](ftp://download.openlinksw.com/support/dbpedia/ \"here\").

In order sort the query log by frequency of queries, do the following steps: -

1. In benchmark.xml file set the tag <queryLogFolder> to the folder in which the query log files exist. Log files are assumed to have .log extension.
2. In benchmark.xml file set the tag <sortedQueriesOutputFile> to the output file in which the sorted queries along with the frequency of each query.
3. In benchmark.xml file set the tag <leastFrequencyForQuery> to the value below which the query is discarded.
4. Call function 'sortQueries' in 'ClusterProcessor' class in order to sort the queries and write the output to the file specified in benchmark.xml, and it will also discard the queries whose frequencies are below the specified value.
5. (Optional) this step is optional but it is recommended in order to accelerate the clustering step. Call function 'makeIDs' in 'ClusterProcessor' class in order to give each query a unique ID and remove the common keywords e.g. from, and where, that will not affect the clustering process and will also make the clustering faster, as the strings will be shorter.

The approximate time of that step is 2.5 hours.

Clustered Query Log:

1. Feed the file containing the queries along with their IDs to 'BorderFlow' application. More information about Border Flow can be found [here]( an overview of steps required to create the benchmark. The methodology can in principle be applied to all RDF knowledge bases. It allows the benchmark to be updated as the knowledge bases and queries to it evolve. \"here\").
2. From 'BorderFlow' you will get a file containing the 'clusterID' and the queries belonging to that cluster.
3. By clustering you get several clusters, each cluster contains a similar set of queries, i.e. queries belonging to the same cluster should to some extent contain similar SPARQL features.

List of Benchmark Queries:

To avoid caching of query results we should introduce a small difference in each run of the query in order to force the triplestore not fetch the query result from its cache.
The required steps to get our set of queries are as follows: -

1. Identify SPARQL-features of interest e.g. UNION, DISTINCT, OPTIONAL, ...
1. Select one of the queries satisfying the feature of interest using the following methodology:

 - Traverse the clusters in order of their total frequency, for each cluster in order select the query with the highest frequency within the cluster with the highest total frequency on condition that this query satisfies one of SPARQL feature or combination of features.
 - Inspect each one of the selected queries, in order to identify some static term(s), i.e. URI or literal, that can be used as a content placeholder(s).
 - Replace the selected static term in each query with a variable(s) and make a select query for that variable(s) only with DISTINCT in order to avoid repetition and with LIMIT to get a specific number of allowed values, this query is called 'Auxiliary Query'.
 - Perform the auxiliary query to get a list of allowed values for placeholder(s).
During each run of the original query replace its placeholder(s) with some random value out of its list of allowed values.
 - Sort the clusters descendingly by their total frequency, i.e. the cumulative sum of frequencies of all queries belong to that cluster.

The time for selecting the queries and their auxiliary queries is approx. 3 days.

Sample Query
============

Following is a sample query with a variable part, that will be used as a placeholder during the hot run phase.
The placeholder is indicated by %%v%%.

SELECT * WHERE {
  {?v2 a dbp-owl:Settlement;    rdfs:label %%v%%.    ?v6 a dbp-owl:Airport.}
  {?v6 dbp-owl:city ?v2.}
  UNION
    {?v6 dbp-owl:location ?v2.}
    {?v6 dbp-prop:iata ?v5.}
  UNION
    {?v6 dbp-owl:iataLocationIdentifier ?v5.}
    OPTIONAL {?v6 foaf:homepage ?v7.}
    OPTIONAL {?v6 dbp-prop:nativename ?v8.}
}

We use another query called the auxiliary query in order to get a list of possible values for that placeholder.
During the hot-run phase, the application selects a random value out of the list of possible values of the placeholder.

The auxiliary query used to fill that list is as follows:

SELECT DISTINCT ?v WHERE{
  {?v2 a dbp-owl:Settlement;
    rdfs:label ?v.
    ?v6 a dbp-owl:Airport.}
  {?v6 dbp-owl:city ?v2.}
  UNION
{?v6 dbp-owl:location ?v2.}
    {?v6 dbp-prop:iata ?v5.}
  UNION
{?v6 dbp-owl:iataLocationIdentifier ?v5.}
  OPTIONAL {?v6 foaf:homepage ?v7.}
  OPTIONAL {?v6 dbp-prop:nativename ?v8.}
} LIMIT 1000

Benchmark Execution
===================
Loading Procedures:

In order to upload data into the 3 different triplestores do a step of the following: -

1. For loading data to Virtuoso, there is a shell script called 'virtload.sh'. Call this shell script as './virtload.sh inputfile.nt http://dbpedia.org 1111 dba pwd' .
2. For loading data to Sesame, set the 'sesameInputTriplesFile' tag in benchmark.xml file to the name of the N-TRIPLES file to read from, set 'sesameServerAddress' tag to the address of the Sesame server, and set 'sesameRepositoryID' tag to the ID of the repository to which you want to upload data. Call Sesame Data Loader.load Data(), and it will load the data to the store specified.
3. For loading data to Jena-TDB, set the 'jenaTDBInputTriplesFile' tag in benchmark.xml file to the name of the N-TRIPLES file to read from, set 'jenaTDBDatasetGraph' tag to the path of 'JenaTDB' dataset. Call Jena TDB Data Loader.load Data(), and it will load the data to the dataset specified.
4. Since Big OWLIM, uses Tomcat and Open RDF- Workbench like Sesame, so same settings can be used for loading data to Big OWLIM store.

For loading dataset of size 100% into virtuoso it takes approx 10 Hrs, 8 Hrs for Jena-TDB, 14 Hrs for Sesame, and 8 Hrs for Big OWLIM.

Benchmark Procedures
=====================

There are 4 classes called 'VirtuosoQueryExecutor', 'JenaTDBQueryExecutor', 'SesameQueryExecutor', and 'BigOWLIMQueryExecutor' for each type of triplestore, each one of them contains a function called 'executeQuery' that takes the SPARQL query as parameter and returns the execution time of that query against the triplestore of interest in micro-seconds.
This function is called within a loop that works for 20 minutes for warm-up, and then for 60 minutes for actual calculation .

Benchmark Metrics
=================

The main metrics used in DBPSB for performance measurement are:

1. Query Mixes per Hour (QMpH), which denotes the number of query mixes posed to the test store in one hour.
2. Queries per Second (Qp S), which is the number of queries (query variations of a specific query) the test store can answer in one second."""^^sysont:Markdown .

projects:DBpedia site:content """Overview
========
Do you know all mayors from towns elevated higher than 1000m, all sitcoms set in New York, or all philosophers that were influenced by Friedrich Nietzsche?

Wikipedia contains information required for answering such questions, but has the problem that its constricted search capabilities only allow very limited access to this valuable knowledge-base. The Semantic Web still lacks a critical mass of RDF data online and up-to-date terms and ontologies are missing for many application domains.

The dbpedia.org project approaches both problems by extracting structured information from Wikipedia and by making this information available on the Web. dbpedia.org allows you to ask sophisticated queries against Wikipedia (like the ones mentioned above) and to link other datasets on the Web to dbpedia data.

Features
========

DBpedia features at the moment:

- two large extracted datasets for different purposes
- a visual query builder available at: http://wikipedia.eis.iai.uni-bonn.de
- a SPARQL endpoint and a data browser
"""^^sysont:Markdown .

projects:DBpediaDQ site:content """As we all know, DBpedia is an important dataset in Linked Data as it is not only connected to and from numerous other datasets, but it also is relied upon for useful information. However, quality problems are inherent in DBpedia be it in terms of incorrectly extracted values or datatype problems since it contains information extracted from crowd-sourced content.

However, not all the data quality problems are automatically detectable. Thus, we aim at crowd-sourcing the quality assessment of the dataset. In order to perform this assessment, we  developed a tool whereby a user can evaluate a random resource by analyzing each triple individually and store the results. Here is the link to the tool: [http://nl.dbpedia.org:8080/TripleCheckMate/](http://nl.dbpedia.org:8080/TripleCheckMate/ \"http://nl.dbpedia.org:8080/TripleCheckMate/\").

If you have any questions or comments, please do not hesitate to contact us at dbpedia-data-quality@googlegroups.com.

Results
==================
- Results : [http://goo.gl/lIKK7](http://goo.gl/lIKK7 \"http://goo.gl/lIKK7\")
- Total no. of users :                                                   58
- Total no. of distinct resources evaluated :              521
- Total no. of resources evaluated :                            792
- Total no. of distinct resources without problems :     86
- Total no. of distinct resources with problems :          435
- Total no. of distinct incorrect triples :                         2928
- Total no. of distinct incorrect triples in the dbprop namespace :      1745
- Total no. of inter-evaluations :                                                           268
- No. of resources with evaluators having different opinions :             89
- Resource-based inter-rater agreement (Cohen’s Kappa) :               0.34
- Triple-based inter-rater agreement (Cohen’s Kappa) :                      0.38
- No. of triples evaluated for correctness :                                           700
- No. of triples evaluated to be correct :                                               567
- No. of triples evaluated incorrectly :                                                  133
- % of triples correctly evaluated :                                                        81
- Average no. of problems per resource :                                             5.69
- Average no. of problems per resource in the dbprop namespace :   3.45
- Average no. of triples per resource :                                                 47.19
- % of triples affected :                                                                        11.93
- % of triples affected in the dbprop namespace :                               7.11

Manuscript
==================
- [Link to presentation](http://www.slideshare.net/amrapalijz/i-semantics-d-bpediadq \"Link to presentation\") presented at [I-Semantics 2013](i-semantics.tugraz.at \"I-Semantics 2013\")
- [Link to manuscript](svn.eis.iai.uni-bonn.de/papers/2013/ISemantics_DBpediaDQ/public.pdf  \"Link to manuscript\") accepted at[I-Semantics 2013](i-semantics.tugraz.at \"I-Semantics 2013\")"""^^sysont:Markdown .

projects:DSSN site:content """# content

* <a href=\"http://www.semantic-web-journal.net/sites/default/files/swj201_4.pdf\">The Paper \"An Architecture of a Distributed Semantic Social Network\"</a>
* <a href=\"http://purl.org/net/dssn/\">The Vocabulary (http://purl.org/net/dssn/)</a>
* <a href=\"https://github.com/AKSW/lib-dssn-php/\">A library for PHP @ github</a>
* <a href=\"https://github.com/white-gecko/xodx/\">A PHP implementation @ github</a>
* <a href=\"http://bis.informatik.uni-leipzig.de/de/Lehre/1213/WS/LV/DSSNP\">A practical in the winter semester 2012/13</a> at University of Leipzig (<a href=\"https://github.com/AKSW/dssnp\">@ github</a>)

# presentation

<iframe style=\"border: solid 1px #999; margin: 1em 0;\" width=\"100%\" height=\"500px\" src=\"http://decks.sebastian.tramp.name/2012-10-08-Vorstellung-DSSN-Praktikum/\" frameborder=\"0\" allowfullscreen></iframe>
"""^^sysont:Markdown .

projects:DeFacto site:content """# Introduction

DeFacto (Deep Fact Validation) is an algorithm for validating statements by finding confirming sources for it on the web. It takes a statement (such as \"Jamaica Inn was directed by Alfred Hitchcock\") as input and then tries to find evidence for the truth of that statement by searching for information in the web. In contrast to typical search engines, it does not just search for textual occurences of parts of the statement, but tries to find web pages, which contain the statement phrased in natural language. It presents the user with a confidence score for the input statement as well as a set of excerpts of relevant web pages, which allows the user to manually look at the evidence.

The project has two use cases:
  * given a statement it can be used to find provenance information for the statement
  * it can directly try to check whether a statement is likely to be true

# Architecture and Approach

<a href=\"http://wiki.eis.iai.uni-bonn.de/files/architecture1.png\"><img width=\"100%\" src=\"http://wiki.eis.iai.uni-bonn.de/files/architecture1.png\" /></a>

The DeFacto system consists of the components depicted above. The system takes an RDF triple as input and returns a confidence value for this triple as well as possible evidence for the fact. The evidence consists of a set of webpages, textual excerpts from those pages and meta-information on the pages. The text excerpts and the associated meta information allow the user to quickly get an overview over possible credible sources for the input statement: Instead of having to use search engines, browsing several webpages and looking for relevant pieces of information, the user can more efficiently review the presented information. Moreover, the system uses techniques which are adapted specifically for fact validation instead of only having to rely on generic information retrieval techniques of search engines.

**Retrieving Webpages:** The first task of the DeFacto system is to retrieve webpages which are relevant for the given task. The retrieval is carried out by issuing several queries to a regular search engine. These queries are computed by verbalizing the RDF triple using natural-language patterns extracted by the BOA framework. As a next step, the highest ranked webpages for each query are retrieved. Those webpages are candidates for being sources for the input fact. Both the search engine queries as well as the retrieval of webpages are executed in parallel to keep the response time for users within a reasonable limit. Note that usually this does not put a high load on particular web servers as webpages are usually derived from several domains.

**Evaluating Webpages:** Once all webpages have been retrieved, they undergo several further processing steps. First, plain text is extracted from each webpage by removing most HTML markup. We can then apply our fact confirmation approach on this text. In essence, the algorithm decides whether the web page contains a natural language formulation of the input fact. This step distinguishes DeFacto from information retrieval methods. If no webpage confirms a fact according to DeFacto, then the system falls back on light-weight NLP techniques and computes whether the webpage does at least provide useful evidence. In addition to fact confirmation checking, the system computes different indicators for the trustworthiness of a webpage. These indicators are of central importance because a single trustworthy webpage confirming a fact may be a more useful source than several webpages with low trustworthiness. The fact confirmation and the trustworthiness indicators of the most relevant webpages are presented to the user.

**Confidence Measurement:** In addition to finding and displaying useful sources, DeFacto also outputs a general confidence value for the input fact. This confidence value ranges between 0% and 100% and serves as an indicator for the user: Higher values indicate that the found sources appear to confirm the fact and can be trusted. Low values mean that not much evidence for the fact could be found on the Web and that the websites that do confirm the fact (if such exist) only display low trustworthiness. The training data for this step is available ((https://github.com/AKSW/DeFacto/blob/master/core/resources/training/data.zip?raw=true here)). Naturally, DeFacto is a (semi-)automatic approach: We do assume that users will not blindly trust the system, but additionally analyze the provided evidence.
"""^^sysont:Markdown .

projects:Diachron a foaf:Project, eis:FundedProject ;
                  rdfs:label "DIACHRON" ;
                  foaf:homepage "http://www.diachron-fp7.eu" ;
                  dcterms:abstract """DIACHRON intends to address and cope with certain issues arising from the evolution of the data such as:

(a) Monitor the changes of LOD datasets (tracking the evolution);

(b) Identify the cause of the evolution of the datasets in respect with the real world evolution of the entities the datasets describe (provenance problem);

(c) Repair various data deficiencies (curation problem);

(d)Temporal and spatial quality assessment of the harvested LOD datasets and determination of the datasets versions that need to be preserved (appraisal);

(e) Archive multiple versions of data and cite them accordingly to make the reference of previous data feasible (archiving and citation);

(f) Retrieve and query previous versions (time traveling queries)

The DIACHRON solution aims not only to store previous versions for preservation in case of future need of them, but to create a live repository of the data that captures and highlights data evolution by keeping all data (current and previous) accessible, combined with a toolset that handles the full life cycle of the Data Web.

""" ;
                  foaf:logo <http://www.diachron-fp7.eu/uploads/2/1/2/0/21208652/4006116.png?239> ;
                  doap:maintainer people:ChristophLange ;
                  ns4:endDate "\"2016-03-31+02:00\"^^xsd:date" ;
                  ns4:startDate "\"2013-04-01+02:00\"^^xsd:date" ;
                  eis:hookline "Preserving the Evolving Data Web: Making Open / Linked Data Diachronic" ;
                  eis:partner ns19:ATHENA_Research_and_Innovation_Center_in_Information_Communication_and_Knowledge_Technologies, ns19:Data_Publica, ns16:brox, ns19:Foundation_for_Research_and_TechnologyHellas_Institute_of_Computer_Science, ns19:DataMarket_EHF, ns19:Hanzo_Archives_Ltd, ns19:University_of_Edinburgh, ns19:European_Bioinformatics_Institute, ns19:Intrasoft_International_SA ;
                  eis:promoted "\"true\"^^xsd:boolean" ;
                  eis:status "Ongoing" ;
                  site:content """The Web has not only caused a revolution in communication; it also has completely changed the way we gather and use data. Open data -- data that is available to everyone -- is exponentially growing, and it has completely transformed the way we now conduct any kind of research or scholarship; it has changed the scientific method. The recent development of Linked Open Data has only increased the possibilities for exploiting public data.
Given the value of open data how do we preserve it for future use? Currently, much of the data we use, e.g. demographic records, clinical statistics, personal and enterprise data as well as many scientific measurements cannot be reproduced.

However, there is overwhelming evidence that we should keep such data where it is technically and economically feasible to do so. Until now this problem has been approached by keeping this information in fixed data sets and using extensions to the standard methods of disseminating and archiving traditional (paper) artifacts. Given the complexity, the interlinking and the dynamic nature of current data, especially Linked Open Data, radically new methods are needed.
DIACHRON tackles this problem with a fundamental assumption: that the processes of publishing and preservation data are one and the same. Data are archived at the point of creation and archiving and dissemination are synonymous.

DIACHRON takes on the challenges of evolution, archiving, provenance, annotation, citation, and data quality in the context of Linked Open Data and modern database systems. DIACHRON intends to automate the collection of metadata, provenance and all forms of contextual information so that data are accessible and usable at the point of creation and remain so indefinitely.
The results of DIACHRON are evaluated in three large-scale use cases: open governmental data life-cycles, large enterprise data intranets and scientific data ecosystems in the life-sciences."""^^sysont:Markdown .

projects:EDSA a foaf:Project, eis:FundedProject ;
              rdfs:label "EDSA" ;
              foaf:homepage "http://edsa-project.eu/" ;
              dcterms:abstract "The European Data Science Academy (EDSA) will establish a virtuous learning production cycle whereby we: a) analyse the required sector specific skillsets for data analysts across the main industrial sectors in Europe; b) develop modular and adaptable data science curricula to meet these needs; and c) deliver training supported by multi-platform and multilingual learning resources based on our curricula. The curricula and learning resources will be continuously evaluated by pedagogical and data science experts during both development and deployment." ;
              foaf:logo <http://edsa-project.eu/edsa-data/themes/edsa/images/edsa-logo.png> ;
              doap:maintainer people:SoerenAuer ;
              ns4:startDate "2015-02-25"^^xsd:date ;
              eis:hookline " European Data Science Academy" ;
              eis:status "Ongoing" .

projects:Erfurt site:content """* Triple Storage: storage abstraction layer to access third party RDF stores as well as its own Zend DB based RDF store
* Storage Abstraction: two different interfaces for the storage abstraction: Zend DB and Virtuoso
* Erfurt RDF Store: SPARQL to SQL rewriter and a corrsponding relational table layout
* Caching: based on analysing the graph patterns of cached SPARQL queries in order to obtain information which updates will change the query result
* More: Access Control, Versioning, SPARQL Query & Update, Plugins & Trigger, Datagathering & Data Wrapper"""^^sysont:Markdown .

projects:FTS dcterms:abstract """The Financial Transparency System (FTS) of the European Commission contains information about grants for European Union projects starting from 2007. It allows users to get an overview on EU funding, including information on beneficiaries as well as the amount and type of expenditure and information on the responsible EU department. The original dataset is freely available on the European Commission website, where users can query the data using an HTML form and download it in CSV and most recently XML format. The result of the conversion allows interesting queries over the data, which were very difficult without it. The main benefit of the dataset is an increased financial transparency of EU project funding. The RDF version of the FTS dataset will become part of the EU Open Data Portal and eventually be hosted and maintained by the European Union itself.
""" ;
             site:content """The original dataset can be found at [EU Commission Financial Transparency System](http://ec.europa.eu/beneficiaries/fts/find_en.htm \"EU Commission Financial Transparency System\") .

Currently, the raw data of 2007, 2008, 2009, 2010 and 2011 is converted into RDF using the depicted vocabulary."""^^sysont:Markdown .

projects:Facete site:content """# Aim

The goal of this project is to ease the navigation of RDF data in SPARQL endpoints using advanced faceted search techniques and the provision of corresponding visualization widgets.

# Features
* Works for large datasets: If a region contains too many items, the user is required to zoom in.
* Pure Java Script code base for enabling easier integration into other websites
* Server component only needs to be a SPARQL endpoint
* Pivoting
"""^^sysont:Markdown .

projects:GHO site:content """The converted GHO data is now available at [http://gho.eis.iai.uni-bonn.de/](http://gho.eis.iai.uni-bonn.de/ \"http://gho.eis.iai.uni-bonn.de/\"). After converting the entire GHO data, an RDF dataset containing almost 8 million triples was obtained. Following is the example of a single statistical item, the death value of 1098, from the GHO dataset represented using the Data Cube vocabulary:

    gho:o1     a           qb:Observation;
           gho:Country     Afghanistan;
           gho:stat_pop    24076;
           gho:Disease     All Causes;
           gho:incidence   18437.

    gho:Country    a    qb:DimensionProperty;
                        rdfs:label    \"Country\".

    gho:Disease    a    qb:DimensionProperty;
                        rdfs:label    \"Disease\".

Further Information
===================
- This is a [short presentation](https://docs.google.com/leaf?id=0B8Mh-RR0aBWQNDRjM2UyMmEtOTNlZC00ZDIwLTg5ZDMtMGZkYTc1YWVjNDRh&hl=en&authkey=CIr8_MYN \"short presentation\") describing the process of conversion of the CSV files to RDF using [SCOVO](http://sw.joanneum.at/scovo/schema.html \"SCOVO\") (Statistical Core Vocabulary) in OntoWiki. SCOVO is an earlier version of the Data Cube Vocabulary and the conversion process is similar for both.
- This is a [position paper](https://docs.google.com/fileview?id=0B8Mh-RR0aBWQODU1ZmM3M2QtOGNiNi00YWY0LTkzYjctYmVlMzViMDRkNGI1&hl=en&authkey=CMeV1cMC \"position paper\") that was accepted for a presentation at the [Ontologies in Biomedicine and Life Sciences](https://wiki.imise.uni-leipzig.de/Gruppen/OBML/Workshops/2010en \"Ontologies in Biomedicine and Life Sciences\") workshop held at Mannheim (Germany) from September 9 – 10, 2010.
- The dataset description has been published [here](http://www.semantic-web-journal.net/content/publishing-and-interlinking-global-health-observatory-dataset \"here\").
- This dataset is also part of the [LODD datasets](http://esw.w3.org/HCLSIG/LODD/Data \"LODD datasets\")."""^^sysont:Markdown .

projects:GOLD site:content """- duration: 1.5 years
- funded by German Research Foundation (Deutsche Forschungsgemeinschaft DFG)
"""^^sysont:Markdown .

projects:GeoKnow site:content """* Duration: 2012–2015
* Funding Programme: FP7-ICT-2011–8 (Collaborative Project - STReP)

# What

* Bring geospatial knowledge integration to the Linked Data Web
* Billion-triple geospatial reasoning and data provenance
* Qualitative interlinking and fusing of geospatial and semantic information
* Adaptive geospatial exploration, authoring and curation

# Why

* Unlock isolated islands of geographic information
* 80% of all data has some spatial dimension, most of it is not processable today
* Geographic data authoring with millions of users requires powerful tools

# For whom

* Added value for the companies and the Linked Data Web community
* Cost-effective data integration for SMEs
* Enterprises can add value to their data with volunteered geographic information
* Users from travel industry will benefit from more background information
"""^^sysont:Markdown .

projects:GeoLift rdfs:comment """Spatial mapping framework for enriching RDF datasets with Geo-spatial information.
"""^^sysont:Markdown ;
                 dcterms:abstract """GeoLift is a spatial mapping component aims to enrich RDF datasets with geo-spatial information. To achieve this goal, GeoLit relies on three atomic modules based on dereferencing, linking and NLP. GeoLift implemented in Java as an open-source project.
"""^^xsd:string ;
                 site:content """General Overview
================

Geographical information can be mentioned in three different ways within Linked Data:

1. **Through dereferencing:** Several datasets contain links to datasets with explicit geographical information such as DBpedia or LinkedGeoData. For example, in a music dataset, one might find information such as http://example.org/Leipzig owl:sameAs http://dbpedia.org/resource/Leipzig. We call this type of reference explicit. We can now use the semantics of RDF to fetch geographical information from DBpedia and attach it to the resource in the other ontology as http://example.org/Leipzig and http://dbpedia.org/resource/Leipzig refer to the same realworld object.

2. **Through linking:** It is known that the Web of Data contains an insufficient number of links. The latest approximations suggest that the Linked Open Data Cloud alone consists of 31+ billion triples but only contains approximately 0.5 billion links (i.e., less than 2% of the triples are links between knowledge bases). The second intuition behind GeoLift is thus to use link discovery to map resources in an input knowledge base to resources in a knowledge that contains explicit geographical information. For example, given a resource http://example.org/Athen, GeoLift should aim to find a resource such as http://dbpedia.org/resource/Athen to map it with. Once having established the link between the two resources, GeoLift can then resolve to the approach defined above.

3. **Through Natural Language Processing:** In some cases, the geographic information is hidden in the objects of data type properties. For example, some datasets contain biographies, textual abstracts describing resources, comments from users, etc. The idea here is to use this information by extracting Named Entities and keywords using automated Information Extraction techniques. Semantic Web Frameworks such as FOX have the main advantage of providing URIs for the keywords and entities that they detect. These URIs can finally be linked with the resources to which the datatype properties were attached. Finally, the geographical information can be dereferenced and attached to the resources whose datatype properties were analyzed.


The idea behind GeoLift is to provide a generic architecture that contains means to exploit these three characteristics of Linked Data. In the following, we present the technical approach underlying GeoLift.

GeoLift Architecture
====================

GeoLift was designed to be a modular tool which can be easily extended and re-purposed. In its first version, it provides two main types of artifacts:

1. **Modules:** These artifacts are in charge of generating geographical data based on RDF data. To this aim, they implement the three intuitions presented above. The input for such a module is an RDF dataset (in Java, a Jena Model ). The output is also an RDF dataset enriched with geographical information (in Java, an enriched Jena Model ).

2. **Operators:** The idea behind operators is to enable users to define a workflow for processing their input dataset. Thus, in case a user knows the type of enrichment that is to be carried out (using linking and then links for example), he can define the sequence of modules that must be used to process his dataset. Note that the format of the input and output of modules is identical. Thus, the user is empowered to create workflows of arbitrary complexity by simply connecting modules.

GeoLift architecture is divided to four layers. The input layer allows reading RDF in different serializations. The enrichment modules are in the second layer and allow adding geographical information to RDF datasets by different means. The operators (which will be implemented in the future version of GeoLift) will combine the enrichment modules and allow defining a workflow for processing information. The output layer serializes the results in different format. The enrichment procedure will be monitored by implementing a controller, which will be added in the future version of GeoLift.

"""^^sysont:Markdown .

projects:LATC site:content """* Duration: 2010–2012
* Funding Programme: FP7-ICT-2009.4.3 (Support Action)
"""^^sysont:Markdown .

projects:LDAP site:content """* [LDAP2SPARQL](http://sourceforge.net/projects/ldap2sparql/) is a backend to the widely used OpenLDAP server. It translates LDAP queries into SPARQL queries, asks a SPARQL endpoint and translates the result back to LDIF.
* [LDAP2OWL](https://github.com/seebi/ldap2owl) converts a directory information tree (DIT) complete with schema information (which will translated into an OWL ontology) and directory objects to an RDF model.
"""^^sysont:Markdown .

projects:LE4SW site:content """* Duration: 2009–2011
* Funding Programme: WK Potential, German Ministry of Education and Research (BMBF)
"""^^sysont:Markdown .

projects:LIMES site:content """General Overview
------------------
LIMES implements novel time-efficient approaches for link discovery in metric spaces. Our approaches different approximation techniques to compute estimates of the similarity between instances. These estimates are then used to filter out a large amount of those instance pairs that do not suffice the mapping conditions. By these means, LIMES can reduce the number of comparisons needed during the mapping process by several orders of magnitude. The approaches implemented in LIMES include the [original LIMES](http://ijcai.org/papers11/Papers/IJCAI11-385.pdf \"IJCAI LIMES\") algorithm for edit distances, [REEDED](http://www.dit.unitn.it/~p2p/OM-2013/om2013_Tpaper1.pdf \"REEDED\") for weighted edit distances, [HR3](http://link.springer.com/chapter/10.1007%2F978-3-642-35176-1_24 \"HR3\"), [HYPPO](http://link.springer.com/article/10.1007%2Fs13740-012-0012-y \"HYPPO\"), and [ORCHID](http://link.springer.com/chapter/10.1007%2F978-3-642-41335-3_25 \"ORCHID\"). Moreover, LIMES implements supervised and unsupervised machine-learning algorithms for finding accurate link specifications. The algorithms implemented here include the supervised, active and unsupervised versions of [EAGLE](http://svn.eis.iai.uni-bonn.de/papers/2012/ESWC_EAGLE/public.pdf \"EAGLE\"), [COALA](http://link.springer.com/chapter/10.1007%2F978-3-642-38288-8_30 \"COALA\") and [EUCLID](http://www.dit.unitn.it/~p2p/OM-2013/om2013_Tpaper3.pdf \"EUCLID\").

Architecture
------------------

The LIMES framework consists of seven main modules of which each can be extended to accommodate new or improved functionality. The central modules of LIMES are the **controller module**, which coordinates the matching process and the **data module**, which contains all the classes necessary to store data.
The matching process is carried out as follows: First, the **controller** calls the **I/O-module**, which reads the configuration file and extracts all the information necessary to carry out the comparison of instances, including the URL of the SPARQL-endpoints of the knowledge bases, the restrictions on the instances to map (e.g., their type), the expression of the metric to be used and the threshold to be used. Examples of configuration files can be found in the distribution.

Given that the configuration file is valid w.r.t. the LIMES Specification Language (LSL), the **query module** is called. This module uses the configuration for the target and source knowledge bases to retrieve instances and properties from the SPARQL-endpoints of the source and target knowledge bases that adhere to the restrictions specified in the configuration file. The query module writes its output into a **cache**, which can be a file (for large number of instances, not implemented yet) or main memory. Once all instances have been stored in the cache, the controller calls the LIMES **engine** which runs through the specification and computes the results. The results are finally returned as RDF or TSV files.

Running LIMES
------------------

Running LIMES can be carried in one of three ways.
<ol>
<li>You can use our hosted <a href=http://limes.eis.iai.uni-bonn.de></a> Linking Service</a>, </li>
<li>Download the <a href=https://github.com/AKSW/LIMES>LIMES package</a> (includes a user manual) and run it locally on your server or</li>
<li>Use the LIMES webservice programmatically at the <a href=http://139.18.2.164:8080/axis2/services/LimesServiceImpl> LIMES Linking Server</a>. A client for tests be found <a href=http://139.18.2.164:8080/LimesWebService_Client.jar> here</a>. The short description (the manual will be out soon) can be found <a href=https://github.com/KLyko/LimesWebService/wiki/Deployed-Version> here</a>.
</li></ol>"""^^sysont:Markdown .

projects:LOD2 site:content """* Duration: 2010–2014
* Funding Programme: FP7-ICT-2009–5 (Collaborative Project)
"""^^sysont:Markdown .

projects:LUCID a foaf:Project, eis:FundedProject ;
               rdfs:label "LUCID" ;
               foaf:homepage "http://lucid-project.org/" ;
               dcterms:abstract """LUCID is a BMBF funded 2-year project which will change the way how partners in supply chain networks will communicate with each other. In LUCID we research and develop on Linked Data technologies in order to allow partners in supply chains to describe their work, their company and their products for other participants. This allows for building distributed networks of supply chain partners on the Web without a centralized infrastructure.

LUCID is funded by the german Federal Ministry of Education and Research (BMBF) in KMU-innovativ: Informations- und Kommunikationstechnologien initiative, which part of the IKT 2020 - Forschung für Innovation funding programme.""" ;
               foaf:logo <http://lucid-project.org/static/img/logo-lucid-project.org.png> ;
               doap:maintainer people:NiklasPetersen ;
               eis:hookline "LINKED VALUE CHAIN DATA" ;
               eis:partner ns16:Infineon_Technologies_AG, ns23:id, ns19:Automotive_Partner_Assotiation, ns16:brox, ns16:Implisense_GmbH ;
               eis:status "Ongoing" ;
               site:content """LUCID is a BMBF funded 2-year project which will change the way how partners in supply chain networks will communicate with each other. In LUCID we research and develop on Linked Data technologies in order to allow partners in supply chains to describe their work, their company and their products for other participants. This allows for building distributed networks of supply chain partners on the Web without a centralized infrastructure.

LUCID is funded by the german Federal Ministry of Education and Research (BMBF) in KMU-innovativ: Informations- und Kommunikationstechnologien initiative, which part of the IKT 2020 - Forschung für Innovation funding programme."""^^sysont:Markdown .

projects:Linda a foaf:Project, eis:FundedProject ;
               rdfs:label "LinDA" ;
               foaf:homepage "http://linda-project.eu" ;
               dcterms:abstract "The LinDA project addresses one of the most significant challenges of the usage and publication of Linked Data, the renovation and conversion of existing data formats into structures that support the semantic enrichment and interlinking of data. The set of tools provided by LinDA will assist enterprises, especially SMEs which often cannot afford the development and maintenance of dedicated information analysis and management departments, in efficiently developing novel  data analytical services that are linked to the available public data therefore contributing to improve their competitiveness and stimulating the emergence of innovative business models." ;
               foaf:logo <http://linda-project.eu/wp-content/uploads/2014/02/linda_logo11.png> ;
               doap:maintainer people:SoerenAuer ;
               ns4:endDate "\"2015-11-31+02:00\"^^xsd:date" ;
               ns4:startDate "\"2013-12-01+02:00\"^^xsd:date" ;
               eis:hookline "Enabling Linked Data and Analytics for SMEs by renovating public sector information" ;
               eis:partner ns19:TTNews24, ns19:Fraunhofer_FOKUS, ns19:National_Technical_University_of_Athens, ns19:HYPERBOREA_SRL, ns19:Piksel_SpA, ns19:Critical_Publics_Ltd, ns19:UBITECH ;
               eis:promoted "\"true\"^^xsd:boolean" ;
               eis:status "Ongoing" ;
               site:content """EU Research embraces SMEs for adding value to everyday operations through the introduction of Linked Open Data

LinDA (Enabling Linked Data and Analytics for SMEs by renovating public sector information - Grant Agreement No: FP7-610565) is an EC co-funded project under the 7th Framework Programme comprised of leading Linked Open Data technology researchers and SMEs and Industries that have seen a clear benefit in adopting the Linked Data paradigm to increase their competitiveness and become world leaders in their service offering activities.

Following up on the recent developments in the fields of Linked and Open Data, LinDA will provide an infrastructure of technologies and methods for porting the advantages of the above-mentioned technological fields to the actual production line of enterprises, with a focus on EU SMEs. In doing so, LinDA will address one of the most significant challenges of the usage and publication of Linked Data, the renovation and conversion of existing data formats into structures that support the semantic enrichment and interlinking of data, thus minimizing the required effort and cost as well as potential semantic conflicts and ambiguities. The LinDA ecosystem of publication and consumption Apps will significantly motivate SMEs to follow the Linked Data paradigm for the publication of open data therefore realizing the full potential of linking, analysing and mashing-up data as well as stimulating new, innovative business models.

LinDA is a 2-year collaborative research and development project that started in December 2013 and is coordinated by the DSSLab research group at National Technical University of Athens (Greece). Consortium partners include: Fraunhofer FOKUS (Germany), UBITECH (Greece), University Of Bonn (Germany), Piksel (Italy), Critical Publics (United Kingdom), Hyperborea (Italy) and TTNews24 (Italy).

The results of the LinDA project are foreseen to have a significant impact on the efficiency of the information management of enterprises, especially SMEs that in most cases cannot afford the development and maintenance of dedicated information analysis and management departments. As such, the cost-efficient development of innovative services and data analytical services that are linked to the available public data will provide SMEs a strong competitive advantage in the market, and will in this way contribute to the competence of the European industry. """^^sysont:Markdown .

projects:LinkedGeoData site:content """# Background

Spatial data is crucial for the Semantic Data Web in order to interlink geographically linked resources.
The [OpenStreetMap](http://openstreetmap.org/) project collects, organizes and publishes geo data the wiki way. Currently the 80.000 Open Street Map users collected data about 22.000.000km ways (roads, highways etc.) on earth. 25.000km are added daily. The Open Street Map database also contains a vast amount of structured information about points-of-interest such as for example shops, amenities, sports venues, businesses, touristic and historic sights.

# Aim

The goal of this project is to publish OSM geo data, interlink it with other data sources and provide efficient means for browsing and authoring. We aim at working as closely as possible with both the OSM and LOD communities.

# Components

The project currently consists of three components:

* Open Street Map data extraction currently works on the basis of OSM database dumps. A live-sync module keeps the data in our SPARQL endpoints up-to-date.
* [LinkedGeo Data browser](http://linkedgeodata.org/browser/ \"LinkedGeo Data browser\") is based on Javascript widgets, which can display the data from the Linked Geo Data SPARQL endpoints. Support for endpoints of other projects in the works.
- A Server providing a Linked Data Interface and a REST API, that grant access to RDFized data based on a (relational) OSM database.

# Links

* [SPARQL Endpoint](http://linkedgeodata.org/OnlineAccess/SparqlEndpoints \"SPARQL Endpoint\")
* [REST API](http://linkedgeodata.org/OnlineAccess/RestApi \"REST API\")
"""^^sysont:Markdown .

projects:LinkedHistory site:content """The first established service uses the PND-key to interlink persons.
[Detailed Information](http://wiki.eis.iai.uni-bonn.de/Projects/LinkedHistory/PND?v=1cnr)

The second service provides interlinking of calender years.
[Detailed Information](http://wiki.eis.iai.uni-bonn.de/Projects/LinkedHistory/calendar?v=17ri)"""^^sysont:Markdown .

projects:LinkingLOD site:content """- duration: 2 years
- funded by German Research Foundation (Deutsche Forschungsgemeinschaft DFG)
"""^^sysont:Markdown .

projects:Luzzu a foaf:Project, eis:OpenSourceProject ;
               rdfs:label "Luzzu", "SemAnn" ;
               foaf:homepage "http://eis-bonn.github.io/Luzzu", "http://github.com/AKSW/semann" ;
               dcterms:abstract """Luzzu is a Quality Assessment Framework that provides an integrated platform that: (1) assesses Linked Data quality using a library of generic and user-provided domain specific quality metrics in a scalable manner; (2) provides queryable quality metadata on the assessed datasets; (3) assembles detailed quality reports on assessed datasets.
Furthermore, we aim to create an infrastructure that:
<ul><li>can be easily extended by users by creating their custom and domain-specific pluggable metrics, either by employing a novel declarative quality metric specification language or conventional imperative plugins;</li>
<li>employs a comprehensive ontology framework for representing and exchanging all quality related information in the assessment workflow;</li>
<li>implements quality-driven dataset ranking algorithms facilit- ating use-case driven discovery and retrieval.</li>
</ul>""", """SemAnn is a web-based semantic annotation tool for PDF documents.
SemAnn allows you to semantically annotate (using RDF triples) text in PDFs. These annotations are then used for recommending similar PDF documents that the reader might find relevant.""" ;
               doap:maintainer people:JeremyDebattista ;
               eis:hookline "A Quality Assessment Framework for Linked Open Datasets", "A web-based semantic annotation tool for PDF documents" ;
               eis:status "Ongoing" .

projects:MobiVoc a foaf:Project, eis:CommunityProject ;
                 rdfs:label "MobiVoc" ;
                 skos:prefLabel "Mobility Vocabulary" ;
                 foaf:homepage <http://mobivoc.org> ;
                 dcterms:abstract """MobiVoc - Open Mobility Vocabulary aims to support the mobility of humans by the mobility of data.







""", "MobiVoc - Open Mobility Vocabulary aims to support the mobility of humans by the mobility of data." ;
                 foaf:logo <http://www.mobivoc.org/static/img/logo-www.mobivoc.org.png> ;
                 doap:maintainer people:NataljaFriesen ;
                 eis:hookline "Open Mobility Vocabulary" ;
                 eis:partner ns19:Automotive_Partner_Assotiation, ns16:brox, ns19:Bremer_Institut_fuer_Produktion_und_Logistik_GmbH ;
                 eis:promoted "1"^^xsd:integer ;
                 eis:status "Ongoing" ;
                 site:content """
Future mobility poses new challenges for the innovative data-based services. Some examples are: route planning according to energy aspects or multimodal mobility services - sharing services, public transportation, taxis in complex environments. Development of such services requires integration of various data sources: e.g. map data, vehicle data, weather data, mobility service descriptions, events information, etc. These data sets often have proprietary data structures. The MobiVoc  initiative MobiVoc intends to enable a data communication among all available data sources by providing a powerfyl vocabulary for modeling the mobility data. """^^sysont:Markdown ;
                 <doap:browse> <https://github.com/MobiVoc> .

projects:NIF4OGGD dcterms:abstract """In the last couple of years the amount of structured open
government data has increased significantly. Already now, citizens are able to leverage the advantages of open data through increased transparency and better opportunities to take part in governmental decision
making processes. Our approach increases the interoperability of existing but distributed open governmental datasets by converting them to the RDF-based NLP Interchange Format (NIF). Furthermore, we integrate the converted data into a geodata store and present a user interface for querying this data via a keyword-based search. The language resource generated in this project is publicly available for download and via a dedicated SPARQL endpoint.
""" .

projects:NKE site:content """Links
==================
- [Slides](http://slideshare.net/kurzum/navigationinduced-knowledge-engineering-by-example \"Slides\")
- Unpublished working draft: [ISWC 2012 submission](http://svn.eis.iai.uni-bonn.de/papers/2011/WWW_NKE/public/iswc_nke.pdf \"ISWC 2012 submission\")
- ISWC 2012 Submission [Evaluation Details](http://svn.eis.iai.uni-bonn.de/papers/2011/WWW_NKE/public/Matching_Results_final.pdf \"Evaluation Details\") and the [respective script and raw data](http://svn.eis.iai.uni-bonn.de/papers/2011/WWW_NKE/public/nke_experiment.tar.gz \"respective script and raw data\").
- [Tutorial Slides](http://svn.eis.iai.uni-bonn.de/papers/2011/WWW_NKE/hanne_tutorial/hanne_tutorial_public.pdf \"Tutorial Slides\")
- [HANNE – ISWC Demo paper](http://iswc2010.semanticweb.org/pdf/522.pdf \"HANNE – ISWC Demo paper\")
- [Google Code project](http://code.google.com/p/nlp2rdf/ \"Google Code project\")
- Corpus Linguistics: [The TIGER Corpus Navigator](https://dspace.utlib.ee/dspace/bitstream/10062/15937/1/tlt9_submission_33.pdf \"The TIGER Corpus Navigator\")

Introduction
==================
 Whenever a consumer enters a department store selling groceries, the way the shelves are sorted and arranged will have been predefined by the store owner. This order might be useful in some cases (where the tooth brush is next to the tooth paste), but in other cases it won't be. If one consumer is searching for protein-rich food, the ideal place to search would be a shelf, with food that is rich of protein. Imagine another consumer, who was searching for the same thing a day before. Imagine she would have taken the effort to go around the store, collect all matching food products and put it on one shelf. Wouldn't this be useful?

In a brick and mortar store such a reordering is impossible for the lack of space alone. But in a digital store, it would not be a shelf, but just another category in the category tree and reordering doesn't require lifting heavy things. With NKE the complexity of creating such categories is disguised as navigation and reduced to selecting examples.

A walkthrough example
==================
 A user is entering the site [http://amazon.com](http://amazon.com \"http://amazon.com\") with the intention to find a selection “2.5 inch external hard drive with 500 GB”. She might proceed as follows:

1. String search for “hard drive” [Amazon search](http://www.amazon.com/s/ref=nb_sb_noss?url=search-alias%3Daps&field-keywords=hard+drive&x=0&y=0 \"Amazon search\").
2. Click on the category “external harddrive” on the left [hierarchy](http://www.amazon.com/gp/search/ref=sr_nr_scat_595048_ln?rh=n%3A595048%2Ck%3Ahard+drive&keywords=hard+drive&ie=UTF8&qid=1291677843&scn=595048&h=d3e44641a0f454bc51210142a7d0d17e57d7b515 \"hierarchy\").
3. Instead of reformulating the string search, the user will now be able to switch into an “Active Learning” mode in which she can create a list of products, which she is searching for and the ones she she does not search.

- Matching (positive examples): [Toshiba Canvio Plus 500 GB USB 2.0 Portable External Hard Drive](http://www.amazon.com/Toshiba-Canvio-Portable-External-E05A050CAU2XK/dp/B003ICWB5Y/ref=sr_1_6?s=pc&ie=UTF8&qid=1291678407&sr=1-6 \"Toshiba Canvio Plus 500 GB USB 2.0 Portable External Hard Drive\"), [Seagate Expansion 500 GB USB 2.0 Portable External Hard Drive](http://www.amazon.com/Seagate-Expansion-Portable-External-ST905004EXA101-RK/dp/B001UHWHO4/ref=sr_1_14?s=pc&ie=UTF8&qid=1291678407&sr=1-14 \"Seagate Expansion 500 GB USB 2.0 Portable External Hard Drive\")

- Not matching (negative examples): [Western Digital My Passport
Essential SE 1 TB USB 3.0 and USB 2.0](http://www.amazon.com/Passport-Essential-Portable-External-WDBACX0010BBK-NESN/dp/B0041OSQ9S/ref=sr_1_3?s=pc&ie=UTF8&qid=1291678407&sr=1-3 \"Western Digital My Passport
Essential SE 1 TB USB 3.0 and USB 2.0\"), [Western Digital WD Elements 1 TB USB 2.0 Desktop External Hard Drive](http://www.amazon.com/Western-Digital-Elements-External-WDBAAU0010HBK-NESN/dp/B002QEBMB4/ref=sr_1_1?s=pc&ie=UTF8&qid=1291678407&sr=1-1 \"Western Digital WD Elements 1 TB USB 2.0 Desktop External Hard Drive\")

Based on this input, an algorithm is able to produce a much preciser recommendation than by analyzing click behavior, because the user is now actually able to directly model the search enquiry by stating examples. In case the recommendation matches the conception of the user, she is able to save it and give it a name, i.e. “2.5'' external hard drives with 500 GB”. This so created category is now available to be incorporated into Amazons hierarchy and will be shown to the next user with the same search intention.

If the Web 3.0 is about “structured data created by a massive user base” then it might mean on the one hand that facts are collected, but on the other hand it might as well mean that users will be able to structure data by navigating, searching and using it. Thus a reciprocal relation is formed between the information need of users and the structure gain through the created taxonomy.

Vision (defining and elaborating the concept of NKE)
==================
Most of the text is taken from our yet unpublished [WWW 2011 submission](http://svn.eis.iai.uni-bonn.de/papers/2011/WWW_NKE/nke_public_draft.pdf \"WWW 2011 submission\").

Formal Definition
==================
Navigational Knowledge Engineering is the manifestation of labeled examples by interpreting user navigation, combined with the active correction and refinement of these examples by the user to create an ontology of user interests through supervised active machine learning.

The NKE methodology consists of three distinct yet interrelated steps:

1. **Navigation**: NKE starts by interpreting navigational behavior of users to infer an initial (seed) set of positive and negative examples.
2. **Iterative Feedback**: NKE supports users in interactively refining the seed set of examples such that the final set of objects satisfies the users’ intent.
3. **Retention**: NKE allows users to retain previously explored sets of objects by grouping them and saving them for later retrieval.

The vision of NKE is to enable low-cost knowledge engineering on the largest possible scale – the Web. The most fundamental consequence of the paradigm is that value is added to data by just navigating and using it. A reciprocal relation is formed between the information need of users and the information gain through the created taxonomy. Although structured data is becoming widely available, no other methodology – to the best of our knowledge (Nov 2010) – is currently able to scale up and provide light-weight knowledge engineering for a massive user base. Using NKE, data providers can publish flat data on the Web without creating any structure **upfront**, but rather observe how structure is created **on the fly** by interested users, who navigate the knowledge base and at the same time also benefit from using it.
As an ontology is created by user navigation, it can be used directly to improve further navigation. For other purposes the ontology might not be used directly, but it can be seen as raw material, that needs to be refined and curated by an ontology expert, a system admin or moderator, employed by the data provider. Two users on Amazon.com searching for 2.5 inch external hard drives might save two intentionally different concepts with a similar extension: “hard drives without an extra power cord” and “hard drives measuring 2.5 inches”. An easy improvement by a knowledge curator would be to define equivalence between these concepts (e.g. via an owl:equivalentClass axiom). The knowledge curator could also review the user-generated ontology in regular intervals and select good concepts to be included into a domain ontology.

Prototype (a description of our prototypical implementation)
==================
The methodology is demonstrated with [HANNE](http://hanne.eis.iai.uni-bonn.de/ \"HANNE\"), a Semantic Web system which enables users and domain experts to navigate over knowledge bases by selecting examples. From these examples, formal OWL class expressions are created and refined by a scalable Iterative Learning approach. When saved by users, these class expressions form an expressive OWL ontology, which can be exploited in numerous ways: as navigation suggestions, as a hierarchy for browsing and as input for a team of ontology editors. In particular, we developed an NKE tool named HANNE (*H*olistic *A*pplication for *N*avigational K*N*owledge *E*ngineering), which implements the NKE method. In this tool, users can search for resources and mark them as relevant (+) and irrelevant (-). Machine learning techniques use this to explore the underlying concept a user is looking for. The demo is available at [http://hanne.eis.iai.uni-bonn.de](http://hanne.eis.iai.uni-bonn.de \"http://hanne.eis.iai.uni-bonn.de\"), the source code can be downloaded from the [Google code project](http://code.google.com/p/nlp2rdf/ \"Google code project\") and a screenshot is shown below:
<img width=\"100%\" src=\"http://wiki.eis.iai.uni-bonn.de//Projects/NKE/files?get=screenshot_real_countries_refined.png\" />

How to use NKE (A tutorial on how to integrate it into a custom system)
=======================================================================

NKE is a methodology, which can be implemented with existing technology and on integrated easily with existing solutions. We will explain the three steps necessary to get a working NKE system and then show some Mockups of how existing portals can be upgraded with NKE. Please tell us, if you find an application, which employs NKE.

3 steps to NKE
==============
1. Your data has to be in a resource-feature scheme. The RDF format for example provides it by design. The resources are objects, which are of interest to the users such as articles in Wikipedia and products on Amazon.com. These objects are described by features, which could be basically any additional data describing the objects such as tags, key-value pairs, any kind of metadata or concrete values such as title, birthdate, salary or price and weight. This is necessary, so a learning algorithm can be provided with the needed input.
2. Choose an entry point for NKE. Before users can actively indulge in NKE, they need to find initial seed examples to start the iterative feedback loop. A non-exhaustive list of displaying objects of interest is given here:
  - Browse down a hierarchy of categories and display the members: [UKAT](http://www.ukat.org.uk/thesaurus/hierarchy.php \"UKAT\")
  - Choose facets: [Faceted Wikipedia Search](http://dbpedia.neofonie.de/browse/ \"Faceted Wikipedia Search\")
  - Anything [Solr](http://lucene.apache.org/solr/ \"Solr\") has to offer
  - A string or keyword search

3. Implement some way for the user to choose positive and negative examples and give him the means to manage such lists. The main incentive for users is that they can manage and order their own dataspace or save those lists to come back later. Allow him to give names to the lists he created. These names are important as they will be the concept names of the resulting ontology. Use supervized active machine learning to find new matching examples so the user can refine the list. There are many off-the-shelf frameworks for machine learning algorithms that can be used. For HANNE we used the [DL-Learner](http://eis.iai.uni-bonn.de/Projects/DLLearner \"DL-Learner\"), which works on arbitrary [RDF/OWL knowledge bases of arbitrary size](http://jens-lehmann.org/files/2009_dllearner_sparql.pdf \"RDF/OWL knowledge bases of arbitrary size\"). [RapidMiner](http://en.wikipedia.org/wiki/RapidMiner \"RapidMiner\") is also an option.

**That's it**. As soon as users start to save the learned concepts and give them names, an ontology of user interests will start growing. Now it is your choice what to do. Here are three suggestions:

- Show them back to the users as Navigation Suggestions
- Integrate them into you category system for Browsing
- Use it to create and extend your Domain Ontology

Mockups
=======
<img width=\"100%\" src=\"http://svn.eis.iai.uni-bonn.de/papers/2011/WWW_NKE/mockups/Wikipedia_Soccer_clubs_in_Saxony_mockup_public.png\" />

<img width=\"100%\" src=\"http://svn.eis.iai.uni-bonn.de/papers/2011/WWW_NKE/mockups/Amazon_hard_drives_mockup_public.png\" />
"""^^sysont:Markdown .

projects:ODINE a foaf:Project, eis:FundedProject ;
               rdfs:label "ODINE" ;
               foaf:homepage "http://opendataincubator.eu/" ;
               dcterms:abstract "The first Open Data Incubator for Europe. Europe is supporting the next generation of digital businesses. The Open Data Incubator for Europe (ODINE) is part of that support - it helps European citizens build sustainable businesses using open data. It will offer up to €100.000 and will set up an environment and EU-wide network, including business angels, VCs and funding agencies, to support small and medium enterprises and startups in creating commercial value from open data. " ;
               foaf:logo <https://pbs.twimg.com/profile_images/528207349102546944/4u1k9xZh_400x400.png> ;
               doap:maintainer people:SoerenAuer ;
               ns4:endDate "2017-08-01"^^xsd:date ;
               ns4:startDate "2015-02-01"^^xsd:date ;
               eis:hookline "Open Data Incubator for Europe" ;
               eis:partner ns16:Open_Data_Institute, ns16:University_of_Southampton ;
               eis:status "Ongoing" ;
               site:content """We are pleased to announce the launch of the first Open Data Incubator for Europe. Europe is supporting the next generation of digital businesses. The Open Data Incubator for Europe (ODINE) is part of that support - it helps European citizens build sustainable businesses using open data. It will offer up to €100.000 and will set up an environment and EU-wide network, including business angels, VCs and funding agencies, to support small and medium enterprises and startups in creating commercial value from open data. Our approach in ODINE is to become facilitators in Europe, providing the tools and the contacts and bringing together data owners, entrepreneurs, investors and other players like Business Schools and Computer/Data training institutions, with the objective in mind of strengthening Europe’s competitive position. ODINE will provide an accelerator programme for SMEs and startups to establish business in open data related areas. In the programme, we will offer expert advisories from serial entrepreneurs and coaching from business schools. The successful graduations of the incubation programme will be further put forward to VCs within the networking, who will invest in the most innovative data-driven startups. Technologically, ODINE will set up a fully-fledged platform that will support the life cycle of the open data, from its generation, publication, and storage to the subsequent usage by the participants of the programme. By initiating an EU-wide industrial focused network, ODINE will not only attract entrepreneurs, but also engage with young innovators and students from universities by organising innovation labs and help them to critically revise their raw open data business ideas.
"""^^sysont:Markdown .

projects:ORE site:content """**Ontology Debugging**: ORE uses OWL reasoning to detect inconsistencies and unsatisfiable classes. State-of-the-art methods are then used to detect the most likely sources for the problems. In a simple process, the user can create a repair plan to resolve a problem, while maintaining full control over desired and undesired inferences.

**Ontology Enrichment**: ORE uses the DL-Learner framework to suggest definitions and super classes for existing classes in the knowledge base. This works if instance data is available and can be used to detect potential problems and harmonise schema and data in the knowledge base."""^^sysont:Markdown .

projects:OntoWikiEU site:content """* Duration: 2008–2010
* Funding Programme: FP7-SME
"""^^sysont:Markdown .

projects:OpenAIRE2020 a foaf:Project, eis:FundedProject ;
                      rdfs:label "OpenAIRE2020" ;
                      foaf:homepage "http://www.openaire.eu" ;
                      dcterms:abstract "OpenAIRE2020 represents a pivotal phase in the long-term effort to implement and strengthen the impact of the Open Access policies of the European Commission, building on the achievements of the OpenAIRE projects.  OpenAIRE2020 will expand and leverage its focus from (1) the agents and resources of scholarly communication to workflows and processes, (2) from publications to data, software, and other research outputs, and the links between them, and (3) strengthen the relationship of European Open Access infrastructures with other regions of the world, in particular Latin America and the U.S. Through these efforts OpenAIRE2020 will truly support and accelerate Open Science and Scholarship, of which Open Access is of fundamental importance." ;
                      foaf:logo <https://www.openaire.eu/images/site_images/OpenAIREplus_logo.png> ;
                      doap:maintainer people:ChristophLange ;
                      ns4:endDate "\"2018-06-30+12:00\"^^xsd:date" ;
                      ns4:startDate "\"2015-01-01+12:00\"^^xsd:date" ;
                      eis:hookline " manage and monitor the outcomes of European funded research." ;
                      eis:status "Ongoing" ;
                      site:content """OpenAIRE2020 represents a pivotal phase in the long-term effort to implement and strengthen the impact of the Open Access policies of the European Commission, building on the achievements of the OpenAIRE projects.  OpenAIRE2020 will expand and leverage its focus from (1) the agents and resources of scholarly communication to workflows and processes, (2) from publications to data, software, and other research outputs, and the links between them, and (3) strengthen the relationship of European Open Access infrastructures with other regions of the world, in particular Latin America and the U.S. Through these efforts OpenAIRE2020 will truly support and accelerate Open Science and Scholarship, of which Open Access is of fundamental importance.

OpenAIRE2020 continues and extends OpenAIRE’s scholarly communication infrastructure to manage and monitor the outcomes of European funded research. It combines its substantial networking capacities and technical capabilities to deliver a robust infrastructure offering support for the Open Access policies in Horizon 2020, via a range of pan-European outreach activities and a suite of services for key stakeholders. It provides researcher support and services for the Open Data Pilot and investigates its legal ramifications. The project offers to national funders the ability to implement OpenAIRE services to monitor research output, whilst new impact measures for research are investigated. OpenAIRE2020 engages with innovative publishing and data initiatives via studies and pilots. By liaising with global infrastructures, it ensures international interoperability of repositories and their valuable Open Access contents.

To ensure sustainability and long-term health for the overall OpenAIRE infrastructure, the proposed OpenAIRE2020 project will establish itself as a legal entity, which will manage the production-level responsibilities securing 24/7 reliability and continuity to all relevant user groups, data providers and other stakeholders.

The University of Bonn contributes Linked Open Data services to the OpenAIRE infrastructure."""^^sysont:Markdown .

projects:OpenCourseWare_observatory a foaf:Project, eis:IncubatorProject ;
                                    rdfs:label "OpenCourseWare observatory" ;
                                    dcterms:abstract "OpenCourseWare observatory is a currently a survey to assess quality of Open CourseWare. A number of selected courses from different OCW systems is assessed based on predefined metrics. The objectives of this study is to determine the quality of OCW which helps to: identify renowned OCW creators and publishers, diagnose the strengths and weaknesses of particular OCW, evaluate the employed creation and curation methods as well as predict the future performance of OCW." ;
                                    doap:maintainer people:ChristophLange .

projects:RDFSlice site:content """RDFSlicing focuses on the selection and extraction. It devises a fragment of SPARQL dubbed SliceSPARQL, which enables the selection of well-defined slices of datasets fulfilling typical information needs. SliceSPARQL supports graph patterns for which each connected subgraph pattern involves a maximum of one variable or IRI in its join conditions. This restriction guarantees the efficient processing of the query against a sequential dataset dump stream. As a result dataset slices can be generated an order of magnitude faster than by using the conventional approach of loading the whole dataset into a triple store and retrieving the slice by executing the query against the triple store's SPARQL endpoint.
"""^^sysont:Markdown .

projects:REX site:content """Despite the significant growth of the Linked Open Data CLoud over the last years, only a small fraction of the information on the Web is represented as Linked Data. This lack of coverage is partly due to the paradigms followed so far to extract Linked Data. While converting structured data to RDF is well supported, most approaches to extract RDF from semi-structured data rely on extraction methods based on manual templates. Moreover, existing wrapper induction approaches for RDF extraction do not ensure the consistency of the knowledge they extract due to the lack on expressive schemas on the Linked Open Data Cloud. Consequently, the extraction of consistent RDF data from Web sources remains an unsolved problem. The **Web RDF Extraction Framework**, **REX**, addresses this problem by learning XPath wrappers from unlabelled Web pages using knowledge from the Linked Open Data Cloud. In contrast to existing approaches to RDF extraction using XPath wrappers, REX ensures that the new knowledge it extracts is logically consistent with the knowledge already available in the input knowledge base.

Evaluation resources can be found here: <a href=\"https://docs.google.com/spreadsheet/ccc?key=0AjkLD3pa7T5XdHhrMDlNUTFxUkpPM0ZiaFFmVHZjYmc&usp=sharing\"> Google Spreadsheet for Evaluation </a>."""^^sysont:Markdown .

projects:ReDDObservatory site:content """# Background
It is widely accepted that there is a large disparity between the availability of treatment options and the prevalence of diseases in the world, thus placing individuals in danger. This disparity is partially caused by the restricted access to information that would allow health- care and research policy makers to formulate more appropriate measures to mitigate this disparity. Specifically, this shortage of information is caused by the difficulty in reliably obtaining and integrating data regarding the disease burden for a given nation and the respective research investments.

In response to these challenges, the Linked Data paradigm provides a simple mechanism for publishing and interlinking structured information on the Web. In conjunction with the ever increasing data on diseases and healthcare research available as Linked Data, an opportunity is created to reduce this information gap that would allow for better policy in response to these disparities.

We present the ReDD-Observatory, an approach for evaluating the *Re*search-*D*isease *D*isparity based on the interlinking and integrating of various biomedical data sources.

# Methodology
The figure below provides a birds eye-view of the methodology involved in the ReDD-Observatory.

<img width=\"100%\" src=\"http://redd.eis.iai.uni-bonn.de/images/overview.png\" />

We first identified relevant datasets to be included that provided relevant information to evaluate the disparity. We not only consider the datasets already present as RDF but also those that are present in unstructured formats. These datasets are:

  1. [LinkedCT](http://linkedct.org) - the RDF representation of [ClinicalTrials.gov](http://clinicaltrials.gov/), which is the database of all clinical trials around the world.
  2. [Bio2RDF's PubMed](http://pubmed.bio2rdf.org/sparql) - the RDF representation of [PubMed](http://www.ncbi.nlm.nih.gov/pubmed/), which is a service of the US National Library of Medicine that includes bibliographic information and abstracts of over 19 million publications from MEDLINE and other life science journals.
  3. WHO's [Global Health Observatory](http://apps.who.int/ghodata/) (GHO), which contains statistical information regarding the mortality and burden of disease classified according to the death and DALY (disability-adjusted life year) estimates grouped by countries and regions.
However, since GHO is not available as Linked Data, as the next step we devised a method for representing unstructured data as RDF. We devised a plug-in in [OntoWiki](http://eis.iai.uni-bonn.de/Projects/OntoWiki) to represent statistical data from GHO as RDF. We used the Data Cube Vocabulary for this conversion. More information is present [here](http://eis.iai.uni-bonn.de/Projects/Stats2RDF). In order to ensure the completeness, conciseness and consistency for the selected datasets our next step is to assess the data quality of the datasets. The next challenging step is to interlink the datasets for a number of concepts such as (a) countries, (b) diseases and (c) publications. The assessment of the disparity is then performed with a number of parametrized SPARQL queries. We evaluate the results wrt. information quality and interlinking precision. As a consequence, we are, for the first time, able to provide reliable indicators for the extent of the research-disease disparity around the world in an semi- automated fashion, thus enabling healthcare professionals and policy makers to make more informed decisions.

# Further Information
  * [ReDD Observatory](http://redd.eis.iai.uni-bonn.de/) - a user interface, which allows users to visualize the disparity for particular diseases and regions as well as drill-down to the underlying data such as trials and publications.
  * [SPARQL Endpoint](http://db0.eis.iai.uni-bonn.de:8895/sparql) - query the integrated datasets.
  * [Sample SPARQL queries](http://redd.eis.iai.uni-bonn.de/queries/)
  * [Interlinks between the three core datasets](http://redd.eis.iai.uni-bonn.de/interlinks/)
  * [paper](http://svn.eis.iai.uni-bonn.de/papers/2011/WWW_ReDD/public.pdf Accepted paper) at the [WI-2011](http://liris.cnrs.fr/~wi-iat11/WI_2011/)
  * [Poster presented at the ESWC 2011 Summer School](http://summerschool.eswc2011.org/sites/default/files/ReDD_Poster_ESWC2011.pdf)
  * [Presentation given at the WI-IAT 2011 conference held in Lyon](http://www.slideshare.net/amrapalijz/reddobservatory)
"""^^sysont:Markdown .

projects:SAIM site:content """Articles
==================
- [ISWC 2011 Ontology Matching Workshop Paper about RAVEN](http://jens-lehmann.org/files/2011/raven.pdf \"ISWC 2011 Ontology Matching Workshop Paper about RAVEN\")
- [ESWC 2012 Paper on EAGLE](http://www.springerlink.com/content/nwr4w44078602350/?MUD=MP \"ESWC 2012 Paper on EAGLE\")

User Interface
==================
A pre-alpha version of the SAIM user interface is available [here](http://139.18.2.136:8080/SAIM \"here\"). SAIM is localized (the screenshot shows it in a german browser) with english and german localization existing. If you want to provide an additional language just let us know and we can provide you with a resource file template.

[Veri Links](http://wiki.eis.iai.uni-bonn.de/Projects/VeriLinks?v=aat \"Veri Links\") (Game Based Link Verification)
==================
As a module of SAIM, we developed an interlinking game with a prupose (GWAP). By verifying links, you earn points, which you can use in the main game to defend against invadors (and save world - as usual). If you disagree with many other users, then you can also get penalties. In the admin console, arbitrary linksets can be uploaded. Depending on the data, facts about resources are displayed in lists or on a map.
Try it: [http://verilinks.eis.iai.uni-bonn.de](http://verilinks.eis.iai.uni-bonn.de \"http://verilinks.eis.iai.uni-bonn.de\")

Developing SAIM using Eclipse
==================
1. Make sure you have Java 6, Maven 2 and Eclipse (preferably JEE) installed.
2. Install the [Subclipse plugin](http://subclipse.tigris.org/ \"Subclipse plugin\") for Subversion support.
3. Install the [Eclipse m2e Maven plugin](http://m2eclipse.sonatype.org/sites/m2e \"Eclipse m2e Maven plugin\") for Maven support and [m2e extras](http://m2eclipse.sonatype.org/sites/m2e-extras \"m2e extras\") \"Maven SCM handler for Subclipse\".
4. \"File >> New >> Other...\" >> \"Checkout Maven Projects from SCM\"
5. Set SCM URL type to \"svn\" and enter [https://saim.svn.sourceforge.net/svnroot/saim/trunk](https://saim.svn.sourceforge.net/svnroot/saim/trunk  \"https://saim.svn.sourceforge.net/svnroot/saim/trunk \") as URL
6. Choose \"Finish\"
"""^^sysont:Markdown .

projects:SCMS site:content """
* Partners: Punk.Netservices GmbH (A), OpenLink Software Ltd. (UK), Netresearch GmbH & Co. KG (D), Digital Trowel Inc. (IL)
* Duration: 2010–2012
* Funding Programme: Eurostars
"""^^sysont:Markdown .

projects:SINA a foaf:Project, eis:IncubatorProject ;
              rdfs:label "SINA" ;
              foaf:homepage "http://sina.aksw.org/" ;
              dcterms:abstract "The Web of Data contains a wealth of knowledge belonging to a large number of domains. Retrieving data from such precious interlinked knowledge bases is an issue. By taking the structure of data into account, it is expected that upcoming generation of search engines is approaching to question answering systems, which directly answer user questions. But developing a question answering over these interlinked data sources is still challenging because of two inherent characteristics: First, different datasets employ heterogeneous schemas and each one may only contain a part of the answer for a certain question. Second, constructing a federated formal query across different datasets requires exploiting links between these datasets on both the schema and instance levels. In this respect, several challenges such as resource disambiguation, vocabulary mismatch, inference, link traversal are raised. In this dissertation, we address these challenges in order to build a question answering system for Linked Data. We present our question answering system Sina, which transforms user-supplied queries (i.e. either natural language queries or keyword queries) into conjunctive SPARQL queries over a set of interlinked data sources. Sina encounters the following challenges: - Query segmentation - Query disambiguation - Query reformulation - Formal query construction - Data fusion on Linked Data - Query cleaning" ;
              foaf:logo <http://sina.aksw.org/resources/images/logo_SINA.png> ;
              ns4:startDate "2010" ;
              site:content """The Web of Data contains a wealth of knowledge belonging to a large number of domains. Retrieving data from such precious interlinked knowledge bases is an issue. By taking the structure of data into account, it is expected that upcoming generation of search engines is approaching to question answering systems, which directly answer user questions. But developing a question answering over these interlinked data sources is still challenging because of two inherent characteristics: First, different datasets employ heterogeneous schemas and each one may only contain a part of the answer for a certain question. Second, constructing a federated formal query across different datasets requires exploiting links between these datasets on both the schema and instance levels. In this respect, several challenges such as resource disambiguation, vocabulary mismatch, inference, link traversal are raised. In this dissertation, we address these challenges in order to build a question answering system for Linked Data. We present our question answering system Sina, which transforms user-supplied queries (i.e. either natural language queries or keyword queries) into conjunctive SPARQL queries over a set of interlinked data sources. Sina encounters the following challenges:
- Query segmentation
- Query disambiguation
- Query reformulation
- Formal query construction
- Data fusion on Linked Data
- Query cleaning"""^^sysont:Markdown .

projects:SPARQL2NL site:content """Survey (not active anymore): [http://blog.eis.iai.uni-bonn.de/2012/sparql2nl-survey/](http://blog.eis.iai.uni-bonn.de/2012/sparql2nl-survey/)

Survey Winners (those who agreed that we can publish their names): Ben Companjen, Thimo Thoeye, Luke Opperman, Jeffrey Putnam, Tobbe Sjogren, Ghalem Ouadjed

[AutoSPARQL TBSL Demo User Interface (using SPARQL2NL)](http://autosparql-tbsl.dl-learner.org)

**Involved CITEC members:**

[Dr. Christina Unger](http://www.sc.cit-ec.uni-bielefeld.de/people/cunger)"""^^sysont:Markdown .

projects:SPARQR site:content """We provide a public web demo. It has limited resources.
If you are using it extensively just download the release and let it run locally. Thanks.

Web service: http://sparqr.dl-learner.org/interface/rest
The README is below.
"""^^sysont:Markdown .

projects:Scoreboard dcterms:abstract """Evidence-based policy is policy informed by rigorously established objective evidence.
An important aspect of evidence-based policy is the use of scientifically rigorous studies to identify programs and practices capable of improving policy relevant outcomes.
Statistics represent a crucial means to determine whether progress is made towards policy targets.
In May 2010, the European Commission adopted the Digital Agenda for Europe (DAE), a strategy to take advantage of the potential offered by the rapid progress of digital technologies.
The DAE is part of the overall Europe2020 strategy for smart, sustainable and inclusive growth.
In order to chart the progress of both the announced policy actions and the key performance targets a scoreboard is published, thus allowing the monitoring and benchmarking of the main developments of information society in European countries. """ ;
                    site:content """The Digital Agenda contains commitments to undertake 101 specific policy actions (78 actions to be taken by the Commission, including 31 legal proposals, and 23 actions proposed to the Member States) intended to stimulate a virtuous circle of investment in and usage of digital technologies.
It identifies 13 key performance targets to show whether Europe is making progress in this area.
In order to chart the progress of both the announced policy actions and the key performance targets, the DAE calls for the publication of an annual scoreboard, supported by a large set of statistical indicators allowing  monitoring and benchmarking of the main developments of information society in European countries. As an outcome, the visualization tool of the Digital Agenda Scoreboard (DAS) was published in June 2011.
This application was developed for interested citizens and professionals (e.g. journalists) providing them with the possibility to browse statistical data with suitable visualization and interaction features.
In addition to these human-readable access methods, machine-readable access facilitating re-usage and interlinkability of the underlying data in a dereferencable way is provided by means of RDF and Linked Open Data."""^^sysont:Markdown .

projects:SemAnn dcterms:abstract "SemAnn is an open source web-based semantic annotation tool for PDF files with a special focus on academic publications. SemAnn allows users to collaboratively annotate text, thus making knowledge contained in those PDF files accessible as RDF graphs for further querying. The tool can be used with arbitrary ontologies as annotation vocabularies. The user can enter annotations of various levels of expressivity  – from simple typed annotations (e.g. annotations typed as [DBpedia](http://dbpedia.org) resources or ontology classes) to describing relationships between annotations themselves (e.g. describing the citation context of an annotation). Structural context of annotations is made available for querying by the tool’s capability of tracking the hierarchy of annotations. This enables reasoners to answer questions such as “find papers where the problem statement of the paper addresses dynamic programming languages.”. It is hence capable of viewing annotations in the context of scientific discourse like the motivation, problem statement, etc (but not limited to it). With its recommendations of similar papers, SemAnn provides an immediate benefit in return for making the effort of annotation. The justification of recommendations includes information about matches by structural context. [Code is available on Github](http://github.com/AKSW/semann)."^^sysont:Markdown .

<http://eis.iai.uni-bonn.de/Projects/SemAnn/1> a foaf:Project, eis:OpenSourceProject ;
                                               rdfs:label "SemAnn" ;
                                               foaf:homepage "http://github.com/AKSW/semann" ;
                                               dcterms:abstract """SemAnn allows you to semantically annotate (using RDF triples) text in
PDFs. These annotations are then used for recommending similar PDF
documents that the reader might find relevant.""" ;
                                               doap:maintainer people:ChristophLange ;
                                               eis:hookline "Web-based semantic annotation tool for PDF documents" ;
                                               eis:status "Ongoing" ;
                                               site:content """SemAnn is an open source web-based
semantic annotation tool for PDF files with a special focus on academic
publications. SemAnn allows users to collaboratively annotate text, thus
making knowledge contained in those PDF files accessible as RDF graphs
for further querying. The tool can be used with arbitrary ontologies as
annotation vocabularies. The user can enter annotations of various
levels of expressivity  – from simple typed annotations (e.g.
annotations typed as [DBpedia](http://dbpedia.org) resources or ontology
classes) to describing relationships between annotations themselves
(e.g. describing the citation context of an annotation). Structural
context of annotations is made available for querying by the tool’s
capability of tracking the hierarchy of annotations. This enables
reasoners to answer questions such as “find papers where the problem
statement of the paper addresses dynamic programming languages.”. It is
hence capable of viewing annotations in the context of scientific
discourse like the motivation, problem statement, etc (but not limited
to it). With its recommendations of similar papers, SemAnn provides an
immediate beneﬁt in return for making the effort of annotation. The
justification of recommendations includes information about matches by
structural context. [Code is available on
Github](http://github.com/AKSW/semann)."""^^sysont:Markdown .

projects:SlideWiki a foaf:Project, eis:FundedProject ;
                   rdfs:label "SlideWiki" ;
                   ov:screenshot <http://lh3.ggpht.com/-1eEGAM8mIG4/TrUtrFohoMI/AAAAAAAABB0/Ta2QC-rsyMs/s800/slidewiki-view.png>, <http://lh4.ggpht.com/-_ucInHOV87c/TrUtqpcwi7I/AAAAAAAABBs/p3bmvtSrHJ0/s800/slidewiki-home.png>, <http://lh6.ggpht.com/-WDej-O6jTZE/TrUtq0wZe2I/AAAAAAAABBw/DrmfWiZgKnY/s800/slidewiki-edit.png>, <http://lh6.ggpht.com/-gtrafeiSUNo/TrUtqrBO2UI/AAAAAAAABBo/FyLTviThwCQ/s800/slidewiki-search.png> ;
                   foaf:homepage "http://slidewiki.org" ;
                   dcterms:abstract "SlideWiki is a collaboration platform which enables communities to build, share and play online presentations. In addition to importing PowerPoint presentations, it supports authoring of interactive online slides using HTML and LateX. Slides and their containers (called Deck), are versioned thereby enabling change tracking. Users can create their own themes on top of existing themes or re-use other's themes." ;
                   foaf:logo <http://slidewiki.org/static/img/slidewiki_logo.png> ;
                   doap:maintainer people:SoerenAuer ;
                   eis:hookline "helps communities to create great presentations collaboratively" ;
                   eis:publicationTag "slidewiki" ;
                   eis:promoted "\"true\"^^xsd:boolean" ;
                   eis:status "Ongoing" ;
                   site:content """SlideWiki aims to exploit the wisdom, creativity and productivity of the crowd for the creation of qualitative, rich, engaging educational content. With SlideWiki users can create and collaborate on slides, diagrams, assessments and arrange this content in richly-structured course presentations.

SlideWiki empowers communities of educators to author, share and re-use sophisticated educational content in a truly collaborative way. Existing presentations can be imported and transformed into interactive courses using HTML and LaTeX. All content in SlideWiki is versioned thereby allowing users to revise, adapt and re-mix all content. Self-test questions can be attached to each individual slide and are aggregated on the presentation level into comprehensive self-assessment tests. Users can create their own presentation themes. Slidewiki supports the semi-automatic translation of courses in more than 50 languages.

With SlideWiki we aim to make educational content dramatically more accessible, interactive, engaging and qualitative. More information about SlideWiki can be found in the [documentation](http://slidewiki.org/documentation \"documentation\").
"""^^sysont:Markdown .

projects:SoftWiki site:content """* Duration: 2006–2009
* Funding Programme: [research initiative “Software Engineering 2006”](http://www.softwarefoerderung.de/), German Ministry of Education and Research (BMBF)
"""^^sysont:Markdown .

projects:SparqlAnalytics site:content """Live Query Usage Stats
======================

Although the goal of this project is more amibitious than \"just\" providing a live chart of SPARQL endpoint activity, this is still a pretty neat \"by-product\", which we intend to develop further.

"""^^sysont:Markdown .

projects:Sparqlify dcterms:abstract """Sparqlify is a SPARQL-SQL rewriter that enables one to define RDF views on relational databases and query them with SPARQL. It is currently in alpha state and powers the Linked-Data Interface of the LinkedGeoData Server – i.e. it provides access to billions of virtual triples from the OpenStreetMap database.
""" ;
                   site:content """# Key Features

* A novel syntax for view definitions inspired by SQL's CREATE VIEW statement. We believe this to lower the learning curve for defining RDB-RDF mappings.
* A query is rewritten into a single SQL statement, giving all control over query planning to the underlying database system.
* Support of geo-spatial functions: In general, Sparqlify supports mapping custom SPARQL functions to relational ones. Some mappings for PostGIS are already provided (e.g. intersection with polygons).

# Limitations

Please be aware that Sparqlify is currently in alpha state and the following limitations hold:

* For the moment, only the PostgreSQL database system is supported.
* Only a subset of SPARQL 1.0 + Sub-Queries is supported: For instance, the implementation of aggregate functions including COUNT is still pending.
* Support for Sparql 1.1 property paths is very unlikely in the near future."""^^sysont:Markdown .

projects:USPatents site:content """About the dataset
==================

- Namespace: [http://us.patents.eis.iai.uni-bonn.de/](http://us.patents.eis.iai.uni-bonn.de/ \"http://us.patents.eis.iai.uni-bonn.de/\")
- SPARQL endpoint: [http://patents.eis.iai.uni-bonn.de/patents/sparql](http://patents.eis.iai.uni-bonn.de/patents/sparql \"http://patents.eis.iai.uni-bonn.de/patents/sparql\")
- GRAPH: [http://aksw.patents.org](http://aksw.patents.org \"http://aksw.patents.org\")
- Version date and number: June, 2013 and 1.1
- Total no. of triples:
- Licensing: [cc-by](http://opendefinition.org/licenses/cc-by/ \"cc-by\")
- VoID file: [http://amrapali.eis.iai.uni-bonn.de/patentsvoid.ttl](http://amrapali.eis.iai.uni-bonn.de/patentsvoid.ttl \"http://amrapali.eis.iai.uni-bonn.de/patentsvoid.ttl\")
- DataHub entry: [http://datahub.io/en/dataset/uspto-patent-data](http://datahub.io/en/dataset/uspto-patent-data \"http://datahub.io/en/dataset/uspto-patent-data\")
- RDF dump:
- RDF/XML example:
- Publication: (under review)

Note
==================
Please note that this is work in progress. If you are interested, please write an email to zaveri@informatik.uni-leipzig.de.
"""^^sysont:Markdown .

projects:VeriLinks site:content """Experiment 2012: Can we create better links by playing games?
==================================================================
In 2012, we officially released Veri Links and started a survey, which we distributed on Linked Data and Semantic Web mailing lists. We recorded in-game statistics and survey answers to obtain a clearer picture on the usefulness of games, in particular VeriLinks, for interlinking. The results and accompanying material for the experiments are available here:

 - [Experiment Report](http://svn.eis.iai.uni-bonn.de/papers/2013/ESWC_VeriLinks/public.pdf \"Experiment Report\")
 - Survey:
- [announcement blog post](http://blog.eis.iai.uni-bonn.de/2012/verilinks/ \"\")
- [survey on VeriLinks](http://surveys.eis.iai.uni-bonn.de/survey/verilinks \"\") [can still be used for feedback, but will be offline eventually]
- [all questions and results as PDF](http://eis.iai.uni-bonn.de/files/verilinks/Survey_VeriLinks_Results.pdf \"\")
- [raw survey results as CSV](http://eis.iai.uni-bonn.de/files/verilinks/Survey_VeriLinks_Raw_Results.csv \"\") (with questions)
 - Data:
- [used link specifications](http://eis.iai.uni-bonn.de/files/verilinks/specs/ \"\")
- [generated links](http://eis.iai.uni-bonn.de/files/verilinks/links/ \"\")
- [manually created GOLD standard](http://eis.iai.uni-bonn.de/files/verilinks/gold_standard.csv \"\")
- [templates used for displaying questions for the above link tasks](http://eis.iai.uni-bonn.de/files/verilinks/Templates.xml \"\")
 - In-Game Statistics (see report for explanations):
- [raw link validation statistics in CSV format](http://eis.iai.uni-bonn.de/files/verilinks/stats/link_validation_raw_data%20.csv \"\"), columns: ID, subject, predicate, object, link task, link specification confidence value (as computed by the above link specifications), game confidence value (explained in the report), GOLD standard (1=correct,0=incorrect), number of times the link has been played, number of times the link has been judged as correct in the game, number of times the link has been judged as incorrect in the game
- [Weka machine learning toolkit training data file](http://eis.iai.uni-bonn.de/files/verilinks/stats/weka_features.arff \"\")

Remark: Since people participated in the survey and played the game outside of the 3-day experiment phase, the raw data above are updated versions of those in the report.

Survey Winners (those who agreed that we can publish their names): Gianluca Demartini, Kingsley Idehen, Joe Montibello, Michael Röder, Jakub Kotowski, Thomas Efer, Virginia Knight, Ruby, Florent Jochaud"""^^sysont:Markdown .

projects:VoCol a foaf:Project, eis:OpenSourceProject ;
               rdfs:label "VoCol" ;
               foaf:homepage "https://github.com/mobivoc/vocol" ;
               dcterms:abstract """Vocabularies typically reflect a consensus among experts in a
certain application domain. They are thus implemented in collaboration
of domain experts and knowledge engineers. Particularly the presence of
domain experts with little technical background requires a low-threshold
vocabulary engineering methodology. This methodology should be im-
plementable without dependencies on complex software components, it
should provide collaborators with comprehensible feedback on syntax
and semantics errors in a tight loop, and it should give access to a human-
readable presentation of the vocabulary. Inspired by agile software and
content development methodologies, we define the VoCol methodology
to address these requirements. We implemented a prototype based on a
loose coupling of validation and documentation generation components
on top of a standard Git repository. All of these components, even the
repository engine, can be exchanged with little effort. By evaluating the
usefulness of error feedback of different tools in the realistic setting of an
emerging mobility vocabulary we prove, however, that our choice of the
crucial validation component is workable.""" ;
               doap:maintainer people:NiklasPetersen ;
               ns4:startDate "\"2014-08-01+02:00\"^^xsd:date" ;
               eis:hookline "A low-threshold agile methodology for collaborative vocabulary development" ;
               eis:partner ns16:brox ;
               eis:status "Ongoing" ;
               site:content """ In order to address the lack of vocabulary development support, we designed
VoCol, a low-threshold agile methodology for collaborative vocabulary devel-
opment. Inspired by agile software and content development methodologies, we
define the VoCol methodology to address these requirements. We implemented
a prototype based on a loose coupling of collaboration, authoring, project man-
agement, validation, documentation and visualization generation components
on top of a standard Git repository. All of these components, even the repos-
itory engine, can be exchanged with little effort to cater for specific use cases.
Through its continuous vocabulary component integration and verification func-
tions, VoCol can be seen as an analogon to continuous integration in software
engineering. You can find more on our [technical report.](http://zenodo.org/record/15023?ln=en#.VPlt6s1GjUY \"VoVol Technical Report\")"""^^sysont:Markdown ;
               doap:Technical_Report "http://zenodo.org/record/15023?ln=en#.VPlt6s1GjUY" .

projects:WDAqua_ITN a foaf:Project, eis:FundedProject ;
                    rdfs:label "WDAqua ITN" ;
                    foaf:homepage "http://wdaqua.informatik.uni-bonn.de/?page_id=34" ;
                    dcterms:abstract "Smart infrastructures and citizens’ participation in the digital society are increasingly data-driven. Sharing, connecting, managing, analysing and understanding data on the Web will enable better services for citizens, communities and industry. However, turning web data into successful services for the public and private sector requires skilled web and data scientists, and it still requires further research. WDAqua aims at advancing the state of the art by intertwining training, research and innovation efforts, centred around data-driven question answering. Question answering is immediately useful to a wide audience of end users, and we will demonstrate this in settings including e-commerce, public sector information, publishing and smart cities. Steps to answering a question are (1) understanding a spoken question, (2) analysing the question’s text, (3) finding data to answer the question, and (4) presenting the answer(s). Every individual research project in WDAqua connects at least two of these steps." ;
                    doap:maintainer people:SoerenAuer ;
                    ns4:endDate "june 2018" ;
                    eis:hookline "Answering Questions using Web Data" ;
                    eis:partner ns23:id, ns16:Open_Data_Institute, ns16:University_of_Southampton ;
                    eis:promoted "\"true\"^^xsd:boolean"@en ;
                    eis:status "ongoing" .

projects:Xturtle site:content """# Installation
Starting from an existing eclipse installation, you can install Xturtle by using the updatesite

`http://xturtle.eis.iai.uni-bonn.de/`

During the installation, you have to trust a certificate named `cn=Sebastian Tramp` with the Thumbprint `D4 30 D2 EF 31 78 40 DF F8 DA 6A F7 F7 EC 89 BB CF 92 44 82`. This may change in the future.

Since Xtext is a dependency of the Xturtle editor, you need to install it as well. For those not having an eclipse, the easiest option is to use the latest [itemis distro](http://xtext.itemis.com/xtext/language=en/36553/downloads) where Xtext is already installed. If you have an eclipse installation, you can use the composite Xtext update site

`http://download.eclipse.org/modeling/tmf/xtext/updates/composite/releases/`

for installing the necessary Xtext components.

You'll know that the editor is working, if you open a .ttl file and you are asked if you want to add the Xtext-Nature to the project. Further, on invoking code completion (ctrl-space) in the first line, something should happen...

For more information on features, usage notes and technical background, have a look at the [wiki](https://github.com/AKSW/Xturtle/wiki)."""^^sysont:Markdown .

projects:xOperator site:content """Introduction
============


Instant Messaging is in addition to Web and Email the most popular service on the Internet. With xOperator we present a strategy and implementation which deeply integrates Instant Messaging networks with the Semantic Web. The xOperator concept is based on the idea of creating an overlay network of collaborative information agents on top of social IM networks. It can be queried using a controlled and easily extensible language based on AIML templates. Such a deep integration of semantic technologies and Instant Messaging bears a number of advantages and benefits for users when compared to the separated use of Semantic Web technologies and IM, the most important ones being context awareness as well as provenance and trust.

Idea
====


Inspired by Tim Berners-Lee's Semantic Agent the xOperator lifts personal knowledge exchange to a new level. Imagine sharing exactly the information you want with the people you trust. Need a phone number? Want to know the birthday of your best friends girlfriend (and in a second step where to buy her a present in a store near you)? Do you get tired to tell everybody that you have a new cellphone number? xOperator enables users to share all that knowledge in a trusted network. Built upon the already existing jabber network (secure connections, widely available) an agent running on your pc allows other users to query your RDF-database returning the favor to you.

Millions of people already share their information on Social Network Sites, only for designated friends to see of course. The great drawback is though that actually, they are helping to maintain a great database for the companies offering these services. Once the Semantic Web will be fully implemented it might also enable the possibility to unify personal information about an individual from different sources. xOperator keeps all data on your computer, giving you the choice what to share with whom and best of all it can't take away that choice by changing the terms and conditions.

Despite all this ideology, xOperator will be, surely, once it exists, a very cool thing to use, which is to say, we are very exited ourselves, what uses it can be put to.

Vision
======

xOperator tries to create a decentralized network of trust. Information is shared in the form of resources, which can be anything (even the information that you are selling your old washing machine). In a later stage it enables you to find friends of friends like centralized services, can already. At the end of the road, xOperator might even be able to find the best product for you without the normally necessary tedious internet research. Companies will be able to offer semantic annotated information about their products, giving the customer a new way of yet unknown price transparency."""^^sysont:Markdown .

people:Publications a foaf:Document ;
                    rdfs:label "Publications" ;
                    site:templateOption "extended", "noheading" ;
                    lod2:exhibitData <http://eis.iai.uni-bonn.de/eis.bib.json?callback=cb> ;
                    site:content """<nav class=\"nav-sidelinks\">
<ul>
<li><strong class=\"headline\">current funded projects</strong>
{{query where=\"?resourceUri a eis:FundedProject. OPTIONAL { ?resourceUri eis:status ?status }  FILTER (?status != 'finished')\" template=\"liplain\"}}
</li>
</nav>


"""^^sysont:Markdown .

people:SaeedehShekarpour a foaf:Person ;
                         rdfs:label "Dr. Saeedeh Shekarpour" ;
                         rdfs:seeAlso <https://www.linkedin.com/nhome/> ;
                         skos:prefLabel "Dr. Saeedeh Shekarpour" ;
                         foaf:name "Saeedeh Shekarpour" ;
                         skos:hiddenLabel "SaeedehShekarpour" ;
                         foaf:currentProject projects:SINA, projects:WDAqua_ITN ;
                         foaf:depiction <https://dl.dropboxusercontent.com/u/28799199/meriva.jpg> ;
                         foaf:mbox <mailto:shekarpourATuni-bonn.de> ;
                         foaf:familyName "Shekarpour" ;
                         eis:publicationTag "shekarpour" ;
                         eis:room "A110a" .

people:SaharVahdati a foaf:Person ;
                    rdfs:label "M.Sc" ;
                    rdfs:seeAlso <http://www.idb.uni-bonn.de/team/sahar-vahdati> ;
                    skos:prefLabel "Sahar Vahdati" ;
                    foaf:name "Sahar Vahdati" ;
                    site:templateOption "extended" ;
                    foaf:currentProject projects:OpenAIRE2020, projects:OpenCourseWare_observatory ;
                    foaf:depiction <https://lh6.googleusercontent.com/-1aYLlJkN9Gk/AAAAAAAAAAI/AAAAAAAAAB4/TpwtSZMguBk/photo.jpg> ;
                    foaf:mbox <mailto:s6savahd@gmail.com> ;
                    foaf:phone <tel:+49228734533> ;
                    foaf:familyName "Vahdati" ;
                    eis:publicationTag "svahdati" ;
                    eis:room "A210" .

people:Saleh_Alkarabubi a foaf:Person ;
                        rdfs:label "Saleh Alkarabubi" ;
                        skos:prefLabel "Saleh Alkarabubi" ;
                        foaf:name "Saleh" ;
                        foaf:depiction <https://lh6.googleusercontent.com/-GrGKEjf3oPI/VMJ9Cr31MwI/AAAAAAAAJD4/6L2_Du2HQCU/s128/saleh.jpg> ;
                        foaf:mbox <mailto:s6saalka@uni-bonn.de> ;
                        foaf:familyName "Alkarabubi" ;
                        eis:room "A110a" .

people:SarvenCapadisli a foaf:Person ;
                       rdfs:seeAlso <http://csarven.ca/cv> ;
                       owl:sameAs <http://csarven.ca/#i> ;
                       foaf:name "Sarven Capadisli" ;
                       foaf:homepage <http://csarven.ca/> ;
                       sioc:feed <http://csarven.ca/atom> ;
                       foaf:depiction <http://csarven.ca/media/images/sarven-capadisli.jpg> ;
                       foaf:mbox <mailto:info@csarven.ca> ;
                       foaf:familyName "Capadisli" .

ns5:AKSWColloquiumMon16122013AboutTheSINAQuestionAnsweringSystemasPresentedAtIBMWatson dcterms:abstract """Last week Saeedeh Shekarpour was invited to present her work at the IBM research center (Watson project, DeepQA) in New York. On Monday, December 16 at 1.30 pm in Room P-702 (Paulinum), Saeedeh Shekarpour will present SINA, a question answering system, which transforms user-supplied queries in natural language into conjunctive SPARQL queries over a set of interlinked data sources.

Furthermore, we would like to announce, that there is complimentary coffee and cake after the session. Bachelor and Master students will be able to get points for attendance.""" ;
                                                                                       site:content """Last week Saeedeh Shekarpour was invited to present her work at the IBM research center (Watson project, DeepQA) in New York. On Monday, December 16 at 1.30 pm in Room P-702 (Paulinum), Saeedeh Shekarpour will present SINA, a question answering system, which transforms user-supplied queries in natural language into conjunctive SPARQL queries over a set of interlinked data sources.

As always, Bachelor and Master students are able to get points for attendance and there is complimentary coffee and cake after the session.

For further reading, please refer to the slides and the publication [Question Answering on Interlinked Data](http://www2013.wwwconference.org/proceedings/p1145.pdf) ([BibTeX](http://dblp.uni-trier.de/rec/bibtex/conf/www/ShekarpourNA13)).

#The SINA Question Answering System

The architectural choices underlying Linked Data have led to a compendium of data sources which contain both duplicated and fragmented information on a large number of domains. One way to enable non-experts users to access this data compendium is to provide keyword search frameworks that can capitalize on the inherent characteristics of Linked Data. The contribution of this work is as follows:

1. A novel approach for determining the most suitable resources for a user-supplied query from different datasets (disambiguation). It employs a hidden Markov model, whose parameters were bootstrapped with different distribution functions.

2. A novel method for constructing a federated formal queries using the disambiguated resources and leveraging the linking structure of the underlying datasets. This approach essentially relies on a combination of domain and range inference as well as a link traversal method for constructing a connected graph which ultimately renders a corresponding SPARQL query.
"""^^sysont:Markdown .

ns5:AKSWColloquiumOnMondayNovember4 dcterms:abstract """In our weekly AKSW Colloquium, we present research, technologies and tools of the Semantic Web. The colloquium is open to the public and we welcome interested students, colleagues and industry partners to experience bleeding edge work-in-progress presentations and discussion rounds as well as talks by invited experts of our AKSW lecture series.

On Monday, November 4 at 1.30 – 2.30 pm in Room P-702 (Paulinum), we will have an introduction of our new PhD intern, Farshad Badie who will talk about Fuzzy OWL Class Expressions.

Furthermore, we would like to announce, that there is complimentary coffee and cake after the session. Bachelor and Master students will be able to get points for attendance.""" ;
                                    site:content """# \"Fuzzy OWL Class Expressions\" by Farshad Badieby, PhD intern

The main approaches are Inductive Logic Programming, Fuzzy DL including Learning Axioms, Reasoning with large A-boxes in Fuzzy DL by DL Reasoners, Fuzzy KR with DL & LP fuzzy DL, Reasoning on Fuzzy UML models. The conclusions of the research will be used for constructing an efficient framework for Intelligent Learning based on the Semantic Web.

Education
---------

- Honoured MSC degree in Software IT and Computer Science (Specialization : Information Systems).
- Essential courses of MSC in Applied Mathematics.
- BSC in Applied Mathematics.
- Work Experience
- Teaching Assistant in “Mathematical Logic”, Dep of Computer Science, University of Debrecen, Hungary.
- Management of Information Systems and Decision Making, Trans Iranian Distribution Company, Iran.
- Teaching Fundamentals of Mathematics, Set Theory, Calculus, Linear Algebra, Discrete Mathematics in High Schools and Colleges, Iran.
"""^^sysont:Markdown .

ns5:AKSWColloquiumWithNIFReleasePreparationOnMondayFebruary10 dcterms:abstract """On Monday, February 10, at 1.30 pm in room P702 (Paulinum of the University of Leipzig main building at the Augustusplatz), Sebastian Hellmann will present the Natural Language Processing (NLP) Interchange Format (NIF) which is based on a Linked Data enabled URI scheme for identifying elements in (hyper-)texts and an ontology for describing common NLP terms and concepts. During the meeting we will jointly look at the existing tools and infrastructure, collect issues and discuss potential fixes. Bringing a laptop is recommended.

As always, Bachelor and Master students are able to get points for attendance and there is complimentary coffee and cake after the session.""" ;
                                                              site:content """On Monday, February 10, at 1.30 pm in room P702 (Paulinum of the University of Leipzig main building at the Augustusplatz), [Sebastian Hellmann](http://eis.iai.uni-bonn.de/SebastianHellmann \"Sebastian Hellmann\") will present the Natural Language Processing (NLP) Interchange Format (NIF) which is based on a Linked Data enabled URI scheme for identifying elements in (hyper-)texts and an ontology for describing common NLP terms and concepts. During the meeting we will jointly look at the existing tools and infrastructure, collect issues and discuss potential fixes. Bringing a laptop is recommended.

As always, Bachelor and Master students are able to get points for attendance and there is complimentary coffee and cake after the session.

Abstract
------------------
We are currently observing a plethora of Natural Language Processing tools and services being made available. Each of the tools and services has its particular strengths and weaknesses, but exploiting the strengths and synergistically combining different tools is currently an extremely cumbersome and time consuming task. Also, once a particular set of tools is integrated, this integration is not reusable by others. We argue that simplifying the interoperability of different NLP tools performing similar but also complementary tasks will facilitate the comparability of results and the creation of sophisticated NLP applications. In this session, we present the NLP Interchange Format (NIF). NIF is based on a Linked Data enabled URI scheme for identifying elements in (hyper-)texts and an ontology for describing common NLP terms and concepts. In contrast to more centralized solutions such as UIMA and GATE, NIF enables the creation of heterogeneous, distributed and loosely coupled NLP applications, which use the Web as an integration platform. We present several use cases of the second version of the NIF specification (NIF 2.0) and the result of a developer study.

References
------------------

- [Integrating NLP using Linked Data, S. Hellmann et al. ISWC 2013](http://svn.eis.iai.uni-bonn.de/papers/2013/ISWC_NIF/public.pdf \"\")
- [http://nlp2rdf.org](http://nlp2rdf.org)
- [http://persistence.uni-leipzig.org/nlp2rdf](http://persistence.uni-leipzig.org/nlp2rdf)"""^^sysont:Markdown .

<http://eis.iai.uni-bonn.de/SchemaEvent/AKSWColloquiumWithNIFReleasePreparationOnMondayFebruary10/1> dcterms:abstract """On Monday, February 10 at 1.30 – 2.30 pm in Room P-702 (Paulinum),  we will jointly look at the existing tools and infrastructure, collect issues and discuss potential fixes. Bringing a laptop is recommended.
Sebastian Hellmann will present the Natural Language Processing (NLP) Interchange Format (NIF) is based on a Linked Data enabled URI scheme for identifying elements in (hyper-)texts and an ontology for describing common NLP terms and concepts.


Furthermore, we would like to announce, that there is complimentary coffee and cake after the session. Bachelor and Master students will be able to get points for attendance.""" .

ns5:DigitaleForschungskollaboration dcterms:abstract """Der Leipziger Semantic Web Tag (LSWT) bietet seit 2009 Unternehmen und Organisationen die Möglichkeit, sich zu Themen im Bereich semantischer Technologien auszutauschen.
""" ;
                                    schema:description """Der Leipziger Semantic Web Tag (LSWT) bietet seit 2009 Unternehmen und Organisationen die Möglichkeit, sich zu Themen im Bereich semantischer Technologien auszutauschen. In diesem Jahr steht der LSWT unter dem Motto \"Von Big Data zu Smart Data\".
Um sich inhaltlich über den LSWT zu Informieren, eignet sich am Besten ein Blick auf die <a href=\"http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Einladung\">Einladung</a>.
""" ;
                                    site:content """# Übersicht / Overview

## [Einladung / Call for Contributions](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Einladung \"CfP\") **Deadline: 20.08.2013**
Bitte füllen Sie [das Formular auf dieser Seite aus](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Einladung \"Formular\") bis zum **20.08.2013** aus, wenn Sie sich aktiv am LSWT 2013 beteiligen wollen. Wir suchen noch Vortragende, Demos, Sponsoren und Tutorials sind aber auch offen für Ihre Vorschläge. Falls Sie Fragen haben oder sich lieber per Email um die Teilnahme bewerben möchten, können Sie sich auch gerne and das [Orga-Team](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Kontakt \"Orga Team\") wenden.
## [Kerntag: 23.09.](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Kerntag \"Kerntag\") anschließend Social Event
## [Tutorials: 24.09.](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Tutorien \"Tutorien\")
## [Keynote: Hans Uszkoreit - Big Data and Text Analytics](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Keynote \"Keynote\")
<table border=\"0\">
<tr><td><img width = \"80\" src = \"http://wiki.eis.iai.uni-bonn.de/files/lswt/2013/HansUszkoreit.png \" /></td><td>
Es gehört zu den Herausforderungen unserer Zeit, adäquat mit unserer Hinterlassenschaft umzugehen: der unüberschaubaren Masse an Text im World Wide Web.  Durch die Kombination von skalierbaren statistischen Modellen mit intelligenten regelbasierten Systemen eröffnet sich die vielversprechende Perspektive, einen fein-granularen, vielseitig einsetzbaren, translingualen \"Wissensgraphen\" zu produzieren, der ein weites Spektrum an Anwendungen bedient. </td></tr></table>

##[ Ort: Campus der Universität Leipzig](http://eis.iai.uni-bonn.de/Events/2013/LeipzigerSemanticWebTag/Anreise \"Anreise\")




"""^^sysont:Markdown .

people:SebastianHellmann site:content """# Homepage
Please look at my old homepage, which contains much more information:
[http://bis.informatik.uni-leipzig.de/SebastianHellmann](http://bis.informatik.uni-leipzig.de/SebastianHellmann \"http://bis.informatik.uni-leipzig.de/SebastianHellmann\")
"""^^sysont:Markdown .

people:SidraFaisal a foaf:Person ;
                   rdfs:label "Sidra Faisal" ;
                   foaf:depiction <http://www.sessionlogs.com/media/icons/defaultIcon.png> ;
                   foaf:familyName "Faisal" .

people:SimonScerri a foaf:Person ;
                   rdfs:seeAlso <https://www.linkedin.com/profile/view?id=14366104&trk=nav_responsive_tab_profile> ;
                   owl:sameAs <https://www.researchgate.net/profile/Simon_Scerri?ev=hdr_xprf> ;
                   skos:prefLabel "Dr. Simon Scerri" ;
                   foaf:name "Simon Scerri" ;
                   foaf:currentProject projects:BigDataEurope ;
                   foaf:depiction <https://dl.dropboxusercontent.com/u/53345423/profile2_small.png> ;
                   foaf:mbox <mailto:scerri@iai.uni-bonn.de> ;
                   foaf:phone <tel:+492241142058> ;
                   foaf:familyName "Scerri" ;
                   eis:room "A118" .

people:SlideWikiTips dcterms:title "SlideWiki Tips & Tricks" ;
                     site:content """Here are some tips & tricks that help you work with anything we are providing in [SlideWiki](http://slidewiki.org) – such as our [lecture notes](/Teaching.html).

## Ways to speed up read access
* Open just the deck (“folder”) you are interested in in a new tab by right-clicking the folder.
* Download a printable version via “More→Print Deck”.
* Download an offline version that's interactively browsable offline via “More→Download Deck”.

## How to ask questions about slides
* Each deck or slide has a “discussion” tab where you can ask questions.
* If you have a user account, you can follow a deck (including all of its child nodes) with the green “follow deck” button in the title box.  The instructor usually follows the whole lecture.
* Followers will be notified of changes to the deck, including discussion posts.
* Be sure to edit your user profile and preferences so that the “notification interval” is not “OFF”.
"""^^sysont:Markdown .

people:SoerenAuer a foaf:Person ;
                  skos:prefLabel "Prof. Dr. Sören Auer" ;
                  foaf:name "Sören Auer" ;
                  sioc:feed <http://enterpriseinformationsystems.wordpress.com/feed/> ;
                  site:templateOption "extended" ;
                  ov:businessCard <http://eis.iai.uni-bonn.de/vCard/Bonn> ;
                  skos:hiddenLabel "SoerenAuer" ;
                  foaf:currentProject projects:VoCol ;
                  foaf:depiction <http://bis.informatik.uni-leipzig.de/images/jpegPhoto.php?name=sn&value=auer> ;
                  foaf:mbox <mailto:auer@cs.uni-bonn.de> ;
                  foaf:phone <tel:+49-228-73-7816> ;
                  foaf:familyName "Auer" ;
                  eis:publicationTag "auer" ;
                  eis:room "A119" ;
                  <site:content> "Test" .

people:StefanLuettringhausKappel a foaf:Person ;
                                 rdfs:label "Dr. Stefan Lüttringhaus-Kappel" ;
                                 skos:prefLabel "Dr. Stefan Lüttringhaus-Kappel" ;
                                 foaf:name "Stefan Lüttringhaus-Kappel" ;
                                 foaf:depiction <http://www.sessionlogs.com/media/icons/defaultIcon.png> ;
                                 foaf:mbox <mailto:stefan@iai.uni-bonn.de> ;
                                 foaf:phone <tel:+49-(228)-73-4536> ;
                                 foaf:familyName "Lüttringhaus-Kappel" ;
                                 eis:room "A209" .

people:StudentWorker a owl:Class ;
                     rdfs:label "Student Worker" ;
                     rdfs:subClassOf foaf:Person .

<http://eis.iai.uni-bonn.de/Talk/PatchR> schema:description """Incorrect or outdated data is a common problem when working with Linked Data in real world applications. Linked Data is distributed over the web and under control of various publishers. It is difficult for data publishers to ensure the quality and timeliness of their data by theirselves, though they might receive individual complaints by data users, who identified incorrect or missing data. Indeed, we see Linked Data users equally responsible for the quality of the datasets they use.
PatchR is a vocabulary to report incorrect data and to propose changes to correct them. Based on this vocabulary a framework is suggested that allows users to efficiently report and data publishers to handle change requests for their datasets.
""" .

<http://eis.iai.uni-bonn.de/Talk/Retresco> schema:description """Roboterjournalismus kam 2012 in die Schlagzeilen. Aus zahlengestützten Reports erstellen Computerprogramme „echte“ Artikel. Forbes begann mit dieser Technologie Unternehmensberichte zu schreiben. Und die Frage kam auf, inwiefern Automatismen den Redakteur ablösen würden. Die Antwort damals: Vielleicht irgendwann, aber nur bei statistikgetriebenen Analysen und 08/15-Texten.
Technologische Verfahren werden jedoch immer besser darin, große Massen unstrukturierter Daten zu erschließen und zu verarbeiten. Neben dem Einfluss auf die Texterstellung, ein Kernelement journalistischer Arbeit, bedeutet dies die Automatisierung ganzer Redaktionsprozesse. Die Digitalisierung der Verlagsbranche findet überall statt: vor und hinter dem Artikel.
Welche Artikel dem Leser beispielsweise als Empfehlungslink auf einer Webseite angezeigt werden, berechnen semantische Analysen heute in Kombination mit Relevanzalgorithmen und Klickdaten. Ähnliche Verfahren nutzen Publisher für den Aufbau ganzer Micro-Sites. Was der Leser sieht, entscheidet, abhängig von Themenumfeld und Nutzerinteressen, eine Software.
Doch wohin führt die Entwicklung? Können semantische Verfahren eine ganze Redaktion ersetzen? Automatisierte Themenauswahl über Twitter und Facebook, Texterstellung aus nutzergeneriertem Content, Content Distribution über Algorithmen?
Alexander Siebert, Gründer und Geschäftsführer von Retresco, spricht in seinem Vortrag über den Einfluss von semantikbasierten Verfahren auf die digitale Entwicklung der Publisherbranche. Er beleuchtet den Status Quo der technologischen Möglichkeiten und zeigt, was künftig möglich sein könnte – und wo gegebenenfalls Grenzen liegen.""" .

<http://eis.iai.uni-bonn.de/Talk/SemantischeTechnologienBeiUnister> rdfs:label """Herausforderungen bei der Integration von Linked Open Data in
E-Commerce-Anwendungen""" ;
                                                                    schema:description """Linked Data ermöglicht die Integration von sehr großen
Datenmengen bzw. Wissensbasen in Geschäftsprozesse und Anwendungen.
Damit wird theoretisch eine Steigerung des verfügbaren Wissens erreicht.
In der praktischen Anwendung zeigt sich allerdings das Problem der
mangelden Datenqualität und von inkompatiblen Daten.
Ein Ausweg wäre die Evaluierung der zu integrierenden Ontologien durch
Domänen-Experten. Der Preis dafür wäre aber die Skalierbarkeit bei der
Integration von Linked Data. Der Vortrag widmet sich in der Praxis
beobachteten Problemen und präsentiert Lösungsvorschläge bzw.
Forschungsideen.""" .

<http://eis.iai.uni-bonn.de/Talk/Unister> rdfs:label """Herausforderungen bei der Integration von Linked Open Data in
E-Commerce-Anwendungen""" .

people:Teaching site:content """<nav class=\"nav-sidelinks\">
<ul>
<li><strong class=\"headline\">[General](#general)</strong></li>
<li><strong class=\"headline\">[Winter](#winter)</strong>
<ul>
<li>[Semantic Web](#winter-lecture)</li>
<li>[Seminar](#winter-seminar)</li>
<li>[Lab](#winter-lab)</li>
</ul>
<li><strong class=\"headline\">[Summer](#summer)</strong>
<ul>
<li>[Enterprise Information Systems](#summer-lecture)</li>
<li>[Seminar](#summer-seminar)</li>
<li>[Lab](#summer-lab)</li>
</ul>
<li><strong class=\"headline\">[Earlier semesters](#earlier)</strong></li>
<li><strong class=\"headline\">[Supervision (of theses etc.)](#supervision)</strong></li>
<li><strong class=\"headline\">[Finished Theses](#mscthesis)</strong></li>
<!--
<li><strong class=\"headline\">current funded projects</strong>
{{query where=\"?resourceUri a eis:FundedProject. OPTIONAL { ?resourceUri eis:status ?status }  FILTER (?status != 'finished')\" template=\"liplain\"}}
</li>
<li><strong class=\"headline\">featured projects</strong>
{{query where=\"?resourceUri eis:promoted 'true'^^xsd:boolean.\" template=\"liplain\"}}
</li>
-->
</ul>
</nav>

<a name=\"general\"></a>
General
-------
* [Tips & tricks for using SlideWiki](/SlideWikiTips.html), the system in which we maintain our lecture notes
* How to get access to eCampus (essential for receiving email announcements, and for accessing non-public material)
  1. If you are a student of the University of Bonn, you most likely have a [Uni-ID (university-wide user account)](http://www.hrz.uni-bonn.de/service/identity-management/uni-id) already.
  1. If you are a guest ([*Gasthörer, Zweithörer*, etc. = user group 4](http://www.hrz.uni-bonn.de/service/identity-management/benutzergruppen)), you need to apply for a Uni-ID.
  1. The first step is to fill the [application online form](http://www.hrz.uni-bonn.de/service/identity-management/benutzungsantrag) (*Neuantrag* = new application; *Verlängerung* = renewal).
  1. Then you need to [hand in some paper documents](http://www.hrz.uni-bonn.de/service/identity-management/benutzergruppen) and will receive your login credentials.
  1. In case of problems, please contact the help desk ([InfoPunkt Uni-ID/University IT services](http://www.hrz.uni-bonn.de/kontakt), [eCampus-specific](https://ecampus.uni-bonn.de/goto.php?target=cat_487854)).

<a name=\"winter\"></a>
Winter Semester 2014/15
------------------

<a name=\"winter-lecture\"></a>
### Semantic Web Lecture (MA-INF 4312)

[eCampus](https://ecampus.uni-bonn.de/goto_ecampus_crs_525221.html), [BASIS](https://basis.uni-bonn.de/qisserver/rds?state=verpublish&status=init&vmfile=no&publishid=91350&moduleCall=webInfo&publishConfFile=webInfo&publishSubDir=veranstaltung), [Slides](http://slidewiki.org/deck/750/latest/)

* Work Load – 180hr.
* Credit Points – 6CP.
* Duration – 1 Semester.
* Programme – M. Sc. Computer Science

The goal of this lecture is to impart knowledge on the fundamentals, technologies and applications of the Semantic Web and information retrieval. As part of the lecture the basic concepts and standards for semantic technologies are explained.

As part of the W3C Semantic Web initiative standards and technologies have been developed for machine-readable exchange of data, information and knowledge on the Web. These standards and technologies are increasingly being used in applications and have already led to a number of exciting projects (e.g. DBpedia, semantic wiki or commercial applications such as schema.org, OpenCalais, or Google’s Freebase). The module provides a theoretically grounded and practically oriented introduction to this area. The topics discussed within the lecture include:

- RDF syntax and data model;
- RDF Schema and formal semantics of RDF (S);
- Ontologies in OWL and formal semantics of OWL;
- RDF databases, triple and knowledge stores, query languages;
- Linked Data Web and Semantic Web applications;
- Semantic text analysis and information retrieval systems.

* Lecturers – [Prof. Dr. Sören Auer](http://eis.iai.uni-bonn.de/SoerenAuer), [Dr. Christoph Lange](http://eis.iai.uni-bonn.de/ChristophLange).
* Pre-Requisites – none.
* Format – Lectures and Exercises with a final (graded) written exam.

<a name=\"winter-seminar\"></a>
### Semantic Web Seminar (MA-INF 4313)

[eCampus](https://ecampus.uni-bonn.de/goto_ecampus_crs_525219.html), [BASIS](https://basis.uni-bonn.de/qisserver/rds?state=verpublish&status=init&vmfile=no&publishid=91381&moduleCall=webInfo&publishConfFile=webInfo&publishSubDir=veranstaltung), [Topics and Schedule](https://docs.google.com/spreadsheets/d/1J5_lVB52KDZGzt0Pd2nvZ3bX4YfpEO8mman0DgyPkOQ/edit#gid=0), [GitHub](https://github.com/EIS-Bonn/MA-INF4313-Seminar) (students and instructors only)

* Work Load – 120hr.
* Credit Points – 4CP.
* Duration – 1 Semester.
* Programme – M. Sc. Computer Science

Through the seminar, students will learn to work with tools and technologies of the Semantic Web as well as assess their capabilities for given problems. They will gain the ability to understand new research results presented in original scientific papers.

Seminar sessions include but not limited to presentations on:
1. Semantic Web Technologies (Triple Stores, Link Discovery Frameworks, NLP Pipelines);
2. Research work submitted to top-tier conferences (such as WWW, ESWC, ISWC) or good journal papers.

* Lecturers – [Dr. Christoph Lange](http://eis.iai.uni-bonn.de/ChristophLange \"Dr. Christoph Lange\"), [Dr. Fabrizio Orlandi](http://eis.iai.uni-bonn.de/FabrizioOrlandi).
* Pre-Requisites – none.
* Format – Oral presentation, written report (graded).

<a name=\"winter-lab\"></a>
### Semantic Web Lab (MA-INF 4314)

[eCampus](https://ecampus.uni-bonn.de/goto_ecampus_crs_525217.html), [BASIS](https://basis.uni-bonn.de/qisserver/rds?state=verpublish&status=init&vmfile=no&publishid=91382&moduleCall=webInfo&publishConfFile=webInfo&publishSubDir=veranstaltung), [GitHub](https://github.com/EIS-Bonn/MA-INF4314-Lab), [Topics, Schedule, Timesheets](https://docs.google.com/spreadsheets/d/19juwwozk5aIsXFH3h73ZMr1Q7kEHXICR7FE8U8LB0eI/edit#gid=1773446858) (students and instructors only)

* Work Load – 270hr.
* Credit Points – 9CP.
* Duration – 1 Semester.
* Programme – M. Sc. Computer Science

The students will carry out a practical task (project) in the context of Semantic Web technologies, including test and documentation of the implemented software/system.

The student should have the ability to properly present and defend design decisions, to prepare readable documentation of software; skills in constructively collaborating with others in small teams over a longer period of time; ability to classify own results with regard to the state-of-the-art

* Lecturers – [Prof. Dr. Sören Auer](http://eis.iai.uni-bonn.de/SoerenAuer \"Prof. Dr. Sören Auer\"), [Dr. Christoph Lange](http://eis.iai.uni-bonn.de/ChristophLange \"Dr. Christoph Lange\").
* Pre-Requisites – none.
* Format – Oral presentation, written report (graded).


<a name=\"summer\"></a>
Summer Semester
------------------

<a name=\"summer-lecture\"></a>
### Enterprise Information Systems Module (MA-INF 3230)

[eCampus](https://ecampus.uni-bonn.de/ilias.php?ref_id=450807&cmdClass=ilinfoscreengui&cmd=showSummary&cmdNode=l8:cq:8l&baseClass=ilRepositoryGUI), [BASIS](https://basis.uni-bonn.de/qisserver/rds?state=verpublish&status=init&vmfile=no&publishid=85222&moduleCall=webInfo&publishConfFile=webInfo&publishSubDir=veranstaltung)

* Work Load – 180hr.
* Credit Points – 6CP.
* Duration – 1 Semester.
* Programme – M. Sc. Computer Science

Students acquire knowledge in the design, development and use of information systems in companies and organizations in general but also in online communities, and inter-enterprise value chains. Topics included:

- Information systems in the enterprise, in particular Enterprise Resource Planning (ERP), Customer Relationship Management (CRM), Supply Chain Management (SCM), data warehouse / business intelligence, e-commerce, geographic information systems;
- Technologies for the implementation of modern information systems and information system environments: in particular, service-oriented information system architectures, workflow management (BPEL), semantic-based data integration, business process management;
- Information systems for the processing of Big Data in particular transactions (OLTP) and analytical information systems (OLAP) for decision support. Data Warehousing and Data Mining.

* Lecturers – [Prof. Dr. Sören Auer](http://eis.iai.uni-bonn.de/SoerenAuer), [Dr. Simon Scerri](http://eis.iai.uni-bonn.de/SimonScerri \"Dr. Simon Scerri\"), [Dr. Fabrizio Orlandi](http://eis.iai.uni-bonn.de/FabrizioOrlandi \"Dr. Fabrizio Orlandi\").
* Pre-Requisites – none.
* Format – Lectures and Exercises with a final (graded) written exam.

<a name=\"summer-seminar\"></a>
### Enterprise Information Systems Seminar (MA-INF 3231)

[eCampus](https://ecampus.uni-bonn.de/ilias.php?ref_id=467983&cmdClass=ilinfoscreengui&cmd=showSummary&cmdNode=l8:cq:8l&baseClass=ilRepositoryGUI), [BASIS](https://basis.uni-bonn.de/qisserver/rds?state=verpublish&status=init&vmfile=no&publishid=85225&moduleCall=webInfo&publishConfFile=webInfo&publishSubDir=veranstaltung)

* Work Load – 120hr.
* Credit Points – 4CP.
* Duration – 1 Semester.
* Programme – M. Sc. Computer Science

The student will learn about new research results presented in original scientific papers and technologies in the area of Enterprise Information Systems. The student should be able to present and to critically discuss these results in the framework of the corresponding area.

* Lecturers – [Dr. Simon Scerri](http://eis.iai.uni-bonn.de/SimonScerri \"Dr. Simon Scerri\"), [Dr. Fabrizio Orlandi](http://eis.iai.uni-bonn.de/FabrizioOrlandi \"Dr. Fabrizio Orlandi\").
* Pre-Requisites – none.
* Format – Oral presentation with a written report (graded).

<a name=\"summer-lab\"></a>
### Enterprise Information Systems Lab (MA-INF 3232)

[eCampus](https://ecampus.uni-bonn.de/goto_ecampus_crs_460085.html), [BASIS](https://basis.uni-bonn.de/qisserver/rds?state=verpublish&status=init&vmfile=no&publishid=85248&moduleCall=webInfo&publishConfFile=webInfo&publishSubDir=veranstaltung)

* Work Load – 270hr.
* Credit Points – 9CP.
* Duration – 1 Semester.
* Programme – M. Sc. Computer Science

The students will carry out a practical task (project) in the context of Enterprise Information Systems, including test and documentation of the implemented software/system.

The student should be able to properly present and defend design decisions, to prepare readable documentation of software; skills in constructively collaborating with others in small teams over a longer period of time; ability to classify own results into the state-of-the-art in the area of

* Lecturers – [Dr. Simon Scerri](http://eis.iai.uni-bonn.de/SimonScerri \"Dr. Simon Scerri\").
* Pre-Requisites – none.
* Format – Oral presentation with a written report (graded).

<a name=\"earlier\"></a>
Earlier Semesters
------------------
* Winter 2013/14
 * MA-INF 4301 – Advanced Topics in Artificial Intelligence: Semantic Web Technologies: [eCampus](https://ecampus.uni-bonn.de/goto_ecampus_crs_367634.html), [BASIS](https://basis.uni-bonn.de/qisserver/rds?state=verpublish&status=init&vmfile=no&publishid=77982&moduleCall=webInfo&publishConfFile=webInfo&publishSubDir=veranstaltung), [Slides](http://slidewiki.org/deck/750/latest/)
 * MA-INF 4313 – Seminar/Lab Semantic Data: [eCampus](https://ecampus.uni-bonn.de/goto_ecampus_crs_374300.html), [BASIS](https://basis.uni-bonn.de/qisserver/rds?state=verpublish&status=init&vmfile=no&publishid=80514&moduleCall=webInfo&publishConfFile=webInfo&publishSubDir=veranstaltung)

<a name=\"supervision\"></a>
Student Supervision
------------------
We also have a number of Lab, Bachelors and Masters thesis in the area of Semantic Web and Enterprise Information Systems. A list of [topics](/Topics \"Topics\") is available whilst we also encourage students to come up with their own idea about a possible topic.  If you suggest your own topic, please prepare a justification of why you think it is a good topic.  Also be aware that we may not have sufficient capacity to supervise all topics you may come up with.

<a name=\"mscthesis\"></a>
Finished Theses
---------------
The following theses were finished in our group.  These are masters' theses unless stated otherwise.  The most recent ones are listed first.

### 2015

* [Green Shifting – A mobile application for the energy efficient usage of renewable energy](http://eis-bonn.github.io/Theses/2015/Theresa_Otte/thesis.pdf), by Theresa Otte
* [Measuring and improving the quality of user interaction with learning management systems](http://eis-bonn.github.io/Theses/2015/Farid_Hasanov/thesis.pdf), by Farid Hasanov
* [A Framework for RDF Data Exploration and Conversion](http://eis-bonn.github.io/Theses/2015/Gaurav_SinghaRoy/thesis.pdf), by Gaurav SinghaRoy

### 2014

* [Disease Information and Semantic Web](http://eis-bonn.github.io/Theses/2014/Turan_Gojayev/thesis.pdf), by Turan Gojayev
* [RDF Quality Extension for OpenRefine](http://eis-bonn.github.io/Theses/2014/Muhammad_Ali_Qasmi/thesis.pdf), by Muhammad Ali Qasmi
* [Crowdsourced Semantic Annotation of Scientific Publications](http://eis-bonn.github.io/Theses/2014/Jaana_Takis/thesis.pdf), by Jaana Takis
* [Semantisches Mapping von Microsoft SharePoint](http://eis-bonn.github.io/Theses/2014/Daniel_Weber/thesis.pdf), by Daniel Weber (Bachelor)
* [Quality Assessment for Linked Open Data: Assessing the Trustworthiness and Relevancy Dimensions](http://eis-bonn.github.io/Theses/2014/Carlos_Montoya/thesis.pdf), by Carlos Montoya
* [Design and Development of a Semantic Web based Data Model for Text Analytics](http://eis-bonn.github.io/Theses/2014/Navid_Nourbakhsh/thesis.pdf), by Navid Nourbakhsh
* [Generalisierung der Persistenzschicht im semantischen Daten-Wiki OntoWiki](http://eis-bonn.github.io/Theses/2014/Matthias_Molitor/thesis.pdf), by Matthias Molitor (Diplom)
"""^^sysont:Markdown .

people:Team site:content """<nav class=\"nav-sidelinks\">
<ul>
<li><strong class=\"headline\">people</strong>
{{query where=\"?group foaf:member ?resourceUri . OPTIONAL { ?resourceUri <http://xmlns.com/foaf/0.1/familyName> ?familyName }\" template=\"liplain\" orderby=\"ASC(?familyName)\"}}
</li>
</ul>
</nav>


{{query where=\"?group foaf:member ?resourceUri  . OPTIONAL { ?resourceUri foaf:familyName ?familyName }\" template=\"li-person-matrix\" orderby=\"ASC(?familyName)\"}}
"""^^sysont:Markdown .

people:Topics a foaf:Document ;
              rdfs:label "Topics" ;
              site:content """

<style>
		.project{
			border: 1px solid black;
			margin-bottom: 10px;
			padding:5px;
			display:block;
		}
		.label{
			font-style:italic;
			clear:both;
		}
		.description{
		}
		.level{
			color:red;
		}
		.requirements{
			color:red;
		}
		.exhibit-collectionSummaryWidget-results{
			display:none;
		}
		.exhibit-collectionView-header{
			display:none;
		}
    </style>

<div style=\"width: 100%\"><table style=\"font-size: 100%\" cellspacing=\"10\" width=\"100%\">
            <tr valign=\"top\">
                <td>
                    <div id=\"exhibit-control-panel\"></div>
                    <div id=\"exhibit-view-panel\">
						<h1>Projects</h1>
                        <div ex:role=\"exhibit-lens\" class=\"project\">
                            <b><span ex:content=\".label\" class=\"label\"></span></b><br/>
                                <span ex:content=\".description\" class=\"description\"></span><br/>
								<b>Domain:</b> <span ex:content=\".domain\"></span><br/>
								<div ex:if-exists=\".requirements\">
								<b>Requirements:</b> <span ex:content=\".requirements\" class=\"requirements\"></span>
								</div>
                                <b>Level:</b> <span ex:content=\".level\" class=\"level\"></span><br/>
								<div ex:if-exists=\".url\">
								<b>More Information:</b> <span ex:content=\".url\"></span>
								</div>
								<b>Contact:</b> <a ex:if-exists=\".email\" ex:href-content=\".email\" ><span ex:content=\".contact\"></span></a>
                        </div>
                       <div ex:role=\"exhibit-view\"
                            ex:viewClass=\"Exhibit.TileView\"
                            ex:orders=\".label\"
                            ex:directions=\"ascending\"
                            ex:possibleOrders=\".level, .contact\"
                            ex:showAll=\"true\"
                            ex:grouped=\"false\">
                        </div>
                    </div>
                </td>
                <td width=\"25%\">
                    <div ex:role=\"facet\" ex:expression=\".technologies\" ex:sortMode=\"count\" ex:facetLabel=\"Technologies\"></div>
					<div ex:role=\"facet\" ex:expression=\".domain\" ex:sortMode=\"count\" ex:facetLabel=\"Domain\"></div>
					<div ex:role=\"facet\" ex:expression=\".level\" ex:sortMode=\"count\" ex:facetLabel=\"Level\"></div>
					<div ex:role=\"facet\" ex:expression=\".contact\" ex:sortMode=\"count\" ex:facetLabel=\"Contact Person\"></div>
                </td>
            </tr>
        </table></div>

    """^^sysont:Markdown .

people:blog rdfs:label "Blog" .

people:eswc_rdf2any_eval rdfs:label "Linked Data Publication and Consumption Framework" ;
                         eis:hookline "Usability Evaluation Resources" ;
                         site:content """#### [Download Evaluation Form](https://www.dropbox.com/s/zw2x5hleawbvmse/LinDA%20Publication%20and%20Consumption%20Framework%20Evaluation%20-%20Google%20Forms.pdf?dl=0 \"Download Evaluation Form\")

#### [View Evaluation Results](https://docs.google.com/spreadsheets/d/1okMbaRehvXWnCaSfVLHG6GzgA34nNhQkshYn20Lqau4/pubhtml?gid=100387488&single=true \"View Evaluation Results\")"""^^sysont:Markdown .

eis:AlumniProject a owl:Class ;
                  rdfs:label "Alumni Project" ;
                  rdfs:subClassOf foaf:Project ;
                  sysont:creationLabel "Projects" ;
                  site:classTemplate "project" .

eis:CommunityProject a owl:Class ;
                     rdfs:label "Community Project" ;
                     rdfs:subClassOf foaf:Project ;
                     sysont:creationLabel "Projects" ;
                     site:classTemplate "project" .

eis:DatasetProject a owl:Class ;
                   rdfs:label "Dataset Project" ;
                   rdfs:subClassOf foaf:Project ;
                   sysont:creationLabel "Projects" ;
                   site:classTemplate "project" .

eis:Demo a owl:Class ;
         rdfs:label "Demo" ;
         rdfs:subClassOf foaf:Project ;
         site:classTemplate "project" .

eis:FundedProject a owl:Class ;
                  rdfs:label "Funded Project" ;
                  rdfs:subClassOf foaf:Project ;
                  sysont:creationLabel "Projects" ;
                  site:classTemplate "project" .

eis:IncubatorProject a owl:Class ;
                     rdfs:label "Incubator Project" ;
                     rdfs:subClassOf foaf:Project ;
                     sysont:creationLabel "Projects" ;
                     site:classTemplate "project" .

eis:OpenSourceProject a owl:Class ;
                      rdfs:label "OpenSource Project" ;
                      rdfs:subClassOf foaf:Project ;
                      sysont:creationLabel "Projects" ;
                      site:classTemplate "project" .

eis:Partner rdfs:label "Project Partner" .

eis:Talk a owl:Class, <http://www.w3.org/2002/07/owl#Class.> ;
         rdfs:label "Vortrag"@de, "Talk" ;
         rdfs:isDefinedBy <http://eis.iai.uni-bonn.de/schema/> ;
         rdfs:subClassOf schema:Event ;
         rdfs:seeAlso <http://data.semanticweb.org/ns/swc/ontology#TalkEvent> ;
         site:classTemplate "talk" .

eis:affiliation a <http://www.w3.org/2002/07/owl#DatatypeProperty.> .

eis:buttonLabel a owl:DatatypeProperty ;
                rdfs:label "button label" ;
                rdfs:comment "this *magic* label of a resource is used as a link button text where suitable" ;
                rdfs:subPropertyOf rdfs:label .

eis:demonstrates a owl:ObjectProperty ;
                 rdfs:label "demonstrates" ;
                 rdfs:domain eis:Demo ;
                 rdfs:range foaf:Project ;
                 rdfs:comment "which project is demonstrated by this demo" ;
                 eis:buttonLabel "Demo" .

eis:funding a owl:DatatypeProperty ;
            rdfs:label "funding" ;
            rdfs:range xsd:nonNegativeInteger ;
            dcterms:description "values of this property is an amount of money in EUR - (nonNegativeIntegers)"^^sysont:Markdown ;
            vs:term_status "testing" .

eis:hookline a owl:DatatypeProperty, <http://www.w3.org/2002/07/owl#DatatypeProperty.> ;
             rdfs:label "hookline" .

eis:partner a owl:ObjectProperty ;
            rdfs:label "partner" ;
            rdfs:domain foaf:Project ;
            rdfs:range foaf:Organization ;
            rdfs:comment "This links an AKSW partner to project."^^sysont:Markdown .

eis:people-default-location a site:TemplateOption ;
                            rdfs:label "people default location" ;
                            rdfs:comment "the default location for all persons"^^sysont:Markdown .

eis:promoted a owl:DatatypeProperty ;
             rdfs:label "promoted" ;
             rdfs:comment "a project which is promoted e.g. on the startpage" .

eis:publicationTag a owl:DatatypeProperty ;
                   rdfs:label "publication tag" ;
                   rdfs:comment "the tag which is used for this project / agend in the aksw.bib file" .

eis:relatedProject a owl:ObjectProperty ;
                   rdfs:label "related project" ;
                   rdfs:domain foaf:Project ;
                   rdfs:range foaf:Project ;
                   rdfs:comment "a symmetric relation between two projects" ;
                   rdfs:subPropertyOf owl:SymmetricProperty .

eis:researchAreas a owl:DatatypeProperty ;
                  rdfs:label "research areas" ;
                  rdfs:domain foaf:Agent .

eis:sideNavigation a owl:ObjectProperty, <http://www.w3.org/2002/07/owl#ObjectProperty.> ;
                   rdfs:label "side navigation" ;
                   rdfs:comment "links to the navigation element which should be rendered in the navigation area on the left"^^sysont:Markdown .

eis:status a owl:DatatypeProperty ;
           rdfs:label "status" ;
           rdfs:domain foaf:Project .

ns18:Computer_Science_Conference_for_University_of_Bonn_Students_2014 a schema:Event ;
                                                                      rdfs:label "Computer Science Conference for University of Bonn Students 2014" ;
                                                                      schema:location address:Romerstrasse164 ;
                                                                      dcterms:abstract "The 1st Computer Science Conference for University of Bonn Students (CSCUBS) will be held on May 21, 2014 (Dies Academicus) at the University of Bonn. CSCUBS is organised by PhD- and MSc-Students and aims to promote research in computer science and scientific exchange among students. The participation of researchers and practitioners of the field is also encouraged. CSCUBS intends to provide the ability to connect with each other and engage in discussions about the participants' respective research and development, and also to establish opportunities for knowledge and technology sharing. Submissions to CSCUBS should describe new research or development related to Computer Science, including University projects, theses, outcomes of professional or leisure activities." ;
                                                                      schema:startDate "2014-05-21"^^xsd:date ;
                                                                      site:abbrevation "CSCUBS 2014" ;
                                                                      schema:additionalType schema:EducationEvent ;
                                                                      schema:performer groups:EIS ;
                                                                      schema:endDate "\"2014-05-21\"^^xsd:date" ;
                                                                      eis:hookline "Computer Science Conference for Students during Dies Academicus" ;
                                                                      site:content """We invite all Students (CS and non-CS) to present their work e.g. Lab Results, Demo Programs, Original Research, Bachelor’s/ Master’s /PhD Thesis, Leisure/professional activities related to CS.

CSCUBS will have **Dr. Andreas Ribbrock** as a keynote speaker. Dr. Ribbrock is a Uni Bonn alumnus and will discuss the cool reasons behind why one should study computer science. The keynote will include a short presentation of Teradata, where Dr. Ribbrock works as a team lead and senior architect.

The Computer Science Conference of University of Bonn Students is awarding the Best Student Paper 2014 Award. The award is endowed with a prize of 500€ sponsored by Fraunhofer IAIS for the honored authors.

Our sponsor Fraunhofer IAIS always has jobs for CS graduates to offer; at the moment they are specifically looking for seasoned Java and C++ software developers proficient in German.

information about the CSCUBS Venue please check:
http://cscubs.cs.uni-bonn.de/2014/"""^^sysont:Markdown .

ns18:Computer_Science_Conference_for_University_of_Bonn_Students_2015 a schema:Event ;
                                                                      rdfs:label "Computer Science Conference for University of Bonn Students 2015" ;
                                                                      schema:location <http://eis.iai.uni-bonn.de/Romerstra%C3%9Fe%20164%2C%2053117%20Bonn> ;
                                                                      dcterms:abstract "The 2nd Computer Science Conference for University of Bonn Students (CSCUBS) will be held on May 20, 2015 (Dies Academicus) at the University of Bonn. CSCUBS is organised by PhD- and MSc-Students and aims to promote research in computer science and scientific exchange among students. The participation of researchers and practitioners of the field is also encouraged. CSCUBS intends to provide the ability to connect with each other and engage in discussions about the participants' respective research and development, and also to establish opportunities for knowledge and technology sharing. Submissions to CSCUBS should describe new research or development related to Computer Science, including University projects, theses, outcomes of professional or leisure activities." ;
                                                                      schema:startDate "2015-05-20T00:00:00+01:00"^^xsd:dateTime ;
                                                                      site:abbrevation "CSCUBS 2015" ;
                                                                      schema:additionalType schema:EducationEvent ;
                                                                      schema:performer groups:EIS ;
                                                                      schema:endDate "2015-05-20" ;
                                                                      eis:hookline "Computer Science Conference for Students during Dies Academicus" ;
                                                                      site:content """We invite all Students (CS and non-CS) to present their work e.g. Lab Results, Demo Programs, Original Research, Bachelor’s/ Master’s /PhD Thesis, Leisure/professional activities related to CS.

CSCUBS will have Dr. Andreas Ribbrock as a keynote speaker. Dr. Ribbrock is a Uni Bonn alumnus and will discuss the cool reasons behind why one should study computer science. The keynote will include a short presentation of Teradata, where Dr. Ribbrock works as a team lead and senior architect.

The Computer Science Conference of University of Bonn Students is awarding the Best Student Paper 2015 Award. The award is endowed with a prize of 500€ sponsored by Fraunhofer IAIS for the honored authors.

Our sponsor Fraunhofer IAIS always has jobs for CS graduates to offer; at the moment they are specifically looking for seasoned Java and C++ software developers proficient in German.

information about the CSCUBS Venue please check:
http://cscubs.cs.uni-bonn.de/2015/"""^^sysont:Markdown .

ns18:Doctoral_College_Workshop_2015 a schema:Event ;
                                    rdfs:label "Doctoral College Workshop 2015 (Seminar- St Etienne -- Bonn) " ;
                                    schema:location address:Schloss_Birlinghoven_1_53754_Sankt_Augustin ;
                                    dcterms:abstract """This seminar is initiation of the SeReCo French German Doctoral College (CDFA/DFDK). This structured graduate programme explores the synergy between the World Wide Web (WWW) and Artificial Intelligence (AI) domains of research focusing on semantic technologies to provide machines with the possibility to reason on the digital contents made available, and, on the other hand on the coordination technologies to provide machines with the possibility to coordinate and cooperate to offer added value services to users from the ever increasing set of deployed services. Their tight integration leads to innovations in computer science and application domains. Objectives
----------


The scientific purpose of the seminar is to explore the spectrum of technologies related to semantics, reasoning and coordination in distributed and open environments (such as the Web) as developed in both laboratories.

The research works include the following topics:

- Semantic data modeling: Linked data, Ontologies, Annotations,
- Reasoning on the Semantic Web,
- Knowledge extraction, knowledge modeling and knowledge integration,
- Adaptive applications and coordination,
- Management and protection of identity, privacy and confidentiality,
- Multi-Agent-based modeling and programming of open and decentralized systems,
- Coordination models and technologies,
- Self-Organizing systems,
- Context aware mobile applications (using mobile devices and sensors)

The aim of the seminar is also to create and foster a synergy into and within the research groups.""" ;
                                    schema:startDate "2015-02-23T00:00:00+01:00"^^xsd:dateTime ;
                                    schema:performer groups:EIS ;
                                    schema:endDate "2015-02-24" ;
                                    site:content """Context
-------


This seminar is initiation of the SeReCo French German Doctoral College (CDFA/DFDK). This structured graduate programme explores the synergy between the World Wide Web (WWW) and Artificial Intelligence (AI) domains of research focusing on semantic technologies to provide machines with the possibility to reason on the digital contents made available, and, on the other
hand on the coordination technologies to provide machines with the possibility to coordinate and cooperate to offer added value services to users from the ever increasing set of deployed services. Their tight integration leads to innovations in computer science and application domains.

Objectives
----------


The scientific purpose of the seminar is to explore the spectrum of technologies related to semantics, reasoning and coordination in distributed and open environments (such as the Web) as developed in both laboratories.

The research works include the following topics:

- Semantic data modeling: Linked data, Ontologies, Annotations,
- Reasoning on the Semantic Web,
- Knowledge extraction, knowledge modeling and knowledge integration,
- Adaptive applications and coordination,
- Management and protection of identity, privacy and confidentiality,
- Multi-Agent-based modeling and programming of open and decentralized systems,
- Coordination models and technologies,
- Self-Organizing systems,
- Context aware mobile applications (using mobile devices and sensors)

The aim of the seminar is also to create and foster a synergy into and within the research groups."""^^sysont:Markdown .

<http://eis.iai.uni-bonn.de/vCard/Bonn> a v:VCard ;
                                        rdfs:label "[Office Bonn]" ;
                                        v:adr <http://aksw.org/vCard/Bonn#adr> .

<http://eis.iai.uni-bonn.de/vCard/Leipzig> a v:VCard ;
                                           rdfs:label "[Office Leipzig]" ;
                                           v:adr <http://eis.iai.uni-bonn.de/Address/vCard/Augustusplatz10> .

<http://github.com/white-gecko> a schema:ProfilePage ;
                                foaf:primaryTopic people:NatanaelArndt ;
                                eis:buttonLabel "@github" .

<http://gitorious.org/~csarven> a schema:ProfilePage ;
                                foaf:primaryTopic people:SarvenCapadisli ;
                                eis:buttonLabel "@gitorious" .

<http://identi.ca/csarven> a schema:ProfilePage ;
                           foaf:primaryTopic people:SarvenCapadisli ;
                           eis:buttonLabel "@Identica" .

lod2:contentRaw a owl:DatatypeProperty ;
                rdfs:label "raw content" .

lod2:exhibitData a owl:ObjectProperty ;
                 rdfs:label "exhibit data" .

site:MovedResource a owl:Class ;
                   rdfs:label "Moved Resource" ;
                   rdfs:isDefinedBy <http://ns.ontowiki.net/SysOnt/Site/> ;
                   rdfs:comment "a resource which is moved to another namespace or which URI is changed for some reason." ;
                   sysont:hidden "1"^^xsd:integer ;
                   skos:note "moved resources should link with site:seeAlso to the new URI" .

site:Navigation a rdfs:Class ;
                rdfs:label "Navigation" ;
                rdfs:comment "an RDF sequence resource which is used by the site extensions menu helper" ;
                rdfs:subClassOf rdf:Seq ;
                skos:note "menu items can have a special label with site:menuLabel" .

site:TemplateOption a owl:Class ;
                    rdfs:label "Template Option" ;
                    rdfs:isDefinedBy <http://ns.ontowiki.net/SysOnt/Site/> ;
                    rdfs:comment "the class of site specific template relevant options which can be used on resources, classes and datasets" ;
                    rdfs:subClassOf owl:DatatypeProperty ;
                    sysont:hidden "1"^^xsd:integer .

site:abbrevation a owl:DatatypeProperty ;
                 rdfs:label "abbrevation" ;
                 rdfs:comment "the abbrevation of a resource is used e.g. as a url naming part as well as can be used for better searching." ;
                 rdfs:subPropertyOf skos:altLabel .

site:classTemplate a owl:DatatypeProperty, owl:FunctionalProperty ;
                   rdfs:label "class template" ;
                   rdfs:domain owl:Class ;
                   rdfs:range xsd:string ;
                   rdfs:comment "identifies the template which is used to render the HTML representation of the resources of this class" .

site:menuLabel a owl:DatatypeProperty, owl:FunctionalProperty ;
               rdfs:label "menu label" ;
               rdfs:comment "if present, the navigation list helper uses this literal for the display name of the menu item" ;
               rdfs:subPropertyOf skos:altLabel .

site:seeAlso a owl:ObjectProperty, owl:FunctionalProperty ;
             rdfs:label "seeAlso (site)" ;
             rdfs:isDefinedBy <http://ns.ontowiki.net/SysOnt/Site/> ;
             rdfs:comment "If a requested resources links with this property to another resource, the server should forward to this resource" ;
             rdfs:subPropertyOf rdfs:seeAlso .

site:template a owl:DatatypeProperty, owl:FunctionalProperty ;
              rdfs:label "template" ;
              rdfs:range xsd:string ;
              rdfs:comment "this attribute overwrites the site:classTemplate property", "identifies the template which is used to render the HTML representation of this specific resources" .

site:templateOption a owl:DatatypeProperty ;
                    rdfs:label "template option" ;
                    rdfs:comment "this property is used to forward some site specific options to rendering template", "Currently, 'minimal' and 'extended' are used to adjust the publication integration" .

sysont:creationLabel a owl:DatatypeProperty ;
                     rdfs:label "creationLabel" ;
                     rdfs:domain <owl:Class> ;
                     rdfs:seeAlso <https://github.com/AKSW/OntoWiki/wiki/Resource-Creation-Extension> .

sysont:hidden a owl:DatatypeProperty, owl:FunctionalProperty ;
              rdfs:label "hidden" ;
              rdfs:domain owl:Thing ;
              rdfs:range xsd:boolean ;
              rdfs:comment "All resources (especially Models, Classes and Properties) can be hidden." .

sysont:instanceNamingScheme a owl:DatatypeProperty ;
                            rdfs:label "instanceNamingScheme" ;
                            rdfs:domain <owl:Class> ;
                            rdfs:seeAlso <https://github.com/AKSW/OntoWiki/wiki/Resource-Creation-Extension> .

<http://ok-mobivoc.iais.fraunhofer.de/> a eis:Demo ;
                                        rdfs:label "VoCol" ;
                                        ov:screenshot <https://lh5.googleusercontent.com/-3UwR2uusWIs/VNC-ubAUzCI/AAAAAAAAAAk/s7XfhhbPNUc/w1147-h881-no/VoCol.jpg> ;
                                        eis:demonstrates projects:VoCol ;
                                        eis:hookline "A low-threshold agile methodology for collaborative vocabulary development" .

ov:businessCard a rdf:Property ;
                rdfs:label "Business Card"@en ;
                rdfs:range v:VCard ;
                rdfs:isDefinedBy <http://open.vocab.org/terms> ;
                rdfs:comment "A business card associated with this resource."@en ;
                owl:equivalentProperty <http://purl.org/uF/hCard/terms/hasCard> ;
                vs:term_status "unstable" ;
                skos:note <http://open.vocab.org/changes/0a8d6d27db41d0a297e67d0da3f0c45b>, <http://open.vocab.org/changes/4d316062a929a47b0313fddaa68084b5> ;
                label:plural "Business Cards"@en ;
                vs:userdocs <http://open.vocab.org/docs/> .

ov:screenshot a rdf:Property ;
              rdfs:label "screenshot"@en ;
              rdfs:domain foaf:Project ;
              rdfs:range foaf:Image ;
              rdfs:isDefinedBy <http://open.vocab.org/terms> ;
              rdfs:comment "A screenshot showing the (software) project in action. Since DOAP only has a property to link a \"web page with screenshots of project\", not a specific screenshot, this property is sometimes more useful."@en ;
              rdfs:subPropertyOf foaf:depiction ;
              owl:inverseOf foaf:depicts ;
              label:plural "screenshots"@en .

dcterms:contributor a rdf:Property ;
                    rdfs:label "contributor" ;
                    rdfs:isDefinedBy <http://purl.org/dc/terms/> .

dcterms:creator a rdf:Property ;
                rdfs:label "creator" ;
                rdfs:isDefinedBy <http://purl.org/dc/terms/> .

dcterms:description rdfs:label "dct:description" .

dcterms:license a rdf:Property ;
                rdfs:label "license" ;
                rdfs:isDefinedBy <http://purl.org/dc/terms/> .

dcterms:publisher a rdf:Property ;
                  rdfs:label "publisher" ;
                  rdfs:isDefinedBy <http://purl.org/dc/terms/> .

dcterms:source a rdf:Property ;
               rdfs:label "source" ;
               rdfs:isDefinedBy <http://purl.org/dc/terms/> .

dcterms:subject a rdf:Property ;
                rdfs:label "subject" ;
                rdfs:isDefinedBy <http://purl.org/dc/terms/> .

dcterms:title a rdf:Property ;
              rdfs:label "title" ;
              rdfs:isDefinedBy <http://purl.org/dc/terms/> .

aiiso:ResearchGroup a owl:Class ;
                    rdfs:label "Research Group" ;
                    rdfs:isDefinedBy <http://purl.org/vocab/aiiso/schema#> ;
                    rdfs:comment "A Research Group is a group of people recognised by an organization as forming a cohesive group referred to by the organization as a research group." ;
                    rdfs:subClassOf foaf:Organization ;
                    sysont:creationLabel "Groups" ;
                    dcterms:issued "2008-05-14" ;
                    site:classTemplate "group" .

void:Dataset a owl:Class ;
             rdfs:label "Dataset" ;
             sysont:hidden "1"^^xsd:integer .

sioct:Comment a owl:Class ;
              rdfs:label "Comment"@en ;
              rdfs:isDefinedBy <http://rdfs.org/sioc/types#> ;
              rdfs:comment "Comment is a subtype of sioc:Post and allows one to explicitly indicate that this SIOC post is a comment.  Note that comments have a narrower scope than sioc:Post and may not apply to all types of community site."@en ;
              rdfs:seeAlso sioct:Forum ;
              sysont:hidden "1"^^xsd:integer .

<http://saim.eis.iai.uni-bonn.de/> eis:demonstrates projects:LIMES .

schema:Event site:classTemplate "event" .

schema:PostalAddress sysont:creationLabel "Address" .

<http://scholar.google.com/citations?user=ke7CJVIAAAAJ> a schema:ProfilePage ;
                                                        foaf:primaryTopic people:MichaelMartin ;
                                                        eis:buttonLabel "@GoogleScholar" .

<http://scholar.google.de/citations?user=dSMSH2wAAAAJ> a schema:ProfilePage ;
                                                       foaf:primaryTopic people:AliKhalili ;
                                                       eis:buttonLabel "@GoogleScholar" .

<http://scholar.google.de/citations?user=pyV5evQAAAAJ> a schema:ProfilePage ;
                                                       foaf:primaryTopic people:SebastianTramp ;
                                                       eis:buttonLabel "@Google Scholar" .

<http://scholar.google.de/citations?user=sEaQ5rgAAAAJ&hl=en> a schema:ProfilePage ;
                                                             foaf:primaryTopic people:JensLehmann ;
                                                             eis:buttonLabel "@Google Scholar" .

<http://sina.aksw.org/> a eis:Demo ;
                        rdfs:label "SINA" ;
                        ov:screenshot <https://lh5.googleusercontent.com/-AaWezkbDLNw/VNEIN9YPWBI/AAAAAAAAACQ/o81qPghuk3I/w1396-h881-no/SINA.png> ;
                        eis:demonstrates projects:SINA ;
                        eis:hookline "question answering system for Linked Data" .

<http://slidewiki.org/> a eis:Demo ;
                        rdfs:label "SlideWiki" ;
                        ov:screenshot <http://lh4.ggpht.com/-_ucInHOV87c/TrUtqpcwi7I/AAAAAAAABBs/p3bmvtSrHJ0/s800/slidewiki-home.png> ;
                        eis:demonstrates projects:SlideWiki ;
                        eis:hookline " helps communities to create great presentations collaborativel" .

<http://twitter.com/csarven> a schema:ProfilePage ;
                             foaf:primaryTopic people:SarvenCapadisli ;
                             eis:buttonLabel "@twitter" .

umbel:isLike a owl:ObjectProperty, owl:SymmetricProperty ;
             rdfs:domain owl:Thing ;
             rdfs:range owl:Thing ;
             rdfs:subPropertyOf owl:topObjectProperty ;
             skos:prefLabel "is like" ;
             skos:definition """The property umbel:isLike is used to assert an associative link between similar individuals who may or may not be identical, but are believed to be so. This property is not intended as a general expression of similarity, but rather the likely but uncertain same identity of the two resources being related.

This property can and should be changed if the certainty of the sameness of identity is subsequently determined.

In general, we may not be able to assert that two individuals are the same based solely on current information on hand. However, there may be quite reasonable bases or methods that the two individuals are likely the same without being one hundred percent sure.

umbel:isLike has the semantics of likely identity, but where there is some uncertainty that the two resources indeed refer to the exact same individual with the same identity. Such uncertainty can arise when, for example, common names may be used for different individuals (e.g., John Smith).

It is appropriate to use this property when there is strong belief the two resources refer to the same individual with the same identity, but that association can not be asserted at the present time with certitude. """ .

doap:Technical_Report a rdf:Property ;
                      rdfs:label "Technical Report" ;
                      rdfs:isDefinedBy <http://usefulinc.com/ns/doap#> ;
                      rdfs:comment "URL for technical report documents"^^sysont:Markdown ;
                      eis:buttonLabel "Technical Report" .

doap:browse a rdf:Property ;
            rdfs:label "browse" ;
            rdfs:domain doap:Repository ;
            rdfs:isDefinedBy <http://usefulinc.com/ns/doap#> ;
            rdfs:comment "Web browser interface to repository." ;
            eis:buttonLabel "Source Code" .

doap:bug-database a owl:ObjectProperty ;
                  rdfs:label "bug database" ;
                  rdfs:isDefinedBy <http://usefulinc.com/ns/doap#> ;
                  rdfs:comment "Bug tracker for a project." ;
                  eis:buttonLabel "Issues" .

doap:download-page a owl:ObjectProperty ;
                   rdfs:label "download page" ;
                   rdfs:isDefinedBy <http://usefulinc.com/ns/doap#> ;
                   rdfs:comment "Web page from which the project software can be downloaded." ;
                   eis:buttonLabel "Download" .

doap:maintainer a rdf:Property ;
                rdfs:label "maintainer" ;
                rdfs:isDefinedBy <http://usefulinc.com/ns/doap#> ;
                rdfs:comment "Maintainer of a project, a project leader." .

doap:programming-language a rdf:Property ;
                          rdfs:label "programming language" ;
                          rdfs:isDefinedBy <http://usefulinc.com/ns/doap#> ;
                          rdfs:comment "Programming language a project is implemented in or intended for use with." .

doap:wiki a rdf:Property ;
          rdfs:label "wiki" ;
          rdfs:isDefinedBy <http://usefulinc.com/ns/doap#> ;
          rdfs:comment "URL of Wiki for collaborative discussion of project." ;
          eis:buttonLabel "Wiki" .

ns4:endDate a rdf:Property ;
            rdfs:label "endDate" ;
            rdfs:range xsd:date .

ns4:startDate a rdf:Property ;
              rdfs:label "startDate" ;
              rdfs:range xsd:date ;
              rdfs:isDefinedBy <http://vocab.ox.ac.uk/projectfunding#> .

<http://wiki.eis.iai.uni-bonn.de/Internal> rdfs:label "Internal Area" .

ns23:id a foaf:Organization ;
        rdfs:label "Fraunhofer IAIS" ;
        foaf:homepage <http://www.iais.fraunhofer.de/> .

<http://www.informatik.uni-trier.de/~ley/pers/hd/m/Martin%3AMichael.html> a schema:ProfilePage ;
                                                                          foaf:primaryTopic people:MichaelMartin ;
                                                                          eis:buttonLabel "@DBLP" .

<http://www.informatik.uni-trier.de/~ley/pers/hd/t/Tramp%3ASebastian.html> a schema:ProfilePage ;
                                                                           foaf:primaryTopic people:SebastianTramp ;
                                                                           eis:buttonLabel "@DBLP" .

<http://www.ontos.com/> rdfs:label "Ontos AG" .

rdf:_1 a rdfs:ContainerMembershipProperty ;
       rdfs:label "1." .

rdf:_10 a rdfs:ContainerMembershipProperty ;
        rdfs:label "10." .

rdf:_2 a rdfs:ContainerMembershipProperty ;
       rdfs:label "2." .

rdf:_3 a rdfs:ContainerMembershipProperty ;
       rdfs:label "3" .

rdf:_4 a rdfs:ContainerMembershipProperty ;
       rdfs:label "4." .

rdf:_5 a rdfs:ContainerMembershipProperty ;
       rdfs:label "5." .

rdf:_6 a rdfs:ContainerMembershipProperty ;
       rdfs:label "6." .

rdf:_7 a rdfs:ContainerMembershipProperty ;
       rdfs:label "7." .

rdf:_8 a rdfs:ContainerMembershipProperty ;
       rdfs:label "8." .

rdf:_9 a rdfs:ContainerMembershipProperty ;
       rdfs:label "9." .

rdf:type a owl:ObjectProperty ;
         rdfs:label "type" ;
         rdfs:range <owl:Class> .

rdfs:label a owl:DatatypeProperty ;
           rdfs:label "label" .

owl:DatatypeProperty a rdfs:Class ;
                     rdfs:label "DatatypeProperty" ;
                     rdfs:isDefinedBy <http://www.w3.org/2002/07/owl#> ;
                     rdfs:comment "The class of data properties." ;
                     rdfs:subClassOf rdf:Property .

owl:ObjectProperty a rdfs:Class ;
                   rdfs:label "ObjectProperty" ;
                   rdfs:isDefinedBy <http://www.w3.org/2002/07/owl#> ;
                   rdfs:comment "The class of object properties." ;
                   rdfs:subClassOf rdf:Property .

skos:hiddenLabel a rdf:Property, owl:AnnotationProperty ;
                 rdfs:label "hidden label"@en ;
                 rdfs:isDefinedBy <http://www.w3.org/2004/02/skos/core> ;
                 rdfs:comment "skos:prefLabel, skos:altLabel and skos:hiddenLabel are pairwise disjoint properties."@en, "The range of skos:hiddenLabel is the class of RDF plain literals."@en ;
                 rdfs:subPropertyOf rdfs:label ;
                 skos:definition "A lexical label for a resource that should be hidden when generating visual displays of the resource, but should still be accessible to free text search operations."@en .

v:VCard a owl:Class ;
        rdfs:label "vCard" ;
        sysont:hidden "1"^^xsd:integer .

v:Work a owl:Class ;
       rdfs:label "vCard Work part" ;
       sysont:hidden "1"^^xsd:integer .

<http://www.xing.com/profile/Sebastian_Tramp> a schema:ProfilePage ;
                                              foaf:primaryTopic people:SebastianTramp ;
                                              eis:buttonLabel "@XING" .

foaf:Document a owl:Class ;
              rdfs:label "Document" ;
              sysont:instanceNamingScheme "label" ;
              site:classTemplate "document" .

foaf:Organization a owl:Class ;
                  rdfs:label "Organization" ;
                  sysont:creationLabel "Partner" ;
                  site:classTemplate "partner" .

foaf:Person a owl:Class ;
            rdfs:label "Person" ;
            sysont:instanceNamingScheme "label" ;
            eis:people-default-location address:Augustusplatz10 ;
            site:classTemplate "person" .

foaf:Project a owl:Class ;
             rdfs:label "Project" ;
             sysont:creationLabel "Projects" ;
             site:classTemplate "project" .

foaf:accountName a rdf:Property, owl:DatatypeProperty ;
                 rdfs:label "account name" ;
                 rdfs:domain foaf:OnlineAccount ;
                 rdfs:range rdfs:Literal ;
                 rdfs:isDefinedBy <http://xmlns.com/foaf/0.1/> ;
                 rdfs:comment "Indicates the name (identifier) associated with this online account." ;
                 vs:term_status "testing" .

foaf:currentProject a owl:ObjectProperty ;
                    rdfs:label "current project" .

foaf:holdsAccount a rdf:Property, owl:ObjectProperty ;
                  rdfs:label "account" ;
                  rdfs:domain foaf:Agent ;
                  rdfs:range foaf:OnlineAccount ;
                  rdfs:isDefinedBy <http://xmlns.com/foaf/0.1/> ;
                  rdfs:comment "Indicates an account held by this agent." ;
                  vs:term_status "archaic" .

foaf:homepage a owl:ObjectProperty ;
              rdfs:label "homepage" ;
              eis:buttonLabel "Homepage" .

foaf:mbox a owl:ObjectProperty ;
          rdfs:label "email" .

foaf:member a owl:ObjectProperty ;
            rdfs:label "member" .

foaf:name a rdf:Property, owl:DatatypeProperty ;
          rdfs:label "name" ;
          rdfs:domain owl:Thing ;
          rdfs:range rdfs:Literal ;
          rdfs:isDefinedBy <http://xmlns.com/foaf/0.1/> ;
          rdfs:comment "A name for some thing." ;
          rdfs:subPropertyOf rdfs:label ;
          vs:term_status "testing" .

foaf:nick a rdf:Property, owl:DatatypeProperty ;
          rdfs:label "nickname" ;
          rdfs:isDefinedBy <http://xmlns.com/foaf/0.1/> ;
          rdfs:comment "A short informal nickname characterising an agent (includes login identifiers, IRC and other chat nicknames)." ;
          vs:term_status "testing" .

foaf:page a owl:ObjectProperty ;
          rdfs:label "page" .

foaf:pastProject a owl:ObjectProperty ;
                 rdfs:label "past project" .

foaf:phone a owl:ObjectProperty ;
           rdfs:label "phone" .

foaf:primaryTopic a rdf:Property, owl:ObjectProperty, owl:FunctionalProperty ;
                  rdfs:label "primary topic" ;
                  rdfs:domain foaf:Document ;
                  rdfs:range owl:Thing ;
                  rdfs:isDefinedBy <http://xmlns.com/foaf/0.1/> ;
                  rdfs:comment "The primary topic of some page or document." ;
                  owl:inverseOf foaf:isPrimaryTopicOf ;
                  vs:term_status "stable" .

foaf:weblog a rdf:Property, owl:ObjectProperty, owl:InverseFunctionalProperty ;
            rdfs:label "weblog" ;
            rdfs:domain foaf:Agent ;
            rdfs:range foaf:Document ;
            rdfs:isDefinedBy <http://xmlns.com/foaf/0.1/> ;
            rdfs:comment "A weblog of some thing (whether person, group, company etc.)." ;
            rdfs:subPropertyOf foaf:page ;
            vs:term_status "testing" ;
            eis:buttonLabel "Weblog" .

<https://enterpriseinformationsystems.wordpress.com/> rdfs:label "Blog" .

ns27:wiki a eis:Demo ;
          rdfs:label "SemAnn" ;
          ov:screenshot <https://cloud.githubusercontent.com/assets/5968369/2618930/2ca19532-bc28-11e3-9ae8-0a7ee14560f3.gif> ;
          eis:demonstrates projects:SemAnn ;
          eis:hookline "Web-based semantic annotation tool for PDF documents." .

<https://github.com/MichaelMartin> a schema:ProfilePage ;
                                   foaf:primaryTopic people:MichaelMartin ;
                                   eis:buttonLabel "@github" .

<https://github.com/seebi> a schema:ProfilePage ;
                           foaf:primaryTopic people:SebastianTramp ;
                           eis:buttonLabel "@github" .

<https://plus.google.com/107848497008619758245?rel=author> a schema:ProfilePage ;
                                                           foaf:primaryTopic people:SebastianTramp ;
                                                           eis:buttonLabel "@Google+" .

<https://plus.google.com/109221747073615777107?rel=author> a schema:ProfilePage ;
                                                           foaf:primaryTopic people:NatanaelArndt ;
                                                           eis:buttonLabel "@Google+" .

<https://plus.google.com/111708276419474823915?rel=author> a schema:ProfilePage ;
                                                           foaf:primaryTopic people:AliKhalili ;
                                                           eis:buttonLabel "@Google+" .

<https://plus.google.com/113013131033550752154?rel=author> a schema:ProfilePage ;
                                                           foaf:primaryTopic people:MichaelMartin ;
                                                           eis:buttonLabel "@Google+" .

<https://plus.google.com/114223893421375686319?rel=author> a schema:ProfilePage ;
                                                           foaf:primaryTopic people:SarvenCapadisli ;
                                                           eis:buttonLabel "@Google+" .

<https://twitter.com/search?q=%23lswt2013&src=hash> a schema:ProfilePage ;
                                                    foaf:primaryTopic ns6:LeipzigerSemanticWebTag ;
                                                    eis:buttonLabel "@Twitter" .

<https://www.facebook.com/MichaelMartin79> a schema:ProfilePage ;
                                           foaf:primaryTopic people:MichaelMartin ;
                                           eis:buttonLabel "@Facebook" .

<https://www.facebook.com/events/445578762204541/> a schema:ProfilePage ;
                                                   foaf:primaryTopic ns6:LeipzigerSemanticWebTag ;
                                                   eis:buttonLabel "@Facebook" .

_:node1 foaf:name "Jaana Takis" .

_:node2 foaf:name "Timofey Ermilov" .
